//! Coverage validation script for CDFA unified library
//! 
//! This script analyzes test coverage and ensures 100% coverage across all modules.
//! It generates detailed reports and identifies uncovered code paths.

use std::collections::{HashMap, HashSet};
use std::fs::{self, File};
use std::io::{self, BufRead, BufReader, Write};
use std::path::{Path, PathBuf};
use std::process::{Command, Stdio};
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CoverageReport {
    pub total_lines: usize,
    pub covered_lines: usize,
    pub percentage: f64,
    pub uncovered_functions: Vec<String>,
    pub uncovered_branches: Vec<String>,
    pub module_coverage: HashMap<String, ModuleCoverage>,
    pub test_results: TestResults,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModuleCoverage {
    pub name: String,
    pub total_lines: usize,
    pub covered_lines: usize,
    pub percentage: f64,
    pub functions: Vec<FunctionCoverage>,
    pub missing_tests: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FunctionCoverage {
    pub name: String,
    pub line_start: usize,
    pub line_end: usize,
    pub covered: bool,
    pub test_count: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestResults {
    pub unit_tests: TestSuite,
    pub integration_tests: TestSuite,
    pub property_tests: TestSuite,
    pub fuzz_tests: TestSuite,
    pub benchmark_tests: TestSuite,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestSuite {
    pub total: usize,
    pub passed: usize,
    pub failed: usize,
    pub ignored: usize,
    pub duration_ms: u64,
}

impl Default for TestSuite {
    fn default() -> Self {
        Self {
            total: 0,
            passed: 0,
            failed: 0,
            ignored: 0,
            duration_ms: 0,
        }
    }
}

pub struct CoverageValidator {
    pub project_root: PathBuf,
    pub source_dir: PathBuf,
    pub test_dir: PathBuf,
    pub target_coverage: f64,
}

impl CoverageValidator {
    pub fn new<P: AsRef<Path>>(project_root: P, target_coverage: f64) -> Self {
        let project_root = project_root.as_ref().to_path_buf();
        let source_dir = project_root.join("src");
        let test_dir = project_root.join("tests");
        
        Self {
            project_root,
            source_dir,
            test_dir,
            target_coverage,
        }
    }

    /// Run comprehensive coverage analysis
    pub fn validate_coverage(&self) -> io::Result<CoverageReport> {
        println!("üîç Starting comprehensive coverage analysis...");
        
        // Step 1: Run all tests with coverage
        let test_results = self.run_all_tests()?;
        
        // Step 2: Generate coverage data
        let coverage_data = self.generate_coverage_data()?;
        
        // Step 3: Analyze source code for uncovered functions
        let module_coverage = self.analyze_module_coverage()?;
        
        // Step 4: Calculate overall metrics
        let (total_lines, covered_lines) = self.calculate_total_coverage(&module_coverage);
        let percentage = if total_lines > 0 {
            (covered_lines as f64 / total_lines as f64) * 100.0
        } else {
            0.0
        };
        
        // Step 5: Identify gaps
        let uncovered_functions = self.find_uncovered_functions(&module_coverage);
        let uncovered_branches = self.find_uncovered_branches(&coverage_data)?;
        
        let report = CoverageReport {
            total_lines,
            covered_lines,
            percentage,
            uncovered_functions,
            uncovered_branches,
            module_coverage,
            test_results,
        };
        
        // Step 6: Generate detailed report
        self.generate_report(&report)?;
        
        // Step 7: Validate against target
        self.validate_target(&report)?;
        
        Ok(report)
    }

    /// Run all test suites and collect results
    fn run_all_tests(&self) -> io::Result<TestResults> {
        println!("üß™ Running all test suites...");
        
        let unit_tests = self.run_test_suite(&["--lib"], "Unit tests")?;
        let integration_tests = self.run_test_suite(&["--test", "*"], "Integration tests")?;
        let property_tests = self.run_test_suite(&["--", "--include-ignored", "property"], "Property tests")?;
        let fuzz_tests = self.run_test_suite(&["--", "--include-ignored", "fuzz"], "Fuzz tests")?;
        let benchmark_tests = self.run_benchmark_tests()?;
        
        Ok(TestResults {
            unit_tests,
            integration_tests,
            property_tests,
            fuzz_tests,
            benchmark_tests,
        })
    }

    /// Run a specific test suite
    fn run_test_suite(&self, args: &[&str], description: &str) -> io::Result<TestSuite> {
        println!("  Running {}...", description);
        
        let start_time = std::time::Instant::now();
        
        let mut cmd = Command::new("cargo");
        cmd.current_dir(&self.project_root)
           .arg("test")
           .args(args)
           .stdout(Stdio::piped())
           .stderr(Stdio::piped());
        
        let output = cmd.output()?;
        let duration_ms = start_time.elapsed().as_millis() as u64;
        
        // Parse test output
        let stdout = String::from_utf8_lossy(&output.stdout);
        let test_suite = self.parse_test_output(&stdout, duration_ms);
        
        if output.status.success() {
            println!("    ‚úÖ {} completed: {} passed, {} failed", 
                     description, test_suite.passed, test_suite.failed);
        } else {
            println!("    ‚ùå {} failed: {} passed, {} failed", 
                     description, test_suite.passed, test_suite.failed);
        }
        
        Ok(test_suite)
    }

    /// Run benchmark tests
    fn run_benchmark_tests(&self) -> io::Result<TestSuite> {
        println!("  Running benchmark tests...");
        
        let start_time = std::time::Instant::now();
        
        let mut cmd = Command::new("cargo");
        cmd.current_dir(&self.project_root)
           .arg("bench")
           .arg("--no-run") // Just compile, don't run long benchmarks
           .stdout(Stdio::piped())
           .stderr(Stdio::piped());
        
        let output = cmd.output()?;
        let duration_ms = start_time.elapsed().as_millis() as u64;
        
        // For benchmarks, we're mainly checking that they compile
        let passed = if output.status.success() { 1 } else { 0 };
        let failed = if output.status.success() { 0 } else { 1 };
        
        Ok(TestSuite {
            total: 1,
            passed,
            failed,
            ignored: 0,
            duration_ms,
        })
    }

    /// Parse test output to extract metrics
    fn parse_test_output(&self, output: &str, duration_ms: u64) -> TestSuite {
        let mut total = 0;
        let mut passed = 0;
        let mut failed = 0;
        let mut ignored = 0;
        
        for line in output.lines() {
            if line.contains("test result:") {
                // Parse line like: "test result: ok. 15 passed; 0 failed; 2 ignored; 0 measured; 0 filtered out"
                let parts: Vec<&str> = line.split_whitespace().collect();
                for i in 0..parts.len() {
                    if parts[i] == "passed;" && i > 0 {
                        passed = parts[i-1].parse().unwrap_or(0);
                    } else if parts[i] == "failed;" && i > 0 {
                        failed = parts[i-1].parse().unwrap_or(0);
                    } else if parts[i] == "ignored;" && i > 0 {
                        ignored = parts[i-1].parse().unwrap_or(0);
                    }
                }
                total = passed + failed + ignored;
                break;
            }
        }
        
        TestSuite {
            total,
            passed,
            failed,
            ignored,
            duration_ms,
        }
    }

    /// Generate coverage data using tarpaulin
    fn generate_coverage_data(&self) -> io::Result<String> {
        println!("üìä Generating coverage data with tarpaulin...");
        
        let mut cmd = Command::new("cargo");
        cmd.current_dir(&self.project_root)
           .arg("tarpaulin")
           .arg("--out")
           .arg("Lcov")
           .arg("--output-dir")
           .arg("target/coverage")
           .arg("--exclude-files")
           .arg("target/*")
           .arg("--exclude-files")
           .arg("tests/*")
           .stdout(Stdio::piped())
           .stderr(Stdio::piped());
        
        let output = cmd.output()?;
        
        if !output.status.success() {
            let stderr = String::from_utf8_lossy(&output.stderr);
            eprintln!("Warning: tarpaulin failed: {}", stderr);
            return Ok(String::new());
        }
        
        // Read the generated lcov file
        let lcov_path = self.project_root.join("target/coverage/lcov.info");
        if lcov_path.exists() {
            fs::read_to_string(lcov_path)
        } else {
            Ok(String::new())
        }
    }

    /// Analyze coverage for each module
    fn analyze_module_coverage(&self) -> io::Result<HashMap<String, ModuleCoverage>> {
        println!("üî¨ Analyzing module coverage...");
        
        let mut module_coverage = HashMap::new();
        
        // Analyze each Rust file in src/
        for entry in walkdir::WalkDir::new(&self.source_dir) {
            let entry = entry?;
            if entry.path().extension().and_then(|s| s.to_str()) == Some("rs") {
                let module_name = self.get_module_name(entry.path());
                let coverage = self.analyze_file_coverage(entry.path())?;
                module_coverage.insert(module_name, coverage);
            }
        }
        
        Ok(module_coverage)
    }

    /// Analyze coverage for a single file
    fn analyze_file_coverage(&self, file_path: &Path) -> io::Result<ModuleCoverage> {
        let content = fs::read_to_string(file_path)?;
        let lines: Vec<&str> = content.lines().collect();
        
        let functions = self.extract_functions(&content);
        let missing_tests = self.find_missing_tests_for_file(file_path)?;
        
        // Simple line counting (in real implementation, use coverage data)
        let total_lines = lines.len();
        let covered_lines = (total_lines as f64 * 0.8) as usize; // Placeholder
        let percentage = (covered_lines as f64 / total_lines as f64) * 100.0;
        
        Ok(ModuleCoverage {
            name: self.get_module_name(file_path),
            total_lines,
            covered_lines,
            percentage,
            functions,
            missing_tests,
        })
    }

    /// Extract function definitions from source code
    fn extract_functions(&self, content: &str) -> Vec<FunctionCoverage> {
        let mut functions = Vec::new();
        let lines: Vec<&str> = content.lines().collect();
        
        for (i, line) in lines.iter().enumerate() {
            let trimmed = line.trim();
            if trimmed.starts_with("pub fn ") || trimmed.starts_with("fn ") {
                if let Some(name) = self.extract_function_name(trimmed) {
                    // Find function end (simplified)
                    let mut end_line = i;
                    let mut brace_count = 0;
                    for (j, &check_line) in lines.iter().enumerate().skip(i) {
                        for ch in check_line.chars() {
                            match ch {
                                '{' => brace_count += 1,
                                '}' => {
                                    brace_count -= 1;
                                    if brace_count == 0 {
                                        end_line = j;
                                        break;
                                    }
                                }
                                _ => {}
                            }
                        }
                        if brace_count == 0 && j > i {
                            break;
                        }
                    }
                    
                    functions.push(FunctionCoverage {
                        name,
                        line_start: i + 1,
                        line_end: end_line + 1,
                        covered: true, // Placeholder - would use actual coverage data
                        test_count: 1, // Placeholder
                    });
                }
            }
        }
        
        functions
    }

    /// Extract function name from function declaration
    fn extract_function_name(&self, line: &str) -> Option<String> {
        // Simple regex-like parsing
        if let Some(start) = line.find("fn ") {
            let after_fn = &line[start + 3..];
            if let Some(end) = after_fn.find('(') {
                let name = after_fn[..end].trim();
                return Some(name.to_string());
            }
        }
        None
    }

    /// Find missing tests for a specific file
    fn find_missing_tests_for_file(&self, file_path: &Path) -> io::Result<Vec<String>> {
        let module_name = self.get_module_name(file_path);
        let test_file_candidates = vec![
            self.test_dir.join(format!("{}_tests.rs", module_name)),
            self.test_dir.join(format!("test_{}.rs", module_name)),
            self.source_dir.join(file_path.file_name().unwrap()),
        ];
        
        let mut missing_tests = Vec::new();
        
        // Check if corresponding test file exists
        let has_test_file = test_file_candidates.iter().any(|p| p.exists());
        if !has_test_file {
            missing_tests.push(format!("No test file found for {}", module_name));
        }
        
        // TODO: Check for specific missing test functions
        
        Ok(missing_tests)
    }

    /// Get module name from file path
    fn get_module_name(&self, file_path: &Path) -> String {
        file_path
            .strip_prefix(&self.source_dir)
            .unwrap_or(file_path)
            .with_extension("")
            .to_string_lossy()
            .replace('/', "::")
    }

    /// Calculate total coverage across all modules
    fn calculate_total_coverage(&self, modules: &HashMap<String, ModuleCoverage>) -> (usize, usize) {
        let total_lines = modules.values().map(|m| m.total_lines).sum();
        let covered_lines = modules.values().map(|m| m.covered_lines).sum();
        (total_lines, covered_lines)
    }

    /// Find all uncovered functions
    fn find_uncovered_functions(&self, modules: &HashMap<String, ModuleCoverage>) -> Vec<String> {
        let mut uncovered = Vec::new();
        
        for module in modules.values() {
            for function in &module.functions {
                if !function.covered {
                    uncovered.push(format!("{}::{}", module.name, function.name));
                }
            }
        }
        
        uncovered
    }

    /// Find uncovered branches from coverage data
    fn find_uncovered_branches(&self, _coverage_data: &str) -> io::Result<Vec<String>> {
        // TODO: Parse LCOV data to find uncovered branches
        Ok(vec![])
    }

    /// Generate detailed coverage report
    fn generate_report(&self, report: &CoverageReport) -> io::Result<()> {
        println!("üìù Generating coverage report...");
        
        let report_dir = self.project_root.join("target/coverage-report");
        fs::create_dir_all(&report_dir)?;
        
        // Generate JSON report
        let json_report = serde_json::to_string_pretty(report)?;
        let json_path = report_dir.join("coverage-report.json");
        fs::write(json_path, json_report)?;
        
        // Generate HTML report
        self.generate_html_report(report, &report_dir)?;
        
        // Generate console summary
        self.print_coverage_summary(report);
        
        Ok(())
    }

    /// Generate HTML coverage report
    fn generate_html_report(&self, report: &CoverageReport, output_dir: &Path) -> io::Result<()> {
        let html_content = format!(
            r#"<!DOCTYPE html>
<html>
<head>
    <title>CDFA Coverage Report</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 40px; }}
        .header {{ background: #f5f5f5; padding: 20px; border-radius: 5px; }}
        .coverage-bar {{ 
            width: 100%; 
            height: 20px; 
            background: #f0f0f0; 
            border-radius: 10px; 
            overflow: hidden; 
        }}
        .coverage-fill {{ 
            height: 100%; 
            background: linear-gradient(to right, #ff4444, #ffaa00, #44ff44); 
        }}
        .module {{ 
            margin: 20px 0; 
            padding: 15px; 
            border: 1px solid #ddd; 
            border-radius: 5px; 
        }}
        .function {{ 
            margin: 5px 0; 
            padding: 5px; 
            background: #f9f9f9; 
        }}
        .covered {{ background: #e8f5e8; }}
        .uncovered {{ background: #ffe8e8; }}
        .test-suite {{
            display: inline-block;
            margin: 10px;
            padding: 10px;
            border: 1px solid #ccc;
            border-radius: 5px;
        }}
        .passed {{ color: green; }}
        .failed {{ color: red; }}
        .ignored {{ color: orange; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>CDFA Coverage Report</h1>
        <p>Generated on {}</p>
        <h2>Overall Coverage: {:.2}%</h2>
        <div class="coverage-bar">
            <div class="coverage-fill" style="width: {:.2}%"></div>
        </div>
        <p>{} / {} lines covered</p>
    </div>
    
    <h2>Test Results</h2>
    <div class="test-suite">
        <h3>Unit Tests</h3>
        <p class="passed">Passed: {}</p>
        <p class="failed">Failed: {}</p>
        <p class="ignored">Ignored: {}</p>
        <p>Duration: {}ms</p>
    </div>
    
    <div class="test-suite">
        <h3>Integration Tests</h3>
        <p class="passed">Passed: {}</p>
        <p class="failed">Failed: {}</p>
        <p class="ignored">Ignored: {}</p>
        <p>Duration: {}ms</p>
    </div>
    
    <div class="test-suite">
        <h3>Property Tests</h3>
        <p class="passed">Passed: {}</p>
        <p class="failed">Failed: {}</p>
        <p class="ignored">Ignored: {}</p>
        <p>Duration: {}ms</p>
    </div>
    
    <div class="test-suite">
        <h3>Fuzz Tests</h3>
        <p class="passed">Passed: {}</p>
        <p class="failed">Failed: {}</p>
        <p class="ignored">Ignored: {}</p>
        <p>Duration: {}ms</p>
    </div>
    
    <h2>Module Coverage</h2>
    {}
    
    <h2>Uncovered Functions</h2>
    <ul>
        {}
    </ul>
    
    <h2>Uncovered Branches</h2>
    <ul>
        {}
    </ul>
</body>
</html>"#,
            chrono::Utc::now().format("%Y-%m-%d %H:%M:%S UTC"),
            report.percentage,
            report.percentage,
            report.covered_lines,
            report.total_lines,
            report.test_results.unit_tests.passed,
            report.test_results.unit_tests.failed,
            report.test_results.unit_tests.ignored,
            report.test_results.unit_tests.duration_ms,
            report.test_results.integration_tests.passed,
            report.test_results.integration_tests.failed,
            report.test_results.integration_tests.ignored,
            report.test_results.integration_tests.duration_ms,
            report.test_results.property_tests.passed,
            report.test_results.property_tests.failed,
            report.test_results.property_tests.ignored,
            report.test_results.property_tests.duration_ms,
            report.test_results.fuzz_tests.passed,
            report.test_results.fuzz_tests.failed,
            report.test_results.fuzz_tests.ignored,
            report.test_results.fuzz_tests.duration_ms,
            self.generate_module_html(&report.module_coverage),
            report.uncovered_functions.iter()
                .map(|f| format!("<li>{}</li>", f))
                .collect::<Vec<_>>()
                .join("\n"),
            report.uncovered_branches.iter()
                .map(|b| format!("<li>{}</li>", b))
                .collect::<Vec<_>>()
                .join("\n"),
        );
        
        let html_path = output_dir.join("index.html");
        fs::write(html_path, html_content)?;
        
        Ok(())
    }

    /// Generate HTML for module coverage
    fn generate_module_html(&self, modules: &HashMap<String, ModuleCoverage>) -> String {
        let mut html = String::new();
        
        for module in modules.values() {
            html.push_str(&format!(
                r#"<div class="module">
                    <h3>{}</h3>
                    <p>Coverage: {:.2}% ({} / {} lines)</p>
                    <div class="coverage-bar">
                        <div class="coverage-fill" style="width: {:.2}%"></div>
                    </div>
                    <h4>Functions:</h4>
                    {}</div>"#,
                module.name,
                module.percentage,
                module.covered_lines,
                module.total_lines,
                module.percentage,
                module.functions.iter()
                    .map(|f| format!(
                        r#"<div class="function {}">
                            {} (lines {}-{}) - {} tests
                        </div>"#,
                        if f.covered { "covered" } else { "uncovered" },
                        f.name,
                        f.line_start,
                        f.line_end,
                        f.test_count
                    ))
                    .collect::<Vec<_>>()
                    .join("\n")
            ));
        }
        
        html
    }

    /// Print coverage summary to console
    fn print_coverage_summary(&self, report: &CoverageReport) {
        println!("\nüìä COVERAGE SUMMARY");
        println!("===================");
        println!("Overall Coverage: {:.2}%", report.percentage);
        println!("Lines Covered: {} / {}", report.covered_lines, report.total_lines);
        
        println!("\nüß™ TEST RESULTS");
        println!("================");
        println!("Unit Tests:        {} passed, {} failed, {} ignored", 
                 report.test_results.unit_tests.passed,
                 report.test_results.unit_tests.failed,
                 report.test_results.unit_tests.ignored);
        println!("Integration Tests: {} passed, {} failed, {} ignored", 
                 report.test_results.integration_tests.passed,
                 report.test_results.integration_tests.failed,
                 report.test_results.integration_tests.ignored);
        println!("Property Tests:    {} passed, {} failed, {} ignored", 
                 report.test_results.property_tests.passed,
                 report.test_results.property_tests.failed,
                 report.test_results.property_tests.ignored);
        println!("Fuzz Tests:        {} passed, {} failed, {} ignored", 
                 report.test_results.fuzz_tests.passed,
                 report.test_results.fuzz_tests.failed,
                 report.test_results.fuzz_tests.ignored);
        
        if !report.uncovered_functions.is_empty() {
            println!("\n‚ùå UNCOVERED FUNCTIONS ({}):", report.uncovered_functions.len());
            for func in &report.uncovered_functions {
                println!("   - {}", func);
            }
        }
        
        if !report.uncovered_branches.is_empty() {
            println!("\n‚ùå UNCOVERED BRANCHES ({}):", report.uncovered_branches.len());
            for branch in &report.uncovered_branches {
                println!("   - {}", branch);
            }
        }
        
        // Module breakdown
        println!("\nüìÅ MODULE BREAKDOWN");
        println!("====================");
        for (name, module) in &report.module_coverage {
            let status = if module.percentage >= 100.0 {
                "‚úÖ"
            } else if module.percentage >= 90.0 {
                "‚ö†Ô∏è "
            } else {
                "‚ùå"
            };
            println!("{} {}: {:.1}%", status, name, module.percentage);
        }
    }

    /// Validate coverage against target
    fn validate_target(&self, report: &CoverageReport) -> io::Result<()> {
        println!("\nüéØ COVERAGE VALIDATION");
        println!("=======================");
        
        if report.percentage >= self.target_coverage {
            println!("‚úÖ Coverage target achieved: {:.2}% >= {:.2}%", 
                     report.percentage, self.target_coverage);
        } else {
            println!("‚ùå Coverage target not met: {:.2}% < {:.2}%", 
                     report.percentage, self.target_coverage);
            println!("   Need {:.2}% more coverage", 
                     self.target_coverage - report.percentage);
            
            // Provide actionable suggestions
            self.provide_coverage_suggestions(report);
            
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("Coverage target not met: {:.2}% < {:.2}%", 
                        report.percentage, self.target_coverage)
            ));
        }
        
        // Check test failures
        let total_failures = report.test_results.unit_tests.failed +
                           report.test_results.integration_tests.failed +
                           report.test_results.property_tests.failed +
                           report.test_results.fuzz_tests.failed;
        
        if total_failures > 0 {
            println!("‚ùå Some tests are failing: {} total failures", total_failures);
            return Err(io::Error::new(
                io::ErrorKind::Other,
                format!("{} tests are failing", total_failures)
            ));
        }
        
        println!("‚úÖ All validation checks passed!");
        Ok(())
    }

    /// Provide suggestions for improving coverage
    fn provide_coverage_suggestions(&self, report: &CoverageReport) {
        println!("\nüí° SUGGESTIONS FOR IMPROVING COVERAGE");
        println!("======================================");
        
        // Find modules with lowest coverage
        let mut modules: Vec<_> = report.module_coverage.iter().collect();
        modules.sort_by(|a, b| a.1.percentage.partial_cmp(&b.1.percentage).unwrap());
        
        println!("üîç Focus on these low-coverage modules:");
        for (name, module) in modules.iter().take(5) {
            if module.percentage < 90.0 {
                println!("   - {}: {:.1}% (need {} more lines)", 
                         name, module.percentage, 
                         ((90.0 - module.percentage) / 100.0 * module.total_lines as f64) as usize);
            }
        }
        
        if !report.uncovered_functions.is_empty() {
            println!("\nüéØ Add tests for these functions:");
            for func in report.uncovered_functions.iter().take(10) {
                println!("   - {}", func);
            }
            if report.uncovered_functions.len() > 10 {
                println!("   ... and {} more", report.uncovered_functions.len() - 10);
            }
        }
        
        println!("\nüìã Recommended test types to add:");
        if report.test_results.property_tests.total == 0 {
            println!("   - Property-based tests for mathematical properties");
        }
        if report.test_results.fuzz_tests.total == 0 {
            println!("   - Fuzz tests for edge cases and robustness");
        }
        println!("   - Error path tests for better branch coverage");
        println!("   - Integration tests for module interactions");
        println!("   - Performance regression tests");
    }
}

/// Main function for running coverage validation
pub fn main() -> io::Result<()> {
    let args: Vec<String> = std::env::args().collect();
    let target_coverage = if args.len() > 1 {
        args[1].parse().unwrap_or(100.0)
    } else {
        100.0
    };
    
    let project_root = std::env::current_dir()?;
    let validator = CoverageValidator::new(project_root, target_coverage);
    
    match validator.validate_coverage() {
        Ok(report) => {
            println!("\n‚úÖ Coverage validation completed successfully!");
            println!("üìä Final coverage: {:.2}%", report.percentage);
            println!("üìù Report saved to: target/coverage-report/index.html");
            Ok(())
        }
        Err(e) => {
            eprintln!("\n‚ùå Coverage validation failed: {}", e);
            std::process::exit(1);
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;

    #[test]
    fn test_coverage_validator_creation() {
        let temp_dir = TempDir::new().unwrap();
        let validator = CoverageValidator::new(temp_dir.path(), 95.0);
        
        assert_eq!(validator.target_coverage, 95.0);
        assert!(validator.project_root.ends_with(temp_dir.path().file_name().unwrap()));
    }

    #[test]
    fn test_function_name_extraction() {
        let validator = CoverageValidator::new(".", 100.0);
        
        assert_eq!(validator.extract_function_name("pub fn test_function() {"), 
                   Some("test_function".to_string()));
        assert_eq!(validator.extract_function_name("fn private_function(x: i32) -> bool {"), 
                   Some("private_function".to_string()));
        assert_eq!(validator.extract_function_name("not a function"), None);
    }

    #[test]
    fn test_module_name_generation() {
        let temp_dir = TempDir::new().unwrap();
        let validator = CoverageValidator::new(temp_dir.path(), 100.0);
        
        let test_path = validator.source_dir.join("core").join("diversity").join("mod.rs");
        let module_name = validator.get_module_name(&test_path);
        
        assert_eq!(module_name, "core::diversity::mod");
    }
}