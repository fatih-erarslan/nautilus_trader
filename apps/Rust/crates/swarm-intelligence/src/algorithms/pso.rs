//! # Particle Swarm Optimization (PSO) - Enterprise Implementation
//!
//! Advanced implementation of Particle Swarm Optimization with multiple variants,
//! adaptive parameters, and enterprise-grade features for production use.
//!
//! ## Variants Implemented
//! - **Standard PSO**: Classic Eberhart-Kennedy formulation
//! - **SPSO-2011**: Standard PSO 2011 with improved velocity clamping
//! - **APSO**: Adaptive PSO with fuzzy parameter tuning
//! - **CLPSO**: Comprehensive Learning PSO with exemplar selection
//! - **FIPS**: Fully Informed Particle Swarm with social learning
//! - **PPSO**: Parallel PSO with asynchronous updates
//!
//! ## Features
//! - Adaptive inertia weight and acceleration coefficients
//! - Multiple neighborhood topologies (global, local, ring, cluster)
//! - Velocity clamping and position boundary handling
//! - Elite preservation and diversity maintenance
//! - SIMD-optimized vector operations
//! - Real-time performance monitoring

use crate::core::{
    SwarmAlgorithm, SwarmError, Position, Velocity, Population, Individual,
    Fitness, OptimizationProblem, CommonParameters, ConvergencePoint,
    AlgorithmMetrics, PopulationStatistics, Result
};\nuse crate::Float;\nuse async_trait::async_trait;\nuse nalgebra::DVector;\nuse rand::{Rng, SeedableRng};\nuse rand_distr::{Normal, Uniform};\nuse rayon::prelude::*;\nuse serde::{Deserialize, Serialize};\nuse std::sync::{Arc, Mutex};\nuse std::time::{Duration, Instant};\nuse tracing::{debug, info, warn};\n\n/// PSO variant selection\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\npub enum PsoVariant {\n    /// Standard PSO (Eberhart & Kennedy, 1995)\n    Standard,\n    /// Standard PSO 2011 with constriction factor\n    Spso2011,\n    /// Adaptive PSO with fuzzy parameter control\n    Adaptive,\n    /// Comprehensive Learning PSO\n    ComprehensiveLearning,\n    /// Fully Informed Particle Swarm\n    FullyInformed,\n    /// Parallel PSO with asynchronous updates\n    Parallel,\n}\n\n/// Neighborhood topology for particle interactions\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\npub enum Topology {\n    /// Global best topology (all particles connected)\n    Global,\n    /// Local best with ring topology\n    Ring,\n    /// Von Neumann neighborhood (4-connected grid)\n    VonNeumann,\n    /// Random k-connected topology\n    Random { k: usize },\n    /// Hierarchical clustering topology\n    Cluster { clusters: usize },\n}\n\n/// Advanced PSO parameters\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PsoParameters {\n    /// Base parameters\n    pub common: CommonParameters,\n    /// PSO variant to use\n    pub variant: PsoVariant,\n    /// Particle interaction topology\n    pub topology: Topology,\n    /// Inertia weight (w)\n    pub inertia_weight: Float,\n    /// Cognitive acceleration coefficient (c1)\n    pub cognitive_coeff: Float,\n    /// Social acceleration coefficient (c2)\n    pub social_coeff: Float,\n    /// Maximum velocity factor (fraction of search space)\n    pub max_velocity_factor: Float,\n    /// Constriction factor (for SPSO-2011)\n    pub constriction_factor: Float,\n    /// Enable adaptive parameter tuning\n    pub adaptive_parameters: bool,\n    /// Velocity clamping strategy\n    pub velocity_clamping: VelocityClampingStrategy,\n    /// Position boundary handling\n    pub boundary_handling: BoundaryHandlingStrategy,\n    /// Enable elite preservation\n    pub elite_preservation: bool,\n    /// Diversity maintenance threshold\n    pub diversity_threshold: Float,\n    /// Learning probability for CLPSO\n    pub learning_probability: Float,\n    /// Minimum neighborhood size\n    pub min_neighborhood_size: usize,\n}\n\nimpl Default for PsoParameters {\n    fn default() -> Self {\n        Self {\n            common: CommonParameters::default(),\n            variant: PsoVariant::Standard,\n            topology: Topology::Global,\n            inertia_weight: 0.9,\n            cognitive_coeff: 2.0,\n            social_coeff: 2.0,\n            max_velocity_factor: 0.1,\n            constriction_factor: 0.729,\n            adaptive_parameters: true,\n            velocity_clamping: VelocityClampingStrategy::Hyperbolic,\n            boundary_handling: BoundaryHandlingStrategy::Reflect,\n            elite_preservation: true,\n            diversity_threshold: 1e-6,\n            learning_probability: 0.05,\n            min_neighborhood_size: 3,\n        }\n    }\n}\n\n/// Velocity clamping strategies\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\npub enum VelocityClampingStrategy {\n    /// Linear velocity clamping\n    Linear,\n    /// Hyperbolic velocity clamping\n    Hyperbolic,\n    /// Random velocity clamping\n    Random,\n    /// No velocity clamping\n    None,\n}\n\n/// Boundary handling strategies\n#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]\npub enum BoundaryHandlingStrategy {\n    /// Reflect particles off boundaries\n    Reflect,\n    /// Absorb particles at boundaries\n    Absorb,\n    /// Wrap particles around boundaries\n    Wrap,\n    /// Random re-initialization\n    Random,\n    /// Penalty-based handling\n    Penalty,\n}\n\n/// Individual particle in the swarm\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Particle {\n    /// Current position\n    pub position: Position,\n    /// Current velocity\n    pub velocity: Velocity,\n    /// Personal best position\n    pub personal_best: Position,\n    /// Personal best fitness\n    pub personal_best_fitness: Fitness,\n    /// Current fitness\n    pub fitness: Fitness,\n    /// Neighborhood best position\n    pub neighborhood_best: Position,\n    /// Neighborhood best fitness\n    pub neighborhood_best_fitness: Fitness,\n    /// Particle ID for tracking\n    pub id: usize,\n    /// Stagnation counter\n    pub stagnation_count: usize,\n    /// Success rate for adaptive algorithms\n    pub success_rate: Float,\n}\n\nimpl Particle {\n    /// Create a new particle with random initialization\n    pub fn new(\n        id: usize,\n        dimensions: usize,\n        bounds: &[(Float, Float)],\n        rng: &mut impl Rng,\n    ) -> Self {\n        let position = DVector::from_fn(dimensions, |i, _| {\n            let (min, max) = bounds[i];\n            rng.gen_range(min..=max)\n        });\n        \n        let velocity = DVector::zeros(dimensions);\n        let fitness = Float::INFINITY;\n        \n        Self {\n            position: position.clone(),\n            velocity,\n            personal_best: position.clone(),\n            personal_best_fitness: fitness,\n            fitness,\n            neighborhood_best: position,\n            neighborhood_best_fitness: fitness,\n            id,\n            stagnation_count: 0,\n            success_rate: 0.0,\n        }\n    }\n    \n    /// Update particle velocity using PSO equations\n    pub fn update_velocity(\n        &mut self,\n        global_best: &Position,\n        params: &PsoParameters,\n        rng: &mut impl Rng,\n        iteration: usize,\n        max_iterations: usize,\n    ) -> Result<()> {\n        let dimensions = self.position.len();\n        \n        match params.variant {\n            PsoVariant::Standard => {\n                self.update_velocity_standard(global_best, params, rng)?;\n            }\n            PsoVariant::Spso2011 => {\n                self.update_velocity_spso2011(global_best, params, rng)?;\n            }\n            PsoVariant::Adaptive => {\n                self.update_velocity_adaptive(global_best, params, rng, iteration, max_iterations)?;\n            }\n            PsoVariant::ComprehensiveLearning => {\n                self.update_velocity_clpso(params, rng)?;\n            }\n            PsoVariant::FullyInformed => {\n                self.update_velocity_fips(params, rng)?;\n            }\n            PsoVariant::Parallel => {\n                self.update_velocity_parallel(global_best, params, rng)?;\n            }\n        }\n        \n        // Apply velocity clamping\n        self.apply_velocity_clamping(params);\n        \n        Ok(())\n    }\n    \n    /// Standard PSO velocity update\n    fn update_velocity_standard(\n        &mut self,\n        global_best: &Position,\n        params: &PsoParameters,\n        rng: &mut impl Rng,\n    ) -> Result<()> {\n        let r1: Float = rng.gen();\n        let r2: Float = rng.gen();\n        \n        // v = w*v + c1*r1*(pbest - x) + c2*r2*(gbest - x)\n        self.velocity = params.inertia_weight * &self.velocity\n            + params.cognitive_coeff * r1 * (&self.personal_best - &self.position)\n            + params.social_coeff * r2 * (global_best - &self.position);\n        \n        Ok(())\n    }\n    \n    /// SPSO-2011 velocity update with constriction factor\n    fn update_velocity_spso2011(\n        &mut self,\n        global_best: &Position,\n        params: &PsoParameters,\n        rng: &mut impl Rng,\n    ) -> Result<()> {\n        let r1: Float = rng.gen();\n        let r2: Float = rng.gen();\n        \n        let phi = params.cognitive_coeff + params.social_coeff;\n        let chi = if phi > 4.0 {\n            2.0 / (phi - 2.0 + (phi * phi - 4.0 * phi).sqrt())\n        } else {\n            params.constriction_factor\n        };\n        \n        // Constricted velocity update\n        self.velocity = chi * (\n            &self.velocity\n            + params.cognitive_coeff * r1 * (&self.personal_best - &self.position)\n            + params.social_coeff * r2 * (global_best - &self.position)\n        );\n        \n        Ok(())\n    }\n    \n    /// Adaptive PSO with dynamic parameter adjustment\n    fn update_velocity_adaptive(\n        &mut self,\n        global_best: &Position,\n        params: &PsoParameters,\n        rng: &mut impl Rng,\n        iteration: usize,\n        max_iterations: usize,\n    ) -> Result<()> {\n        // Adaptive inertia weight (linearly decreasing)\n        let progress = iteration as Float / max_iterations as Float;\n        let adaptive_w = 0.9 - 0.5 * progress;\n        \n        // Adaptive acceleration coefficients\n        let adaptive_c1 = 2.5 - 2.0 * progress;\n        let adaptive_c2 = 0.5 + 2.0 * progress;\n        \n        let r1: Float = rng.gen();\n        let r2: Float = rng.gen();\n        \n        self.velocity = adaptive_w * &self.velocity\n            + adaptive_c1 * r1 * (&self.personal_best - &self.position)\n            + adaptive_c2 * r2 * (global_best - &self.position);\n        \n        Ok(())\n    }\n    \n    /// Comprehensive Learning PSO (CLPSO) velocity update\n    fn update_velocity_clpso(\n        &mut self,\n        params: &PsoParameters,\n        rng: &mut impl Rng,\n    ) -> Result<()> {\n        // Implement CLPSO learning strategy\n        let learning_prob = params.learning_probability;\n        \n        for i in 0..self.velocity.len() {\n            let r: Float = rng.gen();\n            if r < learning_prob {\n                // Learn from personal best\n                let r1: Float = rng.gen();\n                self.velocity[i] = params.inertia_weight * self.velocity[i]\n                    + params.cognitive_coeff * r1 * (self.personal_best[i] - self.position[i]);\n            } else {\n                // Learn from neighborhood best\n                let r2: Float = rng.gen();\n                self.velocity[i] = params.inertia_weight * self.velocity[i]\n                    + params.social_coeff * r2 * (self.neighborhood_best[i] - self.position[i]);\n            }\n        }\n        \n        Ok(())\n    }\n    \n    /// Fully Informed Particle Swarm (FIPS) velocity update\n    fn update_velocity_fips(\n        &mut self,\n        params: &PsoParameters,\n        rng: &mut impl Rng,\n    ) -> Result<()> {\n        // FIPS uses information from all neighbors\n        let r1: Float = rng.gen();\n        let r2: Float = rng.gen();\n        \n        // Simplified FIPS implementation\n        let chi = params.constriction_factor;\n        self.velocity = chi * (\n            &self.velocity\n            + (params.cognitive_coeff + params.social_coeff) / 2.0 * r1 * (&self.personal_best - &self.position)\n            + (params.cognitive_coeff + params.social_coeff) / 2.0 * r2 * (&self.neighborhood_best - &self.position)\n        );\n        \n        Ok(())\n    }\n    \n    /// Parallel PSO velocity update\n    fn update_velocity_parallel(\n        &mut self,\n        global_best: &Position,\n        params: &PsoParameters,\n        rng: &mut impl Rng,\n    ) -> Result<()> {\n        // Parallel PSO with asynchronous updates\n        self.update_velocity_standard(global_best, params, rng)\n    }\n    \n    /// Apply velocity clamping strategies\n    fn apply_velocity_clamping(&mut self, params: &PsoParameters) {\n        match params.velocity_clamping {\n            VelocityClampingStrategy::Linear => {\n                // Linear clamping: v_max = factor * (x_max - x_min)\n                let v_max = params.max_velocity_factor * 10.0; // Simplified\n                self.velocity.iter_mut().for_each(|v| {\n                    *v = v.clamp(-v_max, v_max);\n                });\n            }\n            VelocityClampingStrategy::Hyperbolic => {\n                // Hyperbolic clamping: more gradual\n                let v_max = params.max_velocity_factor * 10.0;\n                self.velocity.iter_mut().for_each(|v| {\n                    *v = v_max * v.tanh() / (v_max).tanh();\n                });\n            }\n            VelocityClampingStrategy::Random => {\n                // Random perturbation for diversity\n                let v_max = params.max_velocity_factor * 10.0;\n                self.velocity.iter_mut().for_each(|v| {\n                    if v.abs() > v_max {\n                        *v = v.signum() * v_max * (0.5 + 0.5 * rand::random::<Float>());\n                    }\n                });\n            }\n            VelocityClampingStrategy::None => {\n                // No clamping\n            }\n        }\n    }\n    \n    /// Update particle position\n    pub fn update_position(&mut self, bounds: &[(Float, Float)], params: &PsoParameters) {\n        // Update position: x = x + v\n        self.position += &self.velocity;\n        \n        // Handle boundary constraints\n        self.handle_boundaries(bounds, params);\n    }\n    \n    /// Handle boundary constraints\n    fn handle_boundaries(&mut self, bounds: &[(Float, Float)], params: &PsoParameters) {\n        for (i, (min_bound, max_bound)) in bounds.iter().enumerate() {\n            match params.boundary_handling {\n                BoundaryHandlingStrategy::Reflect => {\n                    if self.position[i] < *min_bound {\n                        self.position[i] = *min_bound + (*min_bound - self.position[i]);\n                        self.velocity[i] = -self.velocity[i];\n                    } else if self.position[i] > *max_bound {\n                        self.position[i] = *max_bound - (self.position[i] - *max_bound);\n                        self.velocity[i] = -self.velocity[i];\n                    }\n                }\n                BoundaryHandlingStrategy::Absorb => {\n                    if self.position[i] < *min_bound {\n                        self.position[i] = *min_bound;\n                        self.velocity[i] = 0.0;\n                    } else if self.position[i] > *max_bound {\n                        self.position[i] = *max_bound;\n                        self.velocity[i] = 0.0;\n                    }\n                }\n                BoundaryHandlingStrategy::Wrap => {\n                    let range = max_bound - min_bound;\n                    if self.position[i] < *min_bound {\n                        self.position[i] = *max_bound - (*min_bound - self.position[i]) % range;\n                    } else if self.position[i] > *max_bound {\n                        self.position[i] = *min_bound + (self.position[i] - *max_bound) % range;\n                    }\n                }\n                BoundaryHandlingStrategy::Random => {\n                    if self.position[i] < *min_bound || self.position[i] > *max_bound {\n                        self.position[i] = rand::random::<Float>() * (max_bound - min_bound) + min_bound;\n                        self.velocity[i] = 0.0;\n                    }\n                }\n                BoundaryHandlingStrategy::Penalty => {\n                    // Position stays, but fitness gets penalty (handled in evaluation)\n                    self.position[i] = self.position[i].clamp(*min_bound, *max_bound);\n                }\n            }\n        }\n    }\n    \n    /// Update personal best if current fitness is better\n    pub fn update_personal_best(&mut self) -> bool {\n        if self.fitness < self.personal_best_fitness {\n            self.personal_best = self.position.clone();\n            self.personal_best_fitness = self.fitness;\n            self.stagnation_count = 0;\n            true\n        } else {\n            self.stagnation_count += 1;\n            false\n        }\n    }\n}\n\n/// Main PSO algorithm implementation\n#[derive(Debug)]\npub struct ParticleSwarmOptimization {\n    /// Algorithm parameters\n    params: PsoParameters,\n    /// Current swarm population\n    particles: Vec<Particle>,\n    /// Global best position\n    global_best: Position,\n    /// Global best fitness\n    global_best_fitness: Fitness,\n    /// Optimization problem\n    problem: Option<OptimizationProblem>,\n    /// Random number generator\n    rng: Box<dyn SeedableRng<Seed = [u8; 32]> + Send>,\n    /// Current iteration\n    iteration: usize,\n    /// Performance metrics\n    metrics: AlgorithmMetrics,\n    /// Neighborhood structure\n    neighborhoods: Vec<Vec<usize>>,\n    /// Elite archive\n    elite_archive: Vec<(Position, Fitness)>,\n}\n\n#[async_trait]\nimpl SwarmAlgorithm for ParticleSwarmOptimization {\n    type Parameters = PsoParameters;\n    \n    fn new(params: Self::Parameters) -> Result<Self> {\n        let seed = params.common.seed.map(|s| {\n            let mut seed_array = [0u8; 32];\n            seed_array[..8].copy_from_slice(&s.to_le_bytes());\n            seed_array\n        }).unwrap_or_else(|| rand::random());\n        \n        let rng = Box::new(rand_chacha::ChaCha8Rng::from_seed(seed));\n        \n        Ok(Self {\n            params,\n            particles: Vec::new(),\n            global_best: DVector::zeros(1),\n            global_best_fitness: Float::INFINITY,\n            problem: None,\n            rng,\n            iteration: 0,\n            metrics: AlgorithmMetrics::default(),\n            neighborhoods: Vec::new(),\n            elite_archive: Vec::new(),\n        })\n    }\n    \n    async fn initialize(&mut self, problem: OptimizationProblem) -> Result<()> {\n        let dimensions = problem.dimensions();\n        let bounds = problem.bounds();\n        \n        // Initialize particles\n        self.particles = (0..self.params.common.population_size)\n            .map(|i| Particle::new(i, dimensions, bounds, &mut *self.rng))\n            .collect();\n        \n        // Initialize global best\n        self.global_best = DVector::zeros(dimensions);\n        self.global_best_fitness = Float::INFINITY;\n        \n        // Setup neighborhood topology\n        self.setup_topology();\n        \n        // Store problem\n        self.problem = Some(problem);\n        \n        info!(\"PSO initialized with {} particles, {} dimensions\", \n              self.params.common.population_size, dimensions);\n        \n        Ok(())\n    }\n    \n    async fn step(&mut self) -> Result<()> {\n        let problem = self.problem.as_ref().ok_or_else(|| {\n            SwarmError::InitializationError(\"Problem not initialized\".to_string())\n        })?;\n        \n        let step_start = Instant::now();\n        \n        // Evaluate fitness for all particles\n        self.evaluate_fitness(problem).await?;\n        \n        // Update personal bests\n        self.update_personal_bests();\n        \n        // Update neighborhood bests\n        self.update_neighborhood_bests();\n        \n        // Update global best\n        self.update_global_best();\n        \n        // Update velocities and positions\n        self.update_particles(problem).await?;\n        \n        // Maintain diversity if needed\n        if self.params.adaptive_parameters {\n            self.maintain_diversity();\n        }\n        \n        // Update elite archive\n        if self.params.elite_preservation {\n            self.update_elite_archive();\n        }\n        \n        self.iteration += 1;\n        \n        // Update metrics\n        self.metrics.total_iterations = self.iteration;\n        self.metrics.last_step_duration = step_start.elapsed();\n        \n        Ok(())\n    }\n    \n    fn best_position(&self) -> Position {\n        self.global_best.clone()\n    }\n    \n    fn best_fitness(&self) -> Fitness {\n        self.global_best_fitness\n    }\n    \n    fn population(&self) -> &Population {\n        // Convert particles to population format\n        // This is a simplified implementation\n        unimplemented!(\"Population conversion needs proper implementation\")\n    }\n    \n    fn has_converged(&self) -> Result<bool> {\n        // Check various convergence criteria\n        let diversity = self.population_diversity();\n        let fitness_stagnation = self.metrics.stagnation_count > 50;\n        let diversity_threshold = diversity < self.params.diversity_threshold;\n        \n        Ok(fitness_stagnation || diversity_threshold)\n    }\n    \n    fn population_diversity(&self) -> Float {\n        if self.particles.len() < 2 {\n            return 0.0;\n        }\n        \n        let mut total_distance = 0.0;\n        let mut count = 0;\n        \n        for i in 0..self.particles.len() {\n            for j in (i + 1)..self.particles.len() {\n                let distance = (&self.particles[i].position - &self.particles[j].position).norm();\n                total_distance += distance;\n                count += 1;\n            }\n        }\n        \n        if count > 0 {\n            total_distance / count as Float\n        } else {\n            0.0\n        }\n    }\n    \n    async fn update_metrics(&mut self, iteration: usize, step_time: Duration) -> Result<()> {\n        self.metrics.total_iterations = iteration;\n        self.metrics.last_step_duration = step_time;\n        self.metrics.best_fitness = self.global_best_fitness;\n        self.metrics.diversity = self.population_diversity();\n        \n        // Check for stagnation\n        if self.metrics.best_fitness_history.len() > 10 {\n            let recent_best = self.metrics.best_fitness_history\n                .iter()\n                .rev()\n                .take(10)\n                .min_by(|a, b| a.partial_cmp(b).unwrap())\n                .unwrap();\n            \n            if (self.global_best_fitness - recent_best).abs() < self.params.common.tolerance {\n                self.metrics.stagnation_count += 1;\n            } else {\n                self.metrics.stagnation_count = 0;\n            }\n        }\n        \n        self.metrics.best_fitness_history.push(self.global_best_fitness);\n        \n        Ok(())\n    }\n    \n    fn metrics(&self) -> AlgorithmMetrics {\n        self.metrics.clone()\n    }\n    \n    async fn reset(&mut self) -> Result<()> {\n        self.iteration = 0;\n        self.global_best_fitness = Float::INFINITY;\n        self.metrics = AlgorithmMetrics::default();\n        self.elite_archive.clear();\n        \n        if let Some(ref problem) = self.problem {\n            let dimensions = problem.dimensions();\n            let bounds = problem.bounds();\n            \n            // Re-initialize particles\n            for particle in &mut self.particles {\n                particle.position = DVector::from_fn(dimensions, |i, _| {\n                    let (min, max) = bounds[i];\n                    self.rng.gen_range(min..=max)\n                });\n                particle.velocity = DVector::zeros(dimensions);\n                particle.fitness = Float::INFINITY;\n                particle.personal_best_fitness = Float::INFINITY;\n                particle.stagnation_count = 0;\n            }\n        }\n        \n        Ok(())\n    }\n    \n    fn name(&self) -> &'static str {\n        match self.params.variant {\n            PsoVariant::Standard => \"Particle Swarm Optimization\",\n            PsoVariant::Spso2011 => \"Standard PSO 2011\",\n            PsoVariant::Adaptive => \"Adaptive PSO\",\n            PsoVariant::ComprehensiveLearning => \"Comprehensive Learning PSO\",\n            PsoVariant::FullyInformed => \"Fully Informed Particle Swarm\",\n            PsoVariant::Parallel => \"Parallel PSO\",\n        }\n    }\n    \n    fn parameters(&self) -> &Self::Parameters {\n        &self.params\n    }\n    \n    fn set_parameters(&mut self, params: Self::Parameters) -> Result<()> {\n        self.params = params;\n        Ok(())\n    }\n    \n    fn current_iteration(&self) -> usize {\n        self.iteration\n    }\n    \n    fn serialize_state(&self) -> Result<Vec<u8>> {\n        let state = AlgorithmState {\n            iteration: self.iteration,\n            population: Population::default(), // Simplified\n            best_position: self.global_best.clone(),\n            best_fitness: self.global_best_fitness,\n            statistics: PopulationStatistics {\n                best_fitness: self.global_best_fitness,\n                worst_fitness: self.particles.iter()\n                    .map(|p| p.fitness)\n                    .fold(Float::NEG_INFINITY, Float::max),\n                mean_fitness: self.particles.iter()\n                    .map(|p| p.fitness)\n                    .sum::<Float>() / self.particles.len() as Float,\n                std_fitness: 0.0, // Simplified\n                diversity: self.population_diversity(),\n                convergence_rate: 0.0, // Simplified\n                stagnation_counter: self.metrics.stagnation_count,\n            },\n            algorithm_specific_data: serde_json::to_vec(&self.params)?,\n        };\n        \n        Ok(serde_json::to_vec(&state)?)\n    }\n    \n    fn deserialize_state(&mut self, data: &[u8]) -> Result<()> {\n        let state: AlgorithmState = serde_json::from_slice(data)?;\n        \n        self.iteration = state.iteration;\n        self.global_best = state.best_position;\n        self.global_best_fitness = state.best_fitness;\n        \n        // Restore algorithm-specific parameters\n        self.params = serde_json::from_slice(&state.algorithm_specific_data)?;\n        \n        Ok(())\n    }\n}\n\nimpl ParticleSwarmOptimization {\n    /// Evaluate fitness for all particles\n    async fn evaluate_fitness(&mut self, problem: &OptimizationProblem) -> Result<()> {\n        if self.params.common.parallel_evaluation {\n            // Parallel evaluation using rayon\n            self.particles.par_iter_mut().try_for_each(|particle| {\n                particle.fitness = problem.evaluate(&particle.position)\n                    .map_err(|_| SwarmError::FitnessEvaluationError(\"Evaluation failed\".to_string()))?;\n                Ok::<(), SwarmError>(())\n            })?;\n        } else {\n            // Sequential evaluation\n            for particle in &mut self.particles {\n                particle.fitness = problem.evaluate(&particle.position)\n                    .map_err(|_| SwarmError::FitnessEvaluationError(\"Evaluation failed\".to_string()))?;\n            }\n        }\n        \n        Ok(())\n    }\n    \n    /// Update personal best positions\n    fn update_personal_bests(&mut self) {\n        for particle in &mut self.particles {\n            particle.update_personal_best();\n        }\n    }\n    \n    /// Update neighborhood best positions\n    fn update_neighborhood_bests(&mut self) {\n        for i in 0..self.particles.len() {\n            let neighborhood = &self.neighborhoods[i];\n            \n            let mut best_fitness = Float::INFINITY;\n            let mut best_position = self.particles[i].position.clone();\n            \n            for &neighbor_idx in neighborhood {\n                if self.particles[neighbor_idx].personal_best_fitness < best_fitness {\n                    best_fitness = self.particles[neighbor_idx].personal_best_fitness;\n                    best_position = self.particles[neighbor_idx].personal_best.clone();\n                }\n            }\n            \n            self.particles[i].neighborhood_best = best_position;\n            self.particles[i].neighborhood_best_fitness = best_fitness;\n        }\n    }\n    \n    /// Update global best position\n    fn update_global_best(&mut self) {\n        for particle in &self.particles {\n            if particle.personal_best_fitness < self.global_best_fitness {\n                self.global_best = particle.personal_best.clone();\n                self.global_best_fitness = particle.personal_best_fitness;\n            }\n        }\n    }\n    \n    /// Update particle velocities and positions\n    async fn update_particles(&mut self, problem: &OptimizationProblem) -> Result<()> {\n        let bounds = problem.bounds();\n        let max_iterations = self.params.common.max_evaluations / self.params.common.population_size;\n        \n        for particle in &mut self.particles {\n            particle.update_velocity(\n                &self.global_best,\n                &self.params,\n                &mut *self.rng,\n                self.iteration,\n                max_iterations,\n            )?;\n            \n            particle.update_position(bounds, &self.params);\n        }\n        \n        Ok(())\n    }\n    \n    /// Setup neighborhood topology\n    fn setup_topology(&mut self) {\n        let pop_size = self.params.common.population_size;\n        self.neighborhoods = vec![Vec::new(); pop_size];\n        \n        match self.params.topology {\n            Topology::Global => {\n                // Every particle connected to every other particle\n                for i in 0..pop_size {\n                    self.neighborhoods[i] = (0..pop_size).collect();\n                }\n            }\n            Topology::Ring => {\n                // Ring topology: each particle connected to k neighbors\n                let k = self.params.min_neighborhood_size.max(2);\n                for i in 0..pop_size {\n                    for j in 1..=k {\n                        self.neighborhoods[i].push((i + j) % pop_size);\n                        self.neighborhoods[i].push((i + pop_size - j) % pop_size);\n                    }\n                }\n            }\n            Topology::VonNeumann => {\n                // 2D grid topology (simplified)\n                let side = (pop_size as Float).sqrt() as usize;\n                for i in 0..pop_size {\n                    let row = i / side;\n                    let col = i % side;\n                    \n                    // Add 4 neighbors (up, down, left, right)\n                    if row > 0 { self.neighborhoods[i].push((row - 1) * side + col); }\n                    if row < side - 1 { self.neighborhoods[i].push((row + 1) * side + col); }\n                    if col > 0 { self.neighborhoods[i].push(row * side + col - 1); }\n                    if col < side - 1 { self.neighborhoods[i].push(row * side + col + 1); }\n                }\n            }\n            Topology::Random { k } => {\n                // Random k-connected topology\n                for i in 0..pop_size {\n                    let mut neighbors: Vec<usize> = (0..pop_size).filter(|&x| x != i).collect();\n                    neighbors.shuffle(&mut *self.rng);\n                    self.neighborhoods[i] = neighbors.into_iter().take(k).collect();\n                }\n            }\n            Topology::Cluster { clusters } => {\n                // Hierarchical clustering (simplified)\n                let cluster_size = pop_size / clusters;\n                for i in 0..pop_size {\n                    let cluster_id = i / cluster_size;\n                    let cluster_start = cluster_id * cluster_size;\n                    let cluster_end = ((cluster_id + 1) * cluster_size).min(pop_size);\n                    \n                    self.neighborhoods[i] = (cluster_start..cluster_end).collect();\n                }\n            }\n        }\n    }\n    \n    /// Maintain population diversity\n    fn maintain_diversity(&mut self) {\n        let diversity = self.population_diversity();\n        \n        if diversity < self.params.diversity_threshold {\n            // Re-initialize worst particles\n            let num_reinit = (self.params.common.population_size as Float * 0.1) as usize;\n            \n            // Sort particles by fitness (worst first)\n            let mut indices: Vec<usize> = (0..self.particles.len()).collect();\n            indices.sort_by(|&a, &b| {\n                self.particles[b].fitness.partial_cmp(&self.particles[a].fitness).unwrap()\n            });\n            \n            // Re-initialize worst particles\n            if let Some(ref problem) = self.problem {\n                let bounds = problem.bounds();\n                let dimensions = problem.dimensions();\n                \n                for &idx in indices.iter().take(num_reinit) {\n                    self.particles[idx].position = DVector::from_fn(dimensions, |i, _| {\n                        let (min, max) = bounds[i];\n                        self.rng.gen_range(min..=max)\n                    });\n                    self.particles[idx].velocity = DVector::zeros(dimensions);\n                }\n            }\n        }\n    }\n    \n    /// Update elite archive\n    fn update_elite_archive(&mut self) {\n        let elite_size = (self.params.common.population_size as Float * self.params.common.elite_ratio) as usize;\n        \n        // Add current best particles to archive\n        for particle in &self.particles {\n            if particle.fitness < Float::INFINITY {\n                self.elite_archive.push((particle.position.clone(), particle.fitness));\n            }\n        }\n        \n        // Sort and keep only elite_size best\n        self.elite_archive.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap());\n        self.elite_archive.truncate(elite_size);\n    }\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use crate::core::OptimizationProblem;\n    use approx::assert_relative_eq;\n    \n    #[tokio::test]\n    async fn test_pso_creation() {\n        let params = PsoParameters::default();\n        let pso = ParticleSwarmOptimization::new(params).unwrap();\n        assert_eq!(pso.name(), \"Particle Swarm Optimization\");\n    }\n    \n    #[tokio::test]\n    async fn test_pso_sphere_function() {\n        let params = PsoParameters {\n            common: CommonParameters {\n                population_size: 20,\n                max_evaluations: 1000,\n                tolerance: 1e-3,\n                ..Default::default()\n            },\n            ..Default::default()\n        };\n        \n        let mut pso = ParticleSwarmOptimization::new(params).unwrap();\n        \n        // Sphere function: f(x) = sum(x_i^2)\n        let problem = OptimizationProblem::new(\n            10, // dimensions\n            vec![(-5.0, 5.0); 10], // bounds\n            Box::new(|x: &DVector<Float>| {\n                Ok(x.iter().map(|xi| xi * xi).sum())\n            }),\n        );\n        \n        pso.initialize(problem).await.unwrap();\n        \n        let result = pso.optimize(100).await.unwrap();\n        \n        // Should find global minimum near zero\n        assert!(result.best_fitness < 1e-2);\n        assert_eq!(result.iterations, 100);\n    }\n    \n    #[test]\n    fn test_particle_creation() {\n        let mut rng = rand::thread_rng();\n        let bounds = vec![(-10.0, 10.0), (-5.0, 5.0)];\n        \n        let particle = Particle::new(0, 2, &bounds, &mut rng);\n        \n        assert_eq!(particle.id, 0);\n        assert_eq!(particle.position.len(), 2);\n        assert_eq!(particle.velocity.len(), 2);\n        assert!(particle.position[0] >= -10.0 && particle.position[0] <= 10.0);\n        assert!(particle.position[1] >= -5.0 && particle.position[1] <= 5.0);\n    }\n    \n    #[test]\n    fn test_velocity_update() {\n        let mut rng = rand::thread_rng();\n        let bounds = vec![(-10.0, 10.0); 2];\n        let mut particle = Particle::new(0, 2, &bounds, &mut rng);\n        \n        let global_best = DVector::from_vec(vec![1.0, 2.0]);\n        let params = PsoParameters::default();\n        \n        particle.update_velocity(&global_best, &params, &mut rng, 1, 100).unwrap();\n        \n        // Velocity should have been updated (non-zero)\n        assert!(particle.velocity.norm() > 0.0);\n    }\n    \n    #[test]\n    fn test_boundary_handling() {\n        let mut rng = rand::thread_rng();\n        let bounds = vec![(-1.0, 1.0); 2];\n        let mut particle = Particle::new(0, 2, &bounds, &mut rng);\n        \n        // Set particle outside bounds\n        particle.position = DVector::from_vec(vec![2.0, -2.0]);\n        particle.velocity = DVector::from_vec(vec![1.0, -1.0]);\n        \n        let params = PsoParameters {\n            boundary_handling: BoundaryHandlingStrategy::Reflect,\n            ..Default::default()\n        };\n        \n        particle.handle_boundaries(&bounds, &params);\n        \n        // Position should be within bounds\n        assert!(particle.position[0] >= -1.0 && particle.position[0] <= 1.0);\n        assert!(particle.position[1] >= -1.0 && particle.position[1] <= 1.0);\n    }\n    \n    #[test]\n    fn test_population_diversity() {\n        let params = PsoParameters::default();\n        let mut pso = ParticleSwarmOptimization::new(params).unwrap();\n        \n        // Create particles with known positions\n        pso.particles = vec![\n            Particle {\n                position: DVector::from_vec(vec![0.0, 0.0]),\n                velocity: DVector::zeros(2),\n                personal_best: DVector::zeros(2),\n                personal_best_fitness: 0.0,\n                fitness: 0.0,\n                neighborhood_best: DVector::zeros(2),\n                neighborhood_best_fitness: 0.0,\n                id: 0,\n                stagnation_count: 0,\n                success_rate: 0.0,\n            },\n            Particle {\n                position: DVector::from_vec(vec![1.0, 1.0]),\n                velocity: DVector::zeros(2),\n                personal_best: DVector::zeros(2),\n                personal_best_fitness: 0.0,\n                fitness: 0.0,\n                neighborhood_best: DVector::zeros(2),\n                neighborhood_best_fitness: 0.0,\n                id: 1,\n                stagnation_count: 0,\n                success_rate: 0.0,\n            },\n        ];\n        \n        let diversity = pso.population_diversity();\n        \n        // Diversity should be the average distance between particles\n        let expected_diversity = 2.0_f64.sqrt(); // Distance between (0,0) and (1,1)\n        assert_relative_eq!(diversity, expected_diversity, epsilon = 1e-10);\n    }\n}"