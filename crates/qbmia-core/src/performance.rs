//! Performance monitoring and optimization for QBMIA\n\nuse serde::{Deserialize, Serialize};\nuse std::time::{Duration, Instant};\nuse std::collections::VecDeque;\nuse parking_lot::RwLock;\nuse std::sync::Arc;\n\n/// Performance metrics collection\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PerformanceMetrics {\n    processing_times: Arc<RwLock<VecDeque<Duration>>>,\n    total_operations: Arc<RwLock<u64>>,\n    average_latency: Arc<RwLock<Duration>>,\n    peak_latency: Arc<RwLock<Duration>>,\n    min_latency: Arc<RwLock<Duration>>,\n    throughput: Arc<RwLock<f64>>,\n    memory_usage: Arc<RwLock<usize>>,\n    error_count: Arc<RwLock<u64>>,\n    last_reset: Arc<RwLock<Instant>>,\n    window_size: usize,\n}\n\nimpl PerformanceMetrics {\n    /// Create new performance metrics\n    pub fn new() -> Self {\n        Self {\n            processing_times: Arc::new(RwLock::new(VecDeque::with_capacity(1000))),\n            total_operations: Arc::new(RwLock::new(0)),\n            average_latency: Arc::new(RwLock::new(Duration::from_nanos(0))),\n            peak_latency: Arc::new(RwLock::new(Duration::from_nanos(0))),\n            min_latency: Arc::new(RwLock::new(Duration::from_secs(1))),\n            throughput: Arc::new(RwLock::new(0.0)),\n            memory_usage: Arc::new(RwLock::new(0)),\n            error_count: Arc::new(RwLock::new(0)),\n            last_reset: Arc::new(RwLock::new(Instant::now())),\n            window_size: 1000,\n        }\n    }\n\n    /// Record processing time for an operation\n    pub fn record_processing_time(&self, duration: Duration) {\n        let mut times = self.processing_times.write();\n        let mut total = self.total_operations.write();\n        \n        // Add new duration\n        times.push_back(duration);\n        *total += 1;\n        \n        // Maintain window size\n        if times.len() > self.window_size {\n            times.pop_front();\n        }\n        \n        // Update peak latency\n        {\n            let mut peak = self.peak_latency.write();\n            if duration > *peak {\n                *peak = duration;\n            }\n        }\n        \n        // Update min latency\n        {\n            let mut min = self.min_latency.write();\n            if duration < *min {\n                *min = duration;\n            }\n        }\n        \n        // Update average latency\n        {\n            let mut avg = self.average_latency.write();\n            let sum: Duration = times.iter().sum();\n            *avg = sum / times.len() as u32;\n        }\n        \n        // Update throughput (operations per second)\n        {\n            let mut throughput = self.throughput.write();\n            let elapsed = self.last_reset.read().elapsed();\n            if elapsed.as_secs() > 0 {\n                *throughput = *total as f64 / elapsed.as_secs_f64();\n            }\n        }\n    }\n\n    /// Record error occurrence\n    pub fn record_error(&self) {\n        let mut errors = self.error_count.write();\n        *errors += 1;\n    }\n\n    /// Update memory usage\n    pub fn update_memory_usage(&self, bytes: usize) {\n        let mut memory = self.memory_usage.write();\n        *memory = bytes;\n    }\n\n    /// Get total processing count\n    pub fn total_processing_count(&self) -> u64 {\n        *self.total_operations.read()\n    }\n\n    /// Get average latency\n    pub fn average_latency(&self) -> Duration {\n        *self.average_latency.read()\n    }\n\n    /// Get peak latency\n    pub fn peak_latency(&self) -> Duration {\n        *self.peak_latency.read()\n    }\n\n    /// Get minimum latency\n    pub fn min_latency(&self) -> Duration {\n        *self.min_latency.read()\n    }\n\n    /// Get current throughput (ops/sec)\n    pub fn throughput(&self) -> f64 {\n        *self.throughput.read()\n    }\n\n    /// Get current memory usage in bytes\n    pub fn memory_usage(&self) -> usize {\n        *self.memory_usage.read()\n    }\n\n    /// Get error count\n    pub fn error_count(&self) -> u64 {\n        *self.error_count.read()\n    }\n\n    /// Check if performance meets sub-100ms requirement\n    pub fn meets_latency_requirement(&self) -> bool {\n        self.average_latency().as_millis() < 100\n    }\n\n    /// Get performance percentiles\n    pub fn get_percentiles(&self) -> PerformancePercentiles {\n        let times = self.processing_times.read();\n        if times.is_empty() {\n            return PerformancePercentiles::default();\n        }\n        \n        let mut sorted_times: Vec<Duration> = times.iter().cloned().collect();\n        sorted_times.sort();\n        \n        let len = sorted_times.len();\n        let p50_idx = len / 2;\n        let p95_idx = (len as f64 * 0.95) as usize;\n        let p99_idx = (len as f64 * 0.99) as usize;\n        \n        PerformancePercentiles {\n            p50: sorted_times.get(p50_idx).cloned().unwrap_or_default(),\n            p95: sorted_times.get(p95_idx).cloned().unwrap_or_default(),\n            p99: sorted_times.get(p99_idx).cloned().unwrap_or_default(),\n        }\n    }\n\n    /// Reset all metrics\n    pub fn reset(&self) {\n        self.processing_times.write().clear();\n        *self.total_operations.write() = 0;\n        *self.average_latency.write() = Duration::from_nanos(0);\n        *self.peak_latency.write() = Duration::from_nanos(0);\n        *self.min_latency.write() = Duration::from_secs(1);\n        *self.throughput.write() = 0.0;\n        *self.error_count.write() = 0;\n        *self.last_reset.write() = Instant::now();\n    }\n\n    /// Get comprehensive performance report\n    pub fn get_performance_report(&self) -> PerformanceReport {\n        let percentiles = self.get_percentiles();\n        \n        PerformanceReport {\n            total_operations: self.total_processing_count(),\n            average_latency_ms: self.average_latency().as_millis() as f64,\n            peak_latency_ms: self.peak_latency().as_millis() as f64,\n            min_latency_ms: self.min_latency().as_millis() as f64,\n            throughput_ops_per_sec: self.throughput(),\n            memory_usage_bytes: self.memory_usage(),\n            error_count: self.error_count(),\n            error_rate: if self.total_processing_count() > 0 {\n                self.error_count() as f64 / self.total_processing_count() as f64\n            } else {\n                0.0\n            },\n            percentiles,\n            meets_latency_sla: self.meets_latency_requirement(),\n            uptime_seconds: self.last_reset.read().elapsed().as_secs(),\n        }\n    }\n}\n\nimpl Default for PerformanceMetrics {\n    fn default() -> Self {\n        Self::new()\n    }\n}\n\n/// Performance percentiles\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PerformancePercentiles {\n    pub p50: Duration,\n    pub p95: Duration,\n    pub p99: Duration,\n}\n\nimpl Default for PerformancePercentiles {\n    fn default() -> Self {\n        Self {\n            p50: Duration::from_nanos(0),\n            p95: Duration::from_nanos(0),\n            p99: Duration::from_nanos(0),\n        }\n    }\n}\n\n/// Comprehensive performance report\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct PerformanceReport {\n    pub total_operations: u64,\n    pub average_latency_ms: f64,\n    pub peak_latency_ms: f64,\n    pub min_latency_ms: f64,\n    pub throughput_ops_per_sec: f64,\n    pub memory_usage_bytes: usize,\n    pub error_count: u64,\n    pub error_rate: f64,\n    pub percentiles: PerformancePercentiles,\n    pub meets_latency_sla: bool,\n    pub uptime_seconds: u64,\n}\n\n/// Performance optimizer for QBMIA operations\n#[derive(Debug)]\npub struct PerformanceOptimizer {\n    target_latency_ms: u64,\n    optimization_level: u8,\n    simd_enabled: bool,\n    batch_size: usize,\n    cache_size: usize,\n}\n\nimpl PerformanceOptimizer {\n    /// Create new performance optimizer\n    pub fn new(target_latency_ms: u64, optimization_level: u8, simd_enabled: bool) -> Self {\n        Self {\n            target_latency_ms,\n            optimization_level,\n            simd_enabled,\n            batch_size: match optimization_level {\n                0 => 1,\n                1 => 4,\n                2 => 8,\n                3 => 16,\n                _ => 8,\n            },\n            cache_size: match optimization_level {\n                0 => 100,\n                1 => 500,\n                2 => 1000,\n                3 => 2000,\n                _ => 1000,\n            },\n        }\n    }\n\n    /// Optimize data processing based on current performance\n    pub fn optimize_processing(&self, data: &[f64], metrics: &PerformanceMetrics) -> OptimizedProcessing {\n        let current_latency = metrics.average_latency().as_millis() as u64;\n        \n        // Determine if we need to adjust processing parameters\n        let needs_optimization = current_latency > self.target_latency_ms;\n        \n        let batch_size = if needs_optimization {\n            // Reduce batch size to improve latency\n            (self.batch_size / 2).max(1)\n        } else {\n            // Can afford larger batch for throughput\n            self.batch_size * 2\n        };\n        \n        let use_simd = self.simd_enabled && data.len() >= 4;\n        \n        OptimizedProcessing {\n            batch_size,\n            use_simd,\n            parallel_threads: match self.optimization_level {\n                0 => 1,\n                1 => 2,\n                2 => 4,\n                3 => 8,\n                _ => 4,\n            },\n            cache_hints: self.generate_cache_hints(data),\n            memory_prefetch: self.optimization_level >= 2,\n        }\n    }\n\n    /// Generate cache optimization hints\n    fn generate_cache_hints(&self, data: &[f64]) -> CacheHints {\n        CacheHints {\n            prefetch_size: (data.len() / 4).min(64),\n            cache_line_size: 64,\n            temporal_locality: data.len() < 1000, // Small data has better temporal locality\n            spatial_locality: true,\n        }\n    }\n\n    /// Get recommended configuration for target performance\n    pub fn get_recommended_config(&self, current_metrics: &PerformanceMetrics) -> OptimizationRecommendations {\n        let report = current_metrics.get_performance_report();\n        \n        OptimizationRecommendations {\n            increase_batch_size: report.average_latency_ms < self.target_latency_ms as f64 * 0.5,\n            enable_simd: !self.simd_enabled && report.throughput_ops_per_sec < 1000.0,\n            add_parallel_threads: report.average_latency_ms > self.target_latency_ms as f64,\n            optimize_memory: report.memory_usage_bytes > 1_000_000, // 1MB threshold\n            reduce_precision: report.average_latency_ms > self.target_latency_ms as f64 * 2.0,\n            enable_caching: report.error_rate < 0.01, // Low error rate allows aggressive caching\n        }\n    }\n}\n\n/// Optimized processing configuration\n#[derive(Debug, Clone)]\npub struct OptimizedProcessing {\n    pub batch_size: usize,\n    pub use_simd: bool,\n    pub parallel_threads: usize,\n    pub cache_hints: CacheHints,\n    pub memory_prefetch: bool,\n}\n\n/// Cache optimization hints\n#[derive(Debug, Clone)]\npub struct CacheHints {\n    pub prefetch_size: usize,\n    pub cache_line_size: usize,\n    pub temporal_locality: bool,\n    pub spatial_locality: bool,\n}\n\n/// Optimization recommendations\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct OptimizationRecommendations {\n    pub increase_batch_size: bool,\n    pub enable_simd: bool,\n    pub add_parallel_threads: bool,\n    pub optimize_memory: bool,\n    pub reduce_precision: bool,\n    pub enable_caching: bool,\n}\n\n#[cfg(test)]\nmod tests {\n    use super::*;\n    use std::thread::sleep;\n\n    #[test]\n    fn test_performance_metrics_creation() {\n        let metrics = PerformanceMetrics::new();\n        assert_eq!(metrics.total_processing_count(), 0);\n        assert!(metrics.meets_latency_requirement()); // Initially true\n    }\n\n    #[test]\n    fn test_performance_recording() {\n        let metrics = PerformanceMetrics::new();\n        \n        metrics.record_processing_time(Duration::from_millis(50));\n        metrics.record_processing_time(Duration::from_millis(75));\n        \n        assert_eq!(metrics.total_processing_count(), 2);\n        assert!(metrics.average_latency().as_millis() > 0);\n        assert!(metrics.meets_latency_requirement());\n    }\n\n    #[test]\n    fn test_latency_requirement_check() {\n        let metrics = PerformanceMetrics::new();\n        \n        // Record high latency\n        metrics.record_processing_time(Duration::from_millis(150));\n        \n        assert!(!metrics.meets_latency_requirement());\n    }\n\n    #[test]\n    fn test_percentiles_calculation() {\n        let metrics = PerformanceMetrics::new();\n        \n        // Record various latencies\n        for i in 1..=100 {\n            metrics.record_processing_time(Duration::from_millis(i));\n        }\n        \n        let percentiles = metrics.get_percentiles();\n        assert!(percentiles.p50.as_millis() > 0);\n        assert!(percentiles.p95.as_millis() > percentiles.p50.as_millis());\n        assert!(percentiles.p99.as_millis() > percentiles.p95.as_millis());\n    }\n\n    #[test]\n    fn test_performance_optimizer() {\n        let optimizer = PerformanceOptimizer::new(100, 2, true);\n        let metrics = PerformanceMetrics::new();\n        \n        let data = vec![1.0; 1000];\n        let optimization = optimizer.optimize_processing(&data, &metrics);\n        \n        assert!(optimization.batch_size > 0);\n        assert!(optimization.use_simd);\n    }\n\n    #[test]\n    fn test_optimization_recommendations() {\n        let optimizer = PerformanceOptimizer::new(50, 3, false);\n        let metrics = PerformanceMetrics::new();\n        \n        // Simulate slow performance\n        metrics.record_processing_time(Duration::from_millis(200));\n        \n        let recommendations = optimizer.get_recommended_config(&metrics);\n        assert!(recommendations.enable_simd); // Should recommend SIMD for better performance\n    }\n\n    #[test]\n    fn test_performance_report() {\n        let metrics = PerformanceMetrics::new();\n        \n        metrics.record_processing_time(Duration::from_millis(25));\n        metrics.record_processing_time(Duration::from_millis(75));\n        metrics.record_error();\n        metrics.update_memory_usage(1024);\n        \n        let report = metrics.get_performance_report();\n        assert_eq!(report.total_operations, 2);\n        assert_eq!(report.error_count, 1);\n        assert_eq!(report.memory_usage_bytes, 1024);\n        assert!(report.meets_latency_sla);\n    }\n}\n"