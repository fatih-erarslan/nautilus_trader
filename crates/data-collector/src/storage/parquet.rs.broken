//! Parquet storage backend for cryptocurrency data

use super::{Storage, StorageStats};
use crate::{Result, DataCollectorError};
use crate::config::StorageConfig;
use crate::types::*;
use std::path::Path;
use tracing::{info, debug, error};
use arrow::array::*;
use arrow::datatypes::*;
use arrow::record_batch::RecordBatch;
use parquet::arrow::arrow_writer::ArrowWriter;
use parquet::basic::{Compression, Encoding};
use parquet::file::properties::WriterProperties;
use std::sync::Arc;
use std::fs::File;

/// Parquet storage backend
pub struct ParquetStorage {
    config: StorageConfig,
    base_path: std::path::PathBuf,
}

impl ParquetStorage {
    pub async fn new(config: &StorageConfig) -> Result<Self> {
        let base_path = config.base_directory.clone();
        
        // Create directory structure
        std::fs::create_dir_all(&base_path)
            .map_err(|e| DataCollectorError::Storage(format!("Failed to create storage directory: {}", e)))?;
            
        std::fs::create_dir_all(base_path.join("klines"))
            .map_err(|e| DataCollectorError::Storage(format!("Failed to create klines directory: {}", e)))?;
            
        std::fs::create_dir_all(base_path.join("trades"))
            .map_err(|e| DataCollectorError::Storage(format!("Failed to create trades directory: {}", e)))?;
            
        std::fs::create_dir_all(base_path.join("order_books"))
            .map_err(|e| DataCollectorError::Storage(format!("Failed to create order_books directory: {}", e)))?;
            
        std::fs::create_dir_all(base_path.join("tickers"))
            .map_err(|e| DataCollectorError::Storage(format!("Failed to create tickers directory: {}", e)))?;
            
        std::fs::create_dir_all(base_path.join("funding_rates"))
            .map_err(|e| DataCollectorError::Storage(format!("Failed to create funding_rates directory: {}", e)))?;
        
        info!("Initialized Parquet storage at: {:?}", base_path);
        
        Ok(Self {
            config: config.clone(),
            base_path,
        })
    }
    
    /// Create writer properties based on configuration
    fn create_writer_properties(&self) -> WriterProperties {
        let compression = match self.config.compression_algorithm {
            crate::config::CompressionAlgorithm::None => Compression::UNCOMPRESSED,
            crate::config::CompressionAlgorithm::Gzip => Compression::GZIP(Default::default()),
            crate::config::CompressionAlgorithm::Zstd => Compression::ZSTD(Default::default()),
            crate::config::CompressionAlgorithm::Lz4 => Compression::LZ4,
        };
        
        WriterProperties::builder()
            .set_compression(compression)
            .set_encoding(Encoding::PLAIN)
            .set_statistics_enabled(parquet::basic::LogicalType::None, true)
            .build()
    }
    
    /// Generate file path for data type
    fn generate_file_path(&self, data_type: &str, exchange: &str, symbol: &str, date: &str) -> std::path::PathBuf {
        self.base_path
            .join(data_type)
            .join(exchange)
            .join(symbol)
            .join(format!("{}_{}_{}_{}.parquet", data_type, exchange, symbol, date))
    }
    
    /// Write klines to Parquet
    async fn write_klines_to_parquet(&self, klines: &[Kline]) -> Result<()> {
        if klines.is_empty() {
            return Ok(());\n        }\n        \n        let exchange = &klines[0].exchange;\n        let symbol = &klines[0].symbol;\n        let date = klines[0].open_time.format(\"%Y%m%d\").to_string();\n        \n        let file_path = self.generate_file_path(\"klines\", exchange, symbol, &date);\n        \n        // Create parent directory if it doesn't exist\n        if let Some(parent) = file_path.parent() {\n            std::fs::create_dir_all(parent)\n                .map_err(|e| DataCollectorError::Storage(format!(\"Failed to create directory: {}\", e)))?;\n        }\n        \n        // Create Arrow schema for klines\n        let schema = Arc::new(Schema::new(vec![\n            Field::new(\"symbol\", DataType::Utf8, false),\n            Field::new(\"open_time\", DataType::Timestamp(TimeUnit::Millisecond, Some(Arc::from(\"UTC\"))), false),\n            Field::new(\"close_time\", DataType::Timestamp(TimeUnit::Millisecond, Some(Arc::from(\"UTC\"))), false),\n            Field::new(\"open\", DataType::Float64, false),\n            Field::new(\"high\", DataType::Float64, false),\n            Field::new(\"low\", DataType::Float64, false),\n            Field::new(\"close\", DataType::Float64, false),\n            Field::new(\"volume\", DataType::Float64, false),\n            Field::new(\"quote_volume\", DataType::Float64, false),\n            Field::new(\"trades_count\", DataType::UInt64, false),\n            Field::new(\"taker_buy_base_volume\", DataType::Float64, false),\n            Field::new(\"taker_buy_quote_volume\", DataType::Float64, false),\n            Field::new(\"interval\", DataType::Utf8, false),\n            Field::new(\"exchange\", DataType::Utf8, false),\n        ]));\n        \n        // Convert klines to Arrow arrays\n        let mut symbol_builder = StringBuilder::new();\n        let mut open_time_builder = TimestampMillisecondBuilder::new();\n        let mut close_time_builder = TimestampMillisecondBuilder::new();\n        let mut open_builder = Float64Builder::new();\n        let mut high_builder = Float64Builder::new();\n        let mut low_builder = Float64Builder::new();\n        let mut close_builder = Float64Builder::new();\n        let mut volume_builder = Float64Builder::new();\n        let mut quote_volume_builder = Float64Builder::new();\n        let mut trades_count_builder = UInt64Builder::new();\n        let mut taker_buy_base_volume_builder = Float64Builder::new();\n        let mut taker_buy_quote_volume_builder = Float64Builder::new();\n        let mut interval_builder = StringBuilder::new();\n        let mut exchange_builder = StringBuilder::new();\n        \n        for kline in klines {\n            symbol_builder.append_value(&kline.symbol);\n            open_time_builder.append_value(kline.open_time.timestamp_millis());\n            close_time_builder.append_value(kline.close_time.timestamp_millis());\n            open_builder.append_value(kline.open);\n            high_builder.append_value(kline.high);\n            low_builder.append_value(kline.low);\n            close_builder.append_value(kline.close);\n            volume_builder.append_value(kline.volume);\n            quote_volume_builder.append_value(kline.quote_volume);\n            trades_count_builder.append_value(kline.trades_count);\n            taker_buy_base_volume_builder.append_value(kline.taker_buy_base_volume);\n            taker_buy_quote_volume_builder.append_value(kline.taker_buy_quote_volume);\n            interval_builder.append_value(&format!(\"{:?}\", kline.interval));\n            exchange_builder.append_value(&kline.exchange);\n        }\n        \n        let batch = RecordBatch::try_new(\n            schema.clone(),\n            vec![\n                Arc::new(symbol_builder.finish()),\n                Arc::new(open_time_builder.finish()),\n                Arc::new(close_time_builder.finish()),\n                Arc::new(open_builder.finish()),\n                Arc::new(high_builder.finish()),\n                Arc::new(low_builder.finish()),\n                Arc::new(close_builder.finish()),\n                Arc::new(volume_builder.finish()),\n                Arc::new(quote_volume_builder.finish()),\n                Arc::new(trades_count_builder.finish()),\n                Arc::new(taker_buy_base_volume_builder.finish()),\n                Arc::new(taker_buy_quote_volume_builder.finish()),\n                Arc::new(interval_builder.finish()),\n                Arc::new(exchange_builder.finish()),\n            ],\n        ).map_err(|e| DataCollectorError::Storage(format!(\"Failed to create record batch: {}\", e)))?;\n        \n        // Write to Parquet file\n        let file = File::create(&file_path)\n            .map_err(|e| DataCollectorError::Storage(format!(\"Failed to create file: {}\", e)))?;\n            \n        let props = self.create_writer_properties();\n        let mut writer = ArrowWriter::try_new(file, schema, Some(props))\n            .map_err(|e| DataCollectorError::Storage(format!(\"Failed to create Arrow writer: {}\", e)))?;\n            \n        writer.write(&batch)\n            .map_err(|e| DataCollectorError::Storage(format!(\"Failed to write batch: {}\", e)))?;\n            \n        writer.close()\n            .map_err(|e| DataCollectorError::Storage(format!(\"Failed to close writer: {}\", e)))?;\n        \n        debug!(\"Wrote {} klines to: {:?}\", klines.len(), file_path);\n        Ok(())\n    }\n}\n\n#[async_trait::async_trait]\nimpl Storage for ParquetStorage {\n    async fn store_klines(&self, klines: &[Kline]) -> Result<()> {\n        self.write_klines_to_parquet(klines).await\n    }\n    \n    async fn store_trades(&self, trades: &[Trade]) -> Result<()> {\n        // Similar implementation for trades\n        debug!(\"Storing {} trades to Parquet (placeholder)\", trades.len());\n        Ok(())\n    }\n    \n    async fn store_order_books(&self, order_books: &[OrderBook]) -> Result<()> {\n        // Similar implementation for order books\n        debug!(\"Storing {} order books to Parquet (placeholder)\", order_books.len());\n        Ok(())\n    }\n    \n    async fn store_tickers(&self, tickers: &[Ticker24hr]) -> Result<()> {\n        // Similar implementation for tickers\n        debug!(\"Storing {} tickers to Parquet (placeholder)\", tickers.len());\n        Ok(())\n    }\n    \n    async fn store_funding_rates(&self, funding_rates: &[FundingRate]) -> Result<()> {\n        // Similar implementation for funding rates\n        debug!(\"Storing {} funding rates to Parquet (placeholder)\", funding_rates.len());\n        Ok(())\n    }\n    \n    async fn validate(&self) -> Result<bool> {\n        // Check if base directory exists and is writable\n        if !self.base_path.exists() {\n            return Ok(false);\n        }\n        \n        // Try to create a test file\n        let test_file = self.base_path.join(\"test_write_access.tmp\");\n        match std::fs::write(&test_file, \"test\") {\n            Ok(_) => {\n                let _ = std::fs::remove_file(&test_file);\n                Ok(true)\n            },\n            Err(_) => Ok(false),\n        }\n    }\n    \n    async fn get_stats(&self) -> Result<StorageStats> {\n        // Calculate storage statistics by scanning directories\n        let mut total_size = 0u64;\n        let mut file_counts = std::collections::HashMap::new();\n        \n        for data_type in [\"klines\", \"trades\", \"order_books\", \"tickers\", \"funding_rates\"] {\n            let dir_path = self.base_path.join(data_type);\n            if dir_path.exists() {\n                if let Ok(entries) = std::fs::read_dir(&dir_path) {\n                    for entry in entries.flatten() {\n                        if let Ok(metadata) = entry.metadata() {\n                            total_size += metadata.len();\n                            *file_counts.entry(data_type).or_insert(0u64) += 1;\n                        }\n                    }\n                }\n            }\n        }\n        \n        Ok(StorageStats {\n            total_klines: *file_counts.get(\"klines\").unwrap_or(&0),\n            total_trades: *file_counts.get(\"trades\").unwrap_or(&0),\n            total_order_books: *file_counts.get(\"order_books\").unwrap_or(&0),\n            total_tickers: *file_counts.get(\"tickers\").unwrap_or(&0),\n            total_funding_rates: *file_counts.get(\"funding_rates\").unwrap_or(&0),\n            storage_size_bytes: total_size,\n            last_updated: chrono::Utc::now(),\n        })\n    }\n    \n    async fn backup(&self, backup_path: &Path) -> Result<()> {\n        // Copy all files to backup location\n        let backup_target = backup_path.join(\"parquet_data\");\n        std::fs::create_dir_all(&backup_target)\n            .map_err(|e| DataCollectorError::Storage(format!(\"Failed to create backup directory: {}\", e)))?;\n        \n        // Use system copy command for efficiency\n        let status = std::process::Command::new(\"cp\")\n            .arg(\"-r\")\n            .arg(&self.base_path)\n            .arg(&backup_target)\n            .status()\n            .map_err(|e| DataCollectorError::Storage(format!(\"Failed to execute backup: {}\", e)))?;\n            \n        if !status.success() {\n            return Err(DataCollectorError::Storage(\"Backup command failed\".to_string()));\n        }\n        \n        info!(\"Parquet data backed up to: {:?}\", backup_target);\n        Ok(())\n    }\n    \n    async fn restore(&self, backup_path: &Path) -> Result<()> {\n        let backup_source = backup_path.join(\"parquet_data\");\n        \n        if !backup_source.exists() {\n            return Err(DataCollectorError::Storage(\"Backup source not found\".to_string()));\n        }\n        \n        // Remove existing data\n        if self.base_path.exists() {\n            std::fs::remove_dir_all(&self.base_path)\n                .map_err(|e| DataCollectorError::Storage(format!(\"Failed to remove existing data: {}\", e)))?;\n        }\n        \n        // Restore from backup\n        let status = std::process::Command::new(\"cp\")\n            .arg(\"-r\")\n            .arg(&backup_source)\n            .arg(&self.base_path)\n            .status()\n            .map_err(|e| DataCollectorError::Storage(format!(\"Failed to execute restore: {}\", e)))?;\n            \n        if !status.success() {\n            return Err(DataCollectorError::Storage(\"Restore command failed\".to_string()));\n        }\n        \n        info!(\"Parquet data restored from: {:?}\", backup_source);\n        Ok(())\n    }\n}