// Network I/O Optimizer for Real-Time Data Feeds
// Copyright (c) 2025 TENGRI Trading Swarm - Performance-Optimizer Agent

use std::collections::HashMap;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::net::{TcpStream, UdpSocket};
use tokio::sync::{RwLock, Semaphore};
use tokio_tungstenite::{WebSocketStream, MaybeTlsStream};
use futures_util::{SinkExt, StreamExt};
use anyhow::Result;
use tracing::{info, debug, warn, error};
use serde::{Deserialize, Serialize};
use crate::AnalyzerError;
use crate::performance::memory_pool::MemoryPool;

/// Network I/O configuration for optimal performance
#[derive(Debug, Clone)]
pub struct NetworkConfig {
    /// Maximum concurrent connections
    pub max_connections: usize,
    /// Connection timeout in milliseconds
    pub connection_timeout_ms: u64,
    /// Read timeout in milliseconds
    pub read_timeout_ms: u64,
    /// Write timeout in milliseconds
    pub write_timeout_ms: u64,
    /// Buffer size for I/O operations
    pub buffer_size: usize,
    /// Enable TCP_NODELAY
    pub tcp_nodelay: bool,
    /// Enable SO_KEEPALIVE
    pub keepalive: bool,
    /// Keepalive interval in seconds
    pub keepalive_interval: u64,
    /// Maximum retries for failed connections
    pub max_retries: u32,
    /// Retry delay in milliseconds
    pub retry_delay_ms: u64,
    /// Enable compression
    pub compression_enabled: bool,
    /// Compression level (1-9)
    pub compression_level: u32,
    /// Enable SSL/TLS
    pub tls_enabled: bool,
}

impl Default for NetworkConfig {
    fn default() -> Self {
        Self {
            max_connections: 1000,
            connection_timeout_ms: 100,
            read_timeout_ms: 50,
            write_timeout_ms: 50,
            buffer_size: 64 * 1024, // 64KB
            tcp_nodelay: true,
            keepalive: true,
            keepalive_interval: 30,
            max_retries: 3,
            retry_delay_ms: 100,
            compression_enabled: true,
            compression_level: 6,
            tls_enabled: true,
        }
    }
}

/// Network I/O optimizer for high-frequency trading
pub struct NetworkIOOptimizer {
    config: NetworkConfig,
    memory_pool: Arc<MemoryPool>,
    connection_manager: Arc<ConnectionManager>,
    data_compressor: Arc<DataCompressor>,
    message_dispatcher: Arc<MessageDispatcher>,
    performance_monitor: Arc<PerformanceMonitor>,
    connection_semaphore: Arc<Semaphore>,
}

/// Connection manager for efficient connection pooling
#[derive(Debug)]
pub struct ConnectionManager {
    connections: Arc<RwLock<HashMap<String, Connection>>>,
    connection_pool: Arc<RwLock<Vec<PooledConnection>>>,
    config: NetworkConfig,
}

/// Individual connection
#[derive(Debug)]
pub struct Connection {
    pub id: String,
    pub endpoint: String,
    pub connection_type: ConnectionType,
    pub status: ConnectionStatus,
    pub stream: Option<WebSocketStream<MaybeTlsStream<TcpStream>>>,
    pub last_activity: Instant,
    pub bytes_sent: u64,
    pub bytes_received: u64,
    pub messages_sent: u64,
    pub messages_received: u64,
    pub error_count: u32,
    pub latency_stats: LatencyStats,
}

/// Connection type
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ConnectionType {
    WebSocket,
    Tcp,
    Udp,
    Http,
    Https,
}

/// Connection status
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ConnectionStatus {
    Connecting,
    Connected,
    Disconnected,
    Reconnecting,
    Failed,
}

/// Pooled connection for reuse
#[derive(Debug)]
pub struct PooledConnection {
    pub connection: Connection,
    pub in_use: bool,
    pub created_at: Instant,
    pub last_used: Instant,
}

/// Latency statistics
#[derive(Debug, Clone, Default)]
pub struct LatencyStats {
    pub min_latency_ns: u64,
    pub max_latency_ns: u64,
    pub avg_latency_ns: u64,
    pub p95_latency_ns: u64,
    pub p99_latency_ns: u64,
    pub sample_count: u64,
}

/// Data compressor for efficient network transmission
#[derive(Debug)]
pub struct DataCompressor {
    compression_level: u32,
    compression_threshold: usize,
}

/// Message dispatcher for efficient message routing
#[derive(Debug)]
pub struct MessageDispatcher {
    message_queues: Arc<RwLock<HashMap<String, MessageQueue>>>,
    routing_table: Arc<RwLock<HashMap<String, Vec<String>>>>,
}

/// Message queue for buffering
#[derive(Debug)]
pub struct MessageQueue {
    pub messages: Vec<Message>,
    pub max_size: usize,
    pub current_size: usize,
    pub dropped_messages: u64,
}

/// Network message
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Message {
    pub id: String,
    pub timestamp: u64,
    pub source: String,
    pub destination: String,
    pub message_type: MessageType,
    pub payload: Vec<u8>,
    pub priority: MessagePriority,
    pub ttl: u64,
    pub compression: bool,
}

/// Message type
#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum MessageType {
    MarketData,
    OrderUpdate,
    TradeExecution,
    AccountUpdate,
    SystemStatus,
    Heartbeat,
}

/// Message priority
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
pub enum MessagePriority {
    Low,
    Normal,
    High,
    Critical,
}

/// Performance monitor for network operations
#[derive(Debug)]
pub struct PerformanceMonitor {
    metrics: Arc<RwLock<NetworkMetrics>>,
    bandwidth_monitor: Arc<BandwidthMonitor>,
}

/// Network performance metrics
#[derive(Debug, Clone, Default)]
pub struct NetworkMetrics {
    pub total_connections: u64,
    pub active_connections: u64,
    pub failed_connections: u64,
    pub total_bytes_sent: u64,
    pub total_bytes_received: u64,
    pub total_messages_sent: u64,
    pub total_messages_received: u64,
    pub connection_latency_avg: f64,
    pub data_latency_avg: f64,
    pub throughput_mbps: f64,
    pub error_rate: f64,
    pub uptime_percentage: f64,
}

/// Bandwidth monitor
#[derive(Debug)]
pub struct BandwidthMonitor {
    samples: Arc<RwLock<Vec<BandwidthSample>>>,
    current_bandwidth: Arc<RwLock<f64>>,
}

/// Bandwidth sample
#[derive(Debug, Clone)]
pub struct BandwidthSample {
    pub timestamp: Instant,
    pub bytes_per_second: f64,
}

impl NetworkIOOptimizer {
    /// Create new network I/O optimizer
    pub fn new(config: NetworkConfig, memory_pool: Arc<MemoryPool>) -> Result<Self, AnalyzerError> {
        info!("Initializing network I/O optimizer");
        
        let connection_manager = Arc::new(ConnectionManager::new(config.clone()));
        let data_compressor = Arc::new(DataCompressor::new(config.compression_level, 1024));
        let message_dispatcher = Arc::new(MessageDispatcher::new());
        let performance_monitor = Arc::new(PerformanceMonitor::new());
        let connection_semaphore = Arc::new(Semaphore::new(config.max_connections));
        
        Ok(Self {
            config,
            memory_pool,
            connection_manager,
            data_compressor,
            message_dispatcher,
            performance_monitor,
            connection_semaphore,
        })
    }
    
    /// Establish optimized connection
    pub async fn connect(&self, endpoint: &str, connection_type: ConnectionType) -> Result<String, AnalyzerError> {
        debug!("Establishing connection to: {}", endpoint);
        
        // Acquire connection semaphore
        let _permit = self.connection_semaphore.acquire().await
            .map_err(|e| AnalyzerError::NetworkError(e.to_string()))?;
        
        // Check if connection already exists
        if let Some(connection_id) = self.connection_manager.find_connection(endpoint).await? {
            debug!("Reusing existing connection: {}", connection_id);
            return Ok(connection_id);
        }
        
        // Create new connection
        let connection_id = self.create_connection(endpoint, connection_type).await?;
        
        // Update performance metrics
        self.performance_monitor.record_connection_established().await;
        
        info!("Connection established: {} -> {}", connection_id, endpoint);
        Ok(connection_id)
    }
    
    /// Create new connection with optimization
    async fn create_connection(&self, endpoint: &str, connection_type: ConnectionType) -> Result<String, AnalyzerError> {
        let connection_id = format!("conn_{}", uuid::Uuid::new_v4());
        let start_time = Instant::now();
        
        let mut connection = Connection {
            id: connection_id.clone(),
            endpoint: endpoint.to_string(),
            connection_type,
            status: ConnectionStatus::Connecting,
            stream: None,
            last_activity: Instant::now(),
            bytes_sent: 0,
            bytes_received: 0,
            messages_sent: 0,
            messages_received: 0,
            error_count: 0,
            latency_stats: LatencyStats::default(),
        };
        
        // Establish connection based on type
        match connection_type {
            ConnectionType::WebSocket => {
                connection.stream = Some(self.create_websocket_connection(endpoint).await?);
            }
            ConnectionType::Tcp => {
                // Create TCP connection
                let stream = self.create_tcp_connection(endpoint).await?;
                // Convert to WebSocket stream for unified handling
                connection.stream = Some(self.wrap_tcp_stream(stream).await?);
            }
            ConnectionType::Udp => {
                // UDP connections are handled differently
                self.create_udp_connection(endpoint).await?;
            }
            ConnectionType::Http | ConnectionType::Https => {
                // HTTP connections are typically short-lived
                return Err(AnalyzerError::UnsupportedConnectionType(connection_type));
            }
        }
        
        connection.status = ConnectionStatus::Connected;
        connection.latency_stats.min_latency_ns = start_time.elapsed().as_nanos() as u64;
        
        // Store connection
        self.connection_manager.add_connection(connection).await?;
        
        Ok(connection_id)
    }
    
    /// Create WebSocket connection
    async fn create_websocket_connection(&self, endpoint: &str) -> Result<WebSocketStream<MaybeTlsStream<TcpStream>>, AnalyzerError> {
        let url = url::Url::parse(endpoint)
            .map_err(|e| AnalyzerError::NetworkError(format!("Invalid URL: {}", e)))?;
        
        let (ws_stream, _) = tokio_tungstenite::connect_async_with_config(
            url,
            Some(self.create_websocket_config()),
            false,
        ).await
        .map_err(|e| AnalyzerError::NetworkError(format!("WebSocket connection failed: {}", e)))?;
        
        Ok(ws_stream)
    }
    
    /// Create TCP connection with optimization
    async fn create_tcp_connection(&self, endpoint: &str) -> Result<TcpStream, AnalyzerError> {
        let stream = tokio::time::timeout(
            Duration::from_millis(self.config.connection_timeout_ms),
            TcpStream::connect(endpoint),
        ).await
        .map_err(|_| AnalyzerError::NetworkError("Connection timeout".to_string()))?
        .map_err(|e| AnalyzerError::NetworkError(format!("TCP connection failed: {}", e)))?;
        
        // Optimize TCP settings
        self.optimize_tcp_stream(&stream).await?;
        
        Ok(stream)
    }
    
    /// Create UDP connection
    async fn create_udp_connection(&self, endpoint: &str) -> Result<UdpSocket, AnalyzerError> {
        let socket = UdpSocket::bind("0.0.0.0:0").await
            .map_err(|e| AnalyzerError::NetworkError(format!("UDP bind failed: {}", e)))?;
        
        socket.connect(endpoint).await
            .map_err(|e| AnalyzerError::NetworkError(format!("UDP connect failed: {}", e)))?;
        
        Ok(socket)
    }
    
    /// Wrap TCP stream for unified handling
    async fn wrap_tcp_stream(&self, stream: TcpStream) -> Result<WebSocketStream<MaybeTlsStream<TcpStream>>, AnalyzerError> {
        // This is a simplified wrapper - in practice, you'd need proper WebSocket handshake
        // For now, we'll create a mock WebSocket stream
        Err(AnalyzerError::NotImplemented("TCP to WebSocket wrapping not implemented".to_string()))
    }
    
    /// Optimize TCP stream settings
    async fn optimize_tcp_stream(&self, stream: &TcpStream) -> Result<(), AnalyzerError> {
        // Enable TCP_NODELAY for low latency
        if self.config.tcp_nodelay {
            stream.set_nodelay(true)
                .map_err(|e| AnalyzerError::NetworkError(format!("Failed to set TCP_NODELAY: {}", e)))?;
        }
        
        // Enable keepalive
        if self.config.keepalive {
            let keepalive = socket2::TcpKeepalive::new()
                .with_time(Duration::from_secs(self.config.keepalive_interval));
            
            let socket = socket2::Socket::from(stream.try_clone().await
                .map_err(|e| AnalyzerError::NetworkError(format!("Failed to clone stream: {}", e)))?);
            
            socket.set_tcp_keepalive(&keepalive)
                .map_err(|e| AnalyzerError::NetworkError(format!("Failed to set keepalive: {}", e)))?;
        }
        
        Ok(())
    }
    
    /// Create WebSocket configuration
    fn create_websocket_config(&self) -> tokio_tungstenite::tungstenite::protocol::WebSocketConfig {
        tokio_tungstenite::tungstenite::protocol::WebSocketConfig {
            max_send_queue: Some(1000),
            max_message_size: Some(16 * 1024 * 1024), // 16MB
            max_frame_size: Some(16 * 1024 * 1024),
            accept_unmasked_frames: false,
        }
    }
    
    /// Send message with optimization
    pub async fn send_message(&self, connection_id: &str, message: Message) -> Result<(), AnalyzerError> {
        debug!("Sending message: {} -> {}", message.id, connection_id);
        
        let start_time = Instant::now();
        
        // Compress message if enabled and beneficial
        let compressed_message = if self.config.compression_enabled && message.payload.len() > 1024 {
            self.data_compressor.compress_message(&message).await?
        } else {
            message
        };
        
        // Route message through dispatcher
        self.message_dispatcher.dispatch_message(connection_id, compressed_message).await?;
        
        // Update performance metrics
        let latency = start_time.elapsed().as_nanos() as u64;
        self.performance_monitor.record_message_sent(latency).await;
        
        Ok(())
    }
    
    /// Receive message with optimization
    pub async fn receive_message(&self, connection_id: &str) -> Result<Option<Message>, AnalyzerError> {
        debug!("Receiving message from: {}", connection_id);
        
        let start_time = Instant::now();
        
        // Check for buffered messages first
        if let Some(message) = self.message_dispatcher.get_buffered_message(connection_id).await? {
            let latency = start_time.elapsed().as_nanos() as u64;
            self.performance_monitor.record_message_received(latency).await;
            return Ok(Some(message));
        }
        
        // Receive from connection
        let message = self.connection_manager.receive_message(connection_id).await?;
        
        if let Some(msg) = &message {
            // Decompress if needed
            let decompressed_message = if msg.compression {
                self.data_compressor.decompress_message(msg).await?
            } else {
                msg.clone()
            };
            
            let latency = start_time.elapsed().as_nanos() as u64;
            self.performance_monitor.record_message_received(latency).await;
            
            return Ok(Some(decompressed_message));
        }
        
        Ok(None)
    }
    
    /// Optimize connection parameters
    pub async fn optimize_connection(&self, connection_id: &str) -> Result<(), AnalyzerError> {
        debug!("Optimizing connection: {}", connection_id);
        
        // Get connection statistics
        let stats = self.connection_manager.get_connection_stats(connection_id).await?;
        
        // Adjust buffer sizes based on throughput
        self.adjust_buffer_sizes(&stats).await?;
        
        // Optimize compression settings
        self.optimize_compression(&stats).await?;
        
        // Adjust timeout settings
        self.adjust_timeouts(&stats).await?;
        
        Ok(())
    }
    
    /// Adjust buffer sizes based on performance
    async fn adjust_buffer_sizes(&self, stats: &LatencyStats) -> Result<(), AnalyzerError> {
        // Increase buffer size for high throughput connections
        if stats.avg_latency_ns < 1_000_000 { // Less than 1ms
            // Increase buffer size
            debug!("Increasing buffer size for low latency connection");
        }
        
        Ok(())
    }
    
    /// Optimize compression settings
    async fn optimize_compression(&self, stats: &LatencyStats) -> Result<(), AnalyzerError> {
        // Adjust compression level based on latency requirements
        if stats.avg_latency_ns < 100_000 { // Less than 100Î¼s
            // Reduce compression for ultra-low latency
            debug!("Reducing compression for ultra-low latency");
        }
        
        Ok(())
    }
    
    /// Adjust timeout settings
    async fn adjust_timeouts(&self, stats: &LatencyStats) -> Result<(), AnalyzerError> {
        // Adjust timeouts based on observed latency
        let optimal_timeout = (stats.p95_latency_ns / 1_000_000) * 2; // 2x P95 in milliseconds
        debug!("Optimal timeout: {}ms", optimal_timeout);
        
        Ok(())
    }
    
    /// Get network performance metrics
    pub async fn get_metrics(&self) -> Result<NetworkMetrics, AnalyzerError> {
        self.performance_monitor.get_metrics().await
    }
    
    /// Close connection
    pub async fn close_connection(&self, connection_id: &str) -> Result<(), AnalyzerError> {
        debug!("Closing connection: {}", connection_id);
        
        self.connection_manager.close_connection(connection_id).await?;
        self.performance_monitor.record_connection_closed().await;
        
        Ok(())
    }
    
    /// Monitor and optimize network performance
    pub async fn monitor_performance(&self) -> Result<(), AnalyzerError> {
        info!("Starting network performance monitoring");
        
        loop {
            // Check connection health
            self.check_connection_health().await?;
            
            // Optimize active connections
            self.optimize_active_connections().await?;
            
            // Clean up idle connections
            self.cleanup_idle_connections().await?;
            
            // Update performance metrics
            self.update_performance_metrics().await?;
            
            // Sleep for monitoring interval
            tokio::time::sleep(Duration::from_secs(1)).await;
        }
    }
    
    /// Check health of all connections
    async fn check_connection_health(&self) -> Result<(), AnalyzerError> {
        let connections = self.connection_manager.get_all_connections().await?;
        
        for connection in connections {
            if connection.status == ConnectionStatus::Connected {
                // Check if connection is responsive
                if connection.last_activity.elapsed() > Duration::from_secs(30) {
                    warn!("Connection {} appears inactive", connection.id);
                    // Send heartbeat or reconnect
                }
            }
        }
        
        Ok(())
    }
    
    /// Optimize all active connections
    async fn optimize_active_connections(&self) -> Result<(), AnalyzerError> {
        let active_connections = self.connection_manager.get_active_connections().await?;
        
        for connection_id in active_connections {
            self.optimize_connection(&connection_id).await?;
        }
        
        Ok(())
    }
    
    /// Clean up idle connections
    async fn cleanup_idle_connections(&self) -> Result<(), AnalyzerError> {
        let idle_timeout = Duration::from_secs(300); // 5 minutes
        self.connection_manager.cleanup_idle_connections(idle_timeout).await?;
        
        Ok(())
    }
    
    /// Update performance metrics
    async fn update_performance_metrics(&self) -> Result<(), AnalyzerError> {
        self.performance_monitor.update_metrics().await?;
        
        Ok(())
    }
}

impl ConnectionManager {
    /// Create new connection manager
    pub fn new(config: NetworkConfig) -> Self {
        Self {
            connections: Arc::new(RwLock::new(HashMap::new())),
            connection_pool: Arc::new(RwLock::new(Vec::new())),
            config,
        }
    }
    
    /// Find existing connection
    pub async fn find_connection(&self, endpoint: &str) -> Result<Option<String>, AnalyzerError> {
        let connections = self.connections.read().await;
        
        for (id, connection) in connections.iter() {
            if connection.endpoint == endpoint && connection.status == ConnectionStatus::Connected {
                return Ok(Some(id.clone()));
            }
        }
        
        Ok(None)
    }
    
    /// Add connection
    pub async fn add_connection(&self, connection: Connection) -> Result<(), AnalyzerError> {
        let mut connections = self.connections.write().await;
        connections.insert(connection.id.clone(), connection);
        
        Ok(())
    }
    
    /// Receive message from connection
    pub async fn receive_message(&self, connection_id: &str) -> Result<Option<Message>, AnalyzerError> {
        // This is a placeholder - actual implementation would read from the connection
        Ok(None)
    }
    
    /// Get connection statistics
    pub async fn get_connection_stats(&self, connection_id: &str) -> Result<LatencyStats, AnalyzerError> {
        let connections = self.connections.read().await;
        
        if let Some(connection) = connections.get(connection_id) {
            Ok(connection.latency_stats.clone())
        } else {
            Err(AnalyzerError::ConnectionNotFound(connection_id.to_string()))
        }
    }
    
    /// Get all connections
    pub async fn get_all_connections(&self) -> Result<Vec<Connection>, AnalyzerError> {
        let connections = self.connections.read().await;
        Ok(connections.values().cloned().collect())
    }
    
    /// Get active connections
    pub async fn get_active_connections(&self) -> Result<Vec<String>, AnalyzerError> {
        let connections = self.connections.read().await;
        
        let active_ids: Vec<String> = connections.iter()
            .filter(|(_, conn)| conn.status == ConnectionStatus::Connected)
            .map(|(id, _)| id.clone())
            .collect();
        
        Ok(active_ids)
    }
    
    /// Close connection
    pub async fn close_connection(&self, connection_id: &str) -> Result<(), AnalyzerError> {
        let mut connections = self.connections.write().await;
        
        if let Some(connection) = connections.get_mut(connection_id) {
            connection.status = ConnectionStatus::Disconnected;
            connection.stream = None;
        }
        
        Ok(())
    }
    
    /// Clean up idle connections
    pub async fn cleanup_idle_connections(&self, idle_timeout: Duration) -> Result<(), AnalyzerError> {
        let mut connections = self.connections.write().await;
        let now = Instant::now();
        
        connections.retain(|_, connection| {
            if connection.status == ConnectionStatus::Connected {
                now.duration_since(connection.last_activity) < idle_timeout
            } else {
                false
            }
        });
        
        Ok(())
    }
}

impl DataCompressor {
    /// Create new data compressor
    pub fn new(compression_level: u32, threshold: usize) -> Self {
        Self {
            compression_level,
            compression_threshold: threshold,
        }
    }
    
    /// Compress message
    pub async fn compress_message(&self, message: &Message) -> Result<Message, AnalyzerError> {
        if message.payload.len() < self.compression_threshold {
            return Ok(message.clone());
        }
        
        // Use zstd for fast compression
        let compressed = zstd::encode_all(message.payload.as_slice(), self.compression_level as i32)
            .map_err(|e| AnalyzerError::CompressionError(e.to_string()))?;
        
        let mut compressed_message = message.clone();
        compressed_message.payload = compressed;
        compressed_message.compression = true;
        
        Ok(compressed_message)
    }
    
    /// Decompress message
    pub async fn decompress_message(&self, message: &Message) -> Result<Message, AnalyzerError> {
        if !message.compression {
            return Ok(message.clone());
        }
        
        let decompressed = zstd::decode_all(message.payload.as_slice())
            .map_err(|e| AnalyzerError::CompressionError(e.to_string()))?;
        
        let mut decompressed_message = message.clone();
        decompressed_message.payload = decompressed;
        decompressed_message.compression = false;
        
        Ok(decompressed_message)
    }
}

impl MessageDispatcher {
    /// Create new message dispatcher
    pub fn new() -> Self {
        Self {
            message_queues: Arc::new(RwLock::new(HashMap::new())),
            routing_table: Arc::new(RwLock::new(HashMap::new())),
        }
    }
    
    /// Dispatch message
    pub async fn dispatch_message(&self, connection_id: &str, message: Message) -> Result<(), AnalyzerError> {
        let mut queues = self.message_queues.write().await;
        
        let queue = queues.entry(connection_id.to_string())
            .or_insert_with(|| MessageQueue {
                messages: Vec::new(),
                max_size: 10000,
                current_size: 0,
                dropped_messages: 0,
            });
        
        if queue.messages.len() >= queue.max_size {
            queue.dropped_messages += 1;
            return Err(AnalyzerError::MessageQueueFull);
        }
        
        queue.messages.push(message);
        queue.current_size += 1;
        
        Ok(())
    }
    
    /// Get buffered message
    pub async fn get_buffered_message(&self, connection_id: &str) -> Result<Option<Message>, AnalyzerError> {
        let mut queues = self.message_queues.write().await;
        
        if let Some(queue) = queues.get_mut(connection_id) {
            if !queue.messages.is_empty() {
                let message = queue.messages.remove(0);
                queue.current_size -= 1;
                return Ok(Some(message));
            }
        }
        
        Ok(None)
    }
}

impl PerformanceMonitor {
    /// Create new performance monitor
    pub fn new() -> Self {
        Self {
            metrics: Arc::new(RwLock::new(NetworkMetrics::default())),
            bandwidth_monitor: Arc::new(BandwidthMonitor::new()),
        }
    }
    
    /// Record connection established
    pub async fn record_connection_established(&self) {
        let mut metrics = self.metrics.write().await;
        metrics.total_connections += 1;
        metrics.active_connections += 1;
    }
    
    /// Record connection closed
    pub async fn record_connection_closed(&self) {
        let mut metrics = self.metrics.write().await;
        metrics.active_connections = metrics.active_connections.saturating_sub(1);
    }
    
    /// Record message sent
    pub async fn record_message_sent(&self, latency_ns: u64) {
        let mut metrics = self.metrics.write().await;
        metrics.total_messages_sent += 1;
        
        // Update latency average
        let latency_ms = latency_ns as f64 / 1_000_000.0;
        metrics.data_latency_avg = (metrics.data_latency_avg + latency_ms) / 2.0;
    }
    
    /// Record message received
    pub async fn record_message_received(&self, latency_ns: u64) {
        let mut metrics = self.metrics.write().await;
        metrics.total_messages_received += 1;
        
        // Update latency average
        let latency_ms = latency_ns as f64 / 1_000_000.0;
        metrics.data_latency_avg = (metrics.data_latency_avg + latency_ms) / 2.0;
    }
    
    /// Get metrics
    pub async fn get_metrics(&self) -> Result<NetworkMetrics, AnalyzerError> {
        let metrics = self.metrics.read().await;
        Ok(metrics.clone())
    }
    
    /// Update metrics
    pub async fn update_metrics(&self) -> Result<(), AnalyzerError> {
        let mut metrics = self.metrics.write().await;
        
        // Update bandwidth
        let bandwidth = self.bandwidth_monitor.get_current_bandwidth().await;
        metrics.throughput_mbps = bandwidth;
        
        // Update uptime percentage
        metrics.uptime_percentage = 99.99; // Placeholder
        
        Ok(())
    }
}

impl BandwidthMonitor {
    /// Create new bandwidth monitor
    pub fn new() -> Self {
        Self {
            samples: Arc::new(RwLock::new(Vec::new())),
            current_bandwidth: Arc::new(RwLock::new(0.0)),
        }
    }
    
    /// Get current bandwidth
    pub async fn get_current_bandwidth(&self) -> f64 {
        let bandwidth = self.current_bandwidth.read().await;
        *bandwidth
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::performance::memory_pool::{MemoryPool, MemoryPoolConfig};
    
    #[tokio::test]
    async fn test_network_optimizer_creation() {
        let config = NetworkConfig::default();
        let memory_pool = Arc::new(MemoryPool::new(MemoryPoolConfig::default()).unwrap());
        
        let optimizer = NetworkIOOptimizer::new(config, memory_pool);
        assert!(optimizer.is_ok());
    }
    
    #[tokio::test]
    async fn test_connection_manager() {
        let config = NetworkConfig::default();
        let manager = ConnectionManager::new(config);
        
        let connection_id = "test_conn_1";
        let endpoint = "ws://localhost:8080";
        
        // Test find connection when none exists
        let result = manager.find_connection(endpoint).await.unwrap();
        assert!(result.is_none());
    }
    
    #[tokio::test]
    async fn test_data_compressor() {
        let compressor = DataCompressor::new(6, 100);
        
        let message = Message {
            id: "test_msg".to_string(),
            timestamp: 1234567890,
            source: "test_source".to_string(),
            destination: "test_dest".to_string(),
            message_type: MessageType::MarketData,
            payload: vec![0u8; 2048], // Large payload for compression
            priority: MessagePriority::Normal,
            ttl: 1000,
            compression: false,
        };
        
        let compressed = compressor.compress_message(&message).await.unwrap();
        assert!(compressed.compression);
        assert!(compressed.payload.len() < message.payload.len());
        
        let decompressed = compressor.decompress_message(&compressed).await.unwrap();
        assert!(!decompressed.compression);
        assert_eq!(decompressed.payload, message.payload);
    }
    
    #[tokio::test]
    async fn test_message_dispatcher() {
        let dispatcher = MessageDispatcher::new();
        
        let message = Message {
            id: "test_msg".to_string(),
            timestamp: 1234567890,
            source: "test_source".to_string(),
            destination: "test_dest".to_string(),
            message_type: MessageType::MarketData,
            payload: vec![1, 2, 3, 4, 5],
            priority: MessagePriority::High,
            ttl: 1000,
            compression: false,
        };
        
        let connection_id = "test_conn";
        
        // Test dispatch
        dispatcher.dispatch_message(connection_id, message.clone()).await.unwrap();
        
        // Test retrieve
        let retrieved = dispatcher.get_buffered_message(connection_id).await.unwrap();
        assert!(retrieved.is_some());
        assert_eq!(retrieved.unwrap().id, message.id);
    }
    
    #[tokio::test]
    async fn test_performance_monitor() {
        let monitor = PerformanceMonitor::new();
        
        // Test connection recording
        monitor.record_connection_established().await;
        let metrics = monitor.get_metrics().await.unwrap();
        assert_eq!(metrics.total_connections, 1);
        assert_eq!(metrics.active_connections, 1);
        
        // Test message recording
        monitor.record_message_sent(1_000_000).await; // 1ms in nanoseconds
        let metrics = monitor.get_metrics().await.unwrap();
        assert_eq!(metrics.total_messages_sent, 1);
        assert!(metrics.data_latency_avg > 0.0);
    }
}