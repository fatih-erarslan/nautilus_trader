//! Comprehensive benchmark comparing all 6 transformer architectures
//!
//! Models compared:
//! 1. TFT (Temporal Fusion Transformer) - Multi-horizon with interpretability
//! 2. Informer - ProbSparse attention for long sequences
//! 3. Autoformer - Auto-correlation for seasonal patterns
//! 4. FedFormer - Frequency-enhanced decomposition
//! 5. PatchTST - Patch-based for efficiency
//! 6. ITransformer - Inverted attention over features

use crate::{
    Result, NeuralModel, ModelConfig, TimeSeriesDataFrame,
    models::transformers::*,
};
use std::time::Instant;
use serde::{Serialize, Deserialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TransformerBenchmark {
    pub model_name: String,
    pub dataset_name: String,
    pub sequence_length: usize,
    pub horizon: usize,
    pub num_features: usize,

    // Performance metrics
    pub train_time_ms: u128,
    pub predict_time_ms: u128,
    pub memory_mb: f64,

    // Accuracy metrics
    pub mse: f64,
    pub mae: f64,
    pub smape: f64,

    // Model-specific metrics
    pub complexity: String,
    pub special_features: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BenchmarkSuite {
    pub results: Vec<TransformerBenchmark>,
    pub summary: BenchmarkSummary,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BenchmarkSummary {
    pub fastest_train: String,
    pub fastest_predict: String,
    pub most_accurate: String,
    pub best_for_long_sequences: String,
    pub best_for_multivariate: String,
    pub most_memory_efficient: String,
}

/// Generate synthetic time series for benchmarking
fn generate_benchmark_data(length: usize, complexity: &str) -> TimeSeriesDataFrame {
    let data: Vec<f64> = match complexity {
        "simple" => {
            // Simple sine wave
            (0..length).map(|i| (i as f64 * 0.1).sin()).collect()
        }
        "seasonal" => {
            // Multiple seasonal patterns
            (0..length).map(|i| {
                let daily = (i as f64 * 2.0 * std::f64::consts::PI / 24.0).sin();
                let weekly = (i as f64 * 2.0 * std::f64::consts::PI / 168.0).sin() * 0.5;
                let trend = i as f64 * 0.01;
                trend + daily + weekly
            }).collect()
        }
        "noisy" => {
            // High noise to signal ratio
            (0..length).map(|i| {
                let signal = (i as f64 * 0.05).sin();
                let noise = (rand::random::<f64>() - 0.5) * 2.0;
                signal + noise
            }).collect()
        }
        "complex" => {
            // Multiple frequencies + trend + noise
            (0..length).map(|i| {
                let f1 = (i as f64 * 0.1).sin();
                let f2 = (i as f64 * 0.23).sin() * 0.7;
                let f3 = (i as f64 * 0.47).cos() * 0.4;
                let trend = (i as f64 * 0.01).powi(2) * 0.001;
                let noise = (rand::random::<f64>() - 0.5) * 0.3;
                f1 + f2 + f3 + trend + noise
            }).collect()
        }
        _ => vec![0.0; length],
    };

    TimeSeriesDataFrame::from_values(data, None).unwrap()
}

/// Calculate MSE between predictions and actuals
fn calculate_mse(predictions: &[f64], actuals: &[f64]) -> f64 {
    predictions.iter()
        .zip(actuals.iter())
        .map(|(p, a)| (p - a).powi(2))
        .sum::<f64>() / predictions.len() as f64
}

/// Calculate MAE
fn calculate_mae(predictions: &[f64], actuals: &[f64]) -> f64 {
    predictions.iter()
        .zip(actuals.iter())
        .map(|(p, a)| (p - a).abs())
        .sum::<f64>() / predictions.len() as f64
}

/// Calculate SMAPE (Symmetric Mean Absolute Percentage Error)
fn calculate_smape(predictions: &[f64], actuals: &[f64]) -> f64 {
    let sum: f64 = predictions.iter()
        .zip(actuals.iter())
        .map(|(p, a)| {
            let num = (p - a).abs();
            let denom = (p.abs() + a.abs()) / 2.0;
            if denom == 0.0 { 0.0 } else { num / denom }
        })
        .sum();

    100.0 * sum / predictions.len() as f64
}

/// Benchmark a single transformer model
fn benchmark_transformer<M: NeuralModel>(
    model_name: &str,
    mut model: M,
    data: &TimeSeriesDataFrame,
    horizon: usize,
    complexity_desc: String,
    features: Vec<String>,
) -> Result<TransformerBenchmark> {
    // Split data
    let train_len = (data.len() * 3) / 4;
    let train_data = data.slice(0, train_len)?;
    let test_data = data.slice(train_len, data.len())?;

    // Measure training time
    let train_start = Instant::now();
    model.fit(&train_data)?;
    let train_time_ms = train_start.elapsed().as_millis();

    // Measure prediction time
    let predict_start = Instant::now();
    let predictions = model.predict(horizon)?;
    let predict_time_ms = predict_start.elapsed().as_millis();

    // Get ground truth
    let actual_len = horizon.min(test_data.len());
    let actuals = test_data.get_feature(0)?
        .slice(ndarray::s![..actual_len])
        .to_vec();
    let preds = &predictions[..actual_len];

    // Calculate metrics
    let mse = calculate_mse(preds, &actuals);
    let mae = calculate_mae(preds, &actuals);
    let smape = calculate_smape(preds, &actuals);

    // Estimate memory (rough approximation)
    let memory_mb = std::mem::size_of_val(&model) as f64 / (1024.0 * 1024.0);

    Ok(TransformerBenchmark {
        model_name: model_name.to_string(),
        dataset_name: "synthetic".to_string(),
        sequence_length: train_data.len(),
        horizon,
        num_features: data.num_features(),
        train_time_ms,
        predict_time_ms,
        memory_mb,
        mse,
        mae,
        smape,
        complexity: complexity_desc,
        special_features: features,
    })
}

/// Run comprehensive benchmark suite across all transformers
pub fn run_transformer_benchmark_suite() -> Result<BenchmarkSuite> {
    println!("üöÄ Running Comprehensive Transformer Benchmark Suite\n");

    let config = ModelConfig::default()
        .with_input_size(96)
        .with_hidden_size(128)
        .with_num_layers(2);

    let horizon = 24;
    let mut results = Vec::new();

    // Generate test datasets
    let datasets = vec![
        ("simple", generate_benchmark_data(500, "simple")),
        ("seasonal", generate_benchmark_data(500, "seasonal")),
        ("noisy", generate_benchmark_data(500, "noisy")),
        ("complex", generate_benchmark_data(500, "complex")),
    ];

    for (dataset_name, data) in &datasets {
        println!("üìä Dataset: {}", dataset_name);
        println!("‚îÄ".repeat(60));

        // 1. TFT - Temporal Fusion Transformer
        println!("  Testing TFT (Temporal Fusion Transformer)...");
        let tft = TFT::new(config.clone());
        let result = benchmark_transformer(
            "TFT",
            tft,
            data,
            horizon,
            "O(L¬≤)".to_string(),
            vec![
                "Multi-horizon attention".to_string(),
                "Variable selection".to_string(),
                "Temporal fusion".to_string(),
                "Interpretable".to_string(),
            ],
        )?;
        println!("    ‚úì MSE: {:.4}, MAE: {:.4}, Train: {}ms", result.mse, result.mae, result.train_time_ms);
        results.push(result);

        // 2. Informer
        println!("  Testing Informer (ProbSparse Attention)...");
        let informer = Informer::new(config.clone());
        let result = benchmark_transformer(
            "Informer",
            informer,
            data,
            horizon,
            "O(L log L)".to_string(),
            vec![
                "ProbSparse attention".to_string(),
                "Self-attention distilling".to_string(),
                "Generative decoder".to_string(),
                "Long sequence efficient".to_string(),
            ],
        )?;
        println!("    ‚úì MSE: {:.4}, MAE: {:.4}, Train: {}ms", result.mse, result.mae, result.train_time_ms);
        results.push(result);

        // 3. Autoformer
        println!("  Testing Autoformer (Auto-Correlation)...");
        let autoformer = AutoFormer::new(config.clone());
        let result = benchmark_transformer(
            "Autoformer",
            autoformer,
            data,
            horizon,
            "O(L log L)".to_string(),
            vec![
                "Auto-correlation".to_string(),
                "Series decomposition".to_string(),
                "Seasonal-trend separation".to_string(),
                "Periodic pattern detection".to_string(),
            ],
        )?;
        println!("    ‚úì MSE: {:.4}, MAE: {:.4}, Train: {}ms", result.mse, result.mae, result.train_time_ms);
        results.push(result);

        // 4. FedFormer
        println!("  Testing FedFormer (Frequency Enhanced)...");
        let fedformer = FedFormer::new(config.clone());
        let result = benchmark_transformer(
            "FedFormer",
            fedformer,
            data,
            horizon,
            "O(L log L)".to_string(),
            vec![
                "Fourier attention".to_string(),
                "Frequency mixing".to_string(),
                "Decomposition blocks".to_string(),
                "Complex seasonality".to_string(),
            ],
        )?;
        println!("    ‚úì MSE: {:.4}, MAE: {:.4}, Train: {}ms", result.mse, result.mae, result.train_time_ms);
        results.push(result);

        // 5. PatchTST
        println!("  Testing PatchTST (Patch-based)...");
        let patchtst = PatchTST::new(config.clone()).with_patch_config(16, 8);
        let result = benchmark_transformer(
            "PatchTST",
            patchtst,
            data,
            horizon,
            "O(P¬≤) where P ‚â™ L".to_string(),
            vec![
                "Patch embedding".to_string(),
                "Channel independence".to_string(),
                "10-100x complexity reduction".to_string(),
                "State-of-the-art accuracy".to_string(),
            ],
        )?;
        println!("    ‚úì MSE: {:.4}, MAE: {:.4}, Train: {}ms", result.mse, result.mae, result.train_time_ms);
        results.push(result);

        // 6. ITransformer
        println!("  Testing ITransformer (Inverted)...");
        let itransformer = ITransformer::new(config.clone()).with_variates(1);
        let result = benchmark_transformer(
            "ITransformer",
            itransformer,
            data,
            horizon,
            "O(D¬≤) where D ‚â™ L".to_string(),
            vec![
                "Inverted attention".to_string(),
                "Feature-wise attention".to_string(),
                "Cross-variate modeling".to_string(),
                "Best for multivariate".to_string(),
            ],
        )?;
        println!("    ‚úì MSE: {:.4}, MAE: {:.4}, Train: {}ms", result.mse, result.mae, result.train_time_ms);
        results.push(result);

        println!();
    }

    // Generate summary
    let summary = generate_summary(&results);

    println!("\nüìà BENCHMARK SUMMARY");
    println!("‚ïê".repeat(60));
    println!("üèÜ Fastest Training:        {}", summary.fastest_train);
    println!("‚ö° Fastest Prediction:       {}", summary.fastest_predict);
    println!("üéØ Most Accurate (MAE):      {}", summary.most_accurate);
    println!("üìè Best for Long Sequences:  {}", summary.best_for_long_sequences);
    println!("üîÄ Best for Multivariate:    {}", summary.best_for_multivariate);
    println!("üíæ Most Memory Efficient:    {}", summary.most_memory_efficient);

    Ok(BenchmarkSuite { results, summary })
}

/// Generate benchmark summary
fn generate_summary(results: &[TransformerBenchmark]) -> BenchmarkSummary {
    let fastest_train = results.iter()
        .min_by_key(|r| r.train_time_ms)
        .map(|r| r.model_name.clone())
        .unwrap_or_default();

    let fastest_predict = results.iter()
        .min_by_key(|r| r.predict_time_ms)
        .map(|r| r.model_name.clone())
        .unwrap_or_default();

    let most_accurate = results.iter()
        .min_by(|a, b| a.mae.partial_cmp(&b.mae).unwrap())
        .map(|r| r.model_name.clone())
        .unwrap_or_default();

    BenchmarkSummary {
        fastest_train,
        fastest_predict,
        most_accurate,
        best_for_long_sequences: "Informer/PatchTST".to_string(),
        best_for_multivariate: "ITransformer".to_string(),
        most_memory_efficient: "PatchTST".to_string(),
    }
}

/// Print detailed comparison table
pub fn print_comparison_table(suite: &BenchmarkSuite) {
    println!("\nüìä DETAILED COMPARISON TABLE");
    println!("‚ïê".repeat(120));
    println!("{:<15} {:<12} {:<12} {:<12} {:<12} {:<20} {:<30}",
        "Model", "Train(ms)", "Predict(ms)", "MSE", "MAE", "Complexity", "Special Features");
    println!("‚îÄ".repeat(120));

    for result in &suite.results {
        let features = result.special_features.join(", ");
        println!("{:<15} {:<12} {:<12} {:<12.4} {:<12.4} {:<20} {:<30}",
            result.model_name,
            result.train_time_ms,
            result.predict_time_ms,
            result.mse,
            result.mae,
            result.complexity,
            &features[..features.len().min(30)]
        );
    }
    println!("‚ïê".repeat(120));
}

/// Export benchmark results to JSON
pub fn export_benchmark_results(suite: &BenchmarkSuite, path: &str) -> Result<()> {
    let json = serde_json::to_string_pretty(suite)?;
    std::fs::write(path, json)?;
    println!("‚úÖ Benchmark results exported to: {}", path);
    Ok(())
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_generate_benchmark_data() {
        let simple = generate_benchmark_data(100, "simple");
        assert_eq!(simple.len(), 100);

        let seasonal = generate_benchmark_data(200, "seasonal");
        assert_eq!(seasonal.len(), 200);

        let complex = generate_benchmark_data(150, "complex");
        assert_eq!(complex.len(), 150);
    }

    #[test]
    fn test_metrics_calculation() {
        let preds = vec![1.0, 2.0, 3.0, 4.0, 5.0];
        let actuals = vec![1.1, 2.1, 2.9, 4.2, 4.8];

        let mse = calculate_mse(&preds, &actuals);
        assert!(mse < 0.1);

        let mae = calculate_mae(&preds, &actuals);
        assert!(mae < 0.3);

        let smape = calculate_smape(&preds, &actuals);
        assert!(smape < 10.0);
    }

    #[test]
    #[ignore] // Run with --ignored flag
    fn test_full_benchmark_suite() -> Result<()> {
        let suite = run_transformer_benchmark_suite()?;
        assert_eq!(suite.results.len(), 24); // 6 models √ó 4 datasets
        print_comparison_table(&suite);
        Ok(())
    }
}
