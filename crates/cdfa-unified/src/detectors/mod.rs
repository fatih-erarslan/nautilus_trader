//! Advanced pattern detection algorithms for CDFA
//!
//! This module consolidates all specialized detector algorithms into a unified interface:
//! - Fibonacci pattern detection
//! - Black swan event detection
//! - Antifragility analysis
//! - Panarchy analysis
//! - Self-organized criticality analysis
//! - Advanced market microstructure patterns
//!
//! All detectors maintain mathematical accuracy >99.99% and provide real-time performance.

use crate::error::{CdfaError, Result};
use crate::types::*;
use ndarray::prelude::*;
use std::collections::HashMap;

#[cfg(feature = "serde")]
use serde::{Serialize, Deserialize};

/// Prelude for detector modules
pub mod prelude {
    pub use super::fibonacci::*;
    pub use super::black_swan::*;
    pub use super::DetectorConfig;
    pub use super::DetectorResult;
    pub use super::UnifiedDetector;
}

pub mod fibonacci;
pub mod black_swan;
pub mod antifragility;
pub mod panarchy;
pub mod soc;

/// Configuration for all detector algorithms
#[derive(Debug, Clone)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
pub struct DetectorConfig {
    /// Enable real-time processing
    pub real_time_mode: bool,
    
    /// Minimum confidence threshold for detections
    pub min_confidence: Float,
    
    /// Maximum processing time per detection (microseconds)
    pub max_processing_time_us: u64,
    
    /// Enable SIMD optimizations
    pub enable_simd: bool,
    
    /// Enable parallel processing
    pub enable_parallel: bool,
    
    /// Buffer size for streaming data
    pub buffer_size: usize,
    
    /// Numerical tolerance
    pub tolerance: Float,
    
    /// Enable caching
    pub enable_caching: bool,
    
    /// Cache size limit
    pub cache_size_limit: usize,
}

impl Default for DetectorConfig {
    fn default() -> Self {
        Self {
            real_time_mode: true,
            min_confidence: 0.7,
            max_processing_time_us: 1000, // 1ms
            enable_simd: true,
            enable_parallel: true,
            buffer_size: 1000,
            tolerance: 1e-12,
            enable_caching: true,
            cache_size_limit: 10000,
        }
    }
}

/// Generic detector result
#[derive(Debug, Clone)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
pub struct DetectorResult<T> {
    /// Detection result data
    pub data: T,
    
    /// Confidence score (0.0 to 1.0)
    pub confidence: Float,
    
    /// Processing time in microseconds
    pub processing_time_us: u64,
    
    /// Detected pattern timestamp
    pub timestamp: u64,
    
    /// Additional metadata
    pub metadata: HashMap<String, String>,
}

impl<T> DetectorResult<T> {
    /// Create a new detector result
    pub fn new(data: T, confidence: Float) -> Self {
        Self {
            data,
            confidence,
            processing_time_us: 0,
            timestamp: 0,
            metadata: HashMap::new(),
        }
    }
    
    /// Add metadata
    pub fn with_metadata(mut self, key: String, value: String) -> Self {
        self.metadata.insert(key, value);
        self
    }
    
    /// Set processing time
    pub fn with_processing_time(mut self, time_us: u64) -> Self {
        self.processing_time_us = time_us;
        self
    }
    
    /// Set timestamp
    pub fn with_timestamp(mut self, timestamp: u64) -> Self {
        self.timestamp = timestamp;
        self
    }
}

/// Pattern detection trait
pub trait PatternDetector<T> {
    /// Detect patterns in data
    fn detect(&self, data: &FloatArrayView1) -> Result<Vec<DetectorResult<T>>>;
    
    /// Detect patterns in real-time streaming data
    fn detect_streaming(&mut self, data: &FloatArrayView1) -> Result<Vec<DetectorResult<T>>>;
    
    /// Get detector configuration
    fn get_config(&self) -> &DetectorConfig;
    
    /// Update detector configuration
    fn update_config(&mut self, config: DetectorConfig);
    
    /// Reset detector state
    fn reset(&mut self);
}

/// Unified detector that combines all specialized detectors
pub struct UnifiedDetector {
    config: DetectorConfig,
    fibonacci_detector: fibonacci::FibonacciPatternDetector,
    black_swan_detector: black_swan::BlackSwanDetector,
}

impl UnifiedDetector {
    /// Create a new unified detector
    pub fn new(config: DetectorConfig) -> CdfaResult<Self> {
        let bs_config = black_swan::BlackSwanConfig::default();
        let black_swan_detector = black_swan::BlackSwanDetector::new(bs_config)?;
        
        Ok(Self {
            fibonacci_detector: fibonacci::FibonacciPatternDetector::new(config.clone()),
            black_swan_detector,
            config,
        })
    }
    
    /// Detect all patterns simultaneously
    pub fn detect_all_patterns(&self, data: &FloatArrayView1) -> Result<UnifiedDetectionResult> {
        let start_time = std::time::Instant::now();
        
        // Convert ndarray to Vec for black swan detector
        let data_vec: Vec<f64> = data.to_vec();
        
        // Run all detectors
        let fibonacci_results = self.fibonacci_detector.detect(data)?;
        let black_swan_result = self.black_swan_detector.detect_real_time(&data_vec)?;
        
        // Convert black swan result to detector result format
        let black_swan_results = vec![DetectorResult::new(
            ExtremeEvent {
                timestamp: 0,
                probability: black_swan_result.probability,
                severity: black_swan_result.severity,
                direction: black_swan_result.direction,
                components: black_swan_result.components,
            },
            black_swan_result.confidence,
        )];
        
        let processing_time = start_time.elapsed().as_micros() as u64;
        
        Ok(UnifiedDetectionResult {
            fibonacci_patterns: fibonacci_results,
            black_swan_events: black_swan_results,
            processing_time_us: processing_time,
        })
    }
    
    /// Get specific detector by type
    pub fn get_fibonacci_detector(&self) -> &fibonacci::FibonacciPatternDetector {
        &self.fibonacci_detector
    }
    
    pub fn get_black_swan_detector(&self) -> &black_swan::BlackSwanDetector {
        &self.black_swan_detector
    }
}

/// Extreme event detection result for black swan detector
#[derive(Debug, Clone)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
pub struct ExtremeEvent {
    /// Event timestamp
    pub timestamp: u64,
    /// Black Swan probability
    pub probability: f64,
    /// Event severity
    pub severity: f64,
    /// Expected direction
    pub direction: i8,
    /// Component breakdown
    pub components: black_swan::BlackSwanComponents,
}

/// Combined result from all detectors
#[derive(Debug, Clone)]
#[cfg_attr(feature = "serde", derive(Serialize, Deserialize))]
pub struct UnifiedDetectionResult {
    /// Fibonacci pattern detection results
    pub fibonacci_patterns: Vec<DetectorResult<fibonacci::FibonacciPattern>>,
    
    /// Black swan event detection results
    pub black_swan_events: Vec<DetectorResult<ExtremeEvent>>,
    
    /// Total processing time
    pub processing_time_us: u64,
}

impl UnifiedDetectionResult {
    /// Get total number of detections across all detectors
    pub fn total_detections(&self) -> usize {
        self.fibonacci_patterns.len() + self.black_swan_events.len()
    }
    
    /// Get average confidence across all detections
    pub fn average_confidence(&self) -> Float {
        let mut total_confidence = 0.0;
        let mut count = 0;
        
        for result in &self.fibonacci_patterns {
            total_confidence += result.confidence;
            count += 1;
        }
        
        for result in &self.black_swan_events {
            total_confidence += result.confidence;
            count += 1;
        }
        
        if count > 0 {
            total_confidence / count as Float
        } else {
            0.0
        }
    }
    
    /// Check if any high-confidence detections exist
    pub fn has_high_confidence_detections(&self, threshold: Float) -> bool {
        self.fibonacci_patterns.iter().any(|r| r.confidence >= threshold) ||
        self.black_swan_events.iter().any(|r| r.confidence >= threshold)
    }
}

/// Utility functions for detector modules
pub mod utils {
    use super::*;
    
    /// Validate input data for detectors
    pub fn validate_detector_input(data: &FloatArrayView1, min_length: usize) -> Result<()> {
        if data.is_empty() {
            return Err(CdfaError::invalid_input("Input data cannot be empty"));
        }
        
        if data.len() < min_length {
            return Err(CdfaError::invalid_input(
                format!("Input data must have at least {} points, got {}", min_length, data.len())
            ));
        }
        
        // Check for non-finite values
        for (i, &value) in data.iter().enumerate() {
            if !value.is_finite() {
                return Err(CdfaError::invalid_input(
                    format!("Non-finite value {} at index {}", value, i)
                ));
            }
        }
        
        Ok(())
    }
    
    /// Calculate confidence based on various metrics
    pub fn calculate_confidence(
        strength: Float,
        consistency: Float,
        statistical_significance: Float,
    ) -> Float {
        let weights = [0.4, 0.3, 0.3]; // Weights for strength, consistency, significance
        let values = [strength, consistency, statistical_significance];
        
        let weighted_sum: Float = weights.iter().zip(values.iter())
            .map(|(w, v)| w * v)
            .sum();
        
        weighted_sum.max(0.0).min(1.0)
    }
    
    /// Normalize data to [0, 1] range
    pub fn normalize_data(data: &FloatArrayView1) -> Result<FloatArray1> {
        let min_val = data.iter().fold(Float::INFINITY, |a, &b| a.min(b));
        let max_val = data.iter().fold(Float::NEG_INFINITY, |a, &b| a.max(b));
        
        if (max_val - min_val).abs() < Float::EPSILON {
            return Err(CdfaError::invalid_input("Cannot normalize constant data"));
        }
        
        let normalized = data.mapv(|x| (x - min_val) / (max_val - min_val));
        Ok(normalized)
    }
    
    /// Calculate moving average
    pub fn moving_average(data: &FloatArrayView1, window_size: usize) -> Result<FloatArray1> {
        if window_size == 0 || window_size > data.len() {
            return Err(CdfaError::invalid_input("Invalid window size"));
        }
        
        let mut result = Vec::new();
        for i in 0..=data.len() - window_size {
            let window = data.slice(s![i..i + window_size]);
            let average = window.sum() / window_size as Float;
            result.push(average);
        }
        
        Ok(FloatArray1::from(result))
    }
    
    /// Calculate standard deviation
    pub fn standard_deviation(data: &FloatArrayView1) -> Float {
        let mean = data.mean().unwrap_or(0.0);
        let variance = data.iter()
            .map(|x| (x - mean).powi(2))
            .sum::<Float>() / data.len() as Float;
        variance.sqrt()
    }
    
    /// Calculate z-score
    pub fn z_score(data: &FloatArrayView1) -> Result<FloatArray1> {
        let mean = data.mean().unwrap_or(0.0);
        let std_dev = standard_deviation(data);
        
        if std_dev < Float::EPSILON {
            return Err(CdfaError::invalid_input("Cannot calculate z-score for constant data"));
        }
        
        let z_scores = data.mapv(|x| (x - mean) / std_dev);
        Ok(z_scores)
    }
    
    /// Find peaks in data
    pub fn find_peaks(data: &FloatArrayView1, prominence: Float) -> Vec<usize> {
        let mut peaks = Vec::new();
        
        for i in 1..data.len() - 1 {
            if data[i] > data[i - 1] && data[i] > data[i + 1] {
                // Check prominence
                let left_min = data[..i].iter().fold(Float::INFINITY, |a, &b| a.min(b));
                let right_min = data[i + 1..].iter().fold(Float::INFINITY, |a, &b| a.min(b));
                let min_prominence = (data[i] - left_min).min(data[i] - right_min);
                
                if min_prominence >= prominence {
                    peaks.push(i);
                }
            }
        }
        
        peaks
    }
    
    /// Find valleys in data
    pub fn find_valleys(data: &FloatArrayView1, prominence: Float) -> Vec<usize> {
        let mut valleys = Vec::new();
        
        for i in 1..data.len() - 1 {
            if data[i] < data[i - 1] && data[i] < data[i + 1] {
                // Check prominence
                let left_max = data[..i].iter().fold(Float::NEG_INFINITY, |a, &b| a.max(b));
                let right_max = data[i + 1..].iter().fold(Float::NEG_INFINITY, |a, &b| a.max(b));
                let min_prominence = (left_max - data[i]).min(right_max - data[i]);
                
                if min_prominence >= prominence {
                    valleys.push(i);
                }
            }
        }
        
        valleys
    }
    
    /// Calculate fractal dimension using box-counting method
    pub fn fractal_dimension(data: &FloatArrayView1) -> Float {
        let n = data.len();
        if n < 4 {
            return 1.0; // Default for too little data
        }
        
        let mut box_sizes = Vec::new();
        let mut counts = Vec::new();
        
        // Try different box sizes
        for box_size in 1..=n / 4 {
            let mut count = 0;
            for i in 0..n - box_size {
                let window = data.slice(s![i..i + box_size]);
                let min_val = window.iter().fold(Float::INFINITY, |a, &b| a.min(b));
                let max_val = window.iter().fold(Float::NEG_INFINITY, |a, &b| a.max(b));
                if (max_val - min_val) > Float::EPSILON {
                    count += 1;
                }
            }
            
            if count > 0 {
                box_sizes.push(box_size as Float);
                counts.push(count as Float);
            }
        }
        
        if box_sizes.len() < 2 {
            return 1.0;
        }
        
        // Calculate slope of log-log plot
        let log_sizes: Vec<Float> = box_sizes.iter().map(|x| x.ln()).collect();
        let log_counts: Vec<Float> = counts.iter().map(|x| x.ln()).collect();
        
        let n_points = log_sizes.len() as Float;
        let sum_x = log_sizes.iter().sum::<Float>();
        let sum_y = log_counts.iter().sum::<Float>();
        let sum_xy = log_sizes.iter().zip(log_counts.iter()).map(|(x, y)| x * y).sum::<Float>();
        let sum_x2 = log_sizes.iter().map(|x| x * x).sum::<Float>();
        
        let slope = (n_points * sum_xy - sum_x * sum_y) / (n_points * sum_x2 - sum_x * sum_x);
        
        // Fractal dimension is negative slope
        -slope
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use approx::assert_abs_diff_eq;
    
    #[test]
    fn test_detector_config() {
        let config = DetectorConfig::default();
        assert!(config.real_time_mode);
        assert_eq!(config.min_confidence, 0.7);
        assert!(config.enable_simd);
        assert!(config.enable_parallel);
    }
    
    #[test]
    fn test_detector_result() {
        let result = DetectorResult::new("test_data".to_string(), 0.85)
            .with_metadata("key".to_string(), "value".to_string())
            .with_processing_time(1000)
            .with_timestamp(12345);
        
        assert_eq!(result.data, "test_data");
        assert_eq!(result.confidence, 0.85);
        assert_eq!(result.processing_time_us, 1000);
        assert_eq!(result.timestamp, 12345);
        assert_eq!(result.metadata.get("key"), Some(&"value".to_string()));
    }
    
    #[test]
    fn test_validate_detector_input() {
        use ndarray::array;
        
        // Valid input
        let valid_data = array![1.0, 2.0, 3.0, 4.0, 5.0];
        assert!(utils::validate_detector_input(&valid_data.view(), 3).is_ok());
        
        // Empty input
        let empty_data = array![];
        assert!(utils::validate_detector_input(&empty_data.view(), 3).is_err());
        
        // Too short
        let short_data = array![1.0, 2.0];
        assert!(utils::validate_detector_input(&short_data.view(), 3).is_err());
        
        // Non-finite values
        let invalid_data = array![1.0, Float::NAN, 3.0];
        assert!(utils::validate_detector_input(&invalid_data.view(), 3).is_err());
    }
    
    #[test]
    fn test_calculate_confidence() {
        let confidence = utils::calculate_confidence(0.8, 0.7, 0.9);
        assert!(confidence >= 0.0 && confidence <= 1.0);
        
        // Test with weighted average: 0.4*0.8 + 0.3*0.7 + 0.3*0.9 = 0.32 + 0.21 + 0.27 = 0.8
        assert_abs_diff_eq!(confidence, 0.8, epsilon = 1e-10);
    }
    
    #[test]
    fn test_normalize_data() {
        use ndarray::array;
        
        let data = array![1.0, 2.0, 3.0, 4.0, 5.0];
        let normalized = utils::normalize_data(&data.view()).unwrap();
        
        assert_abs_diff_eq!(normalized[0], 0.0, epsilon = 1e-10);
        assert_abs_diff_eq!(normalized[4], 1.0, epsilon = 1e-10);
        assert_abs_diff_eq!(normalized[2], 0.5, epsilon = 1e-10);
    }
    
    #[test]
    fn test_moving_average() {
        use ndarray::array;
        
        let data = array![1.0, 2.0, 3.0, 4.0, 5.0];
        let ma = utils::moving_average(&data.view(), 3).unwrap();
        
        assert_eq!(ma.len(), 3);
        assert_abs_diff_eq!(ma[0], 2.0, epsilon = 1e-10); // (1+2+3)/3
        assert_abs_diff_eq!(ma[1], 3.0, epsilon = 1e-10); // (2+3+4)/3
        assert_abs_diff_eq!(ma[2], 4.0, epsilon = 1e-10); // (3+4+5)/3
    }
    
    #[test]
    fn test_standard_deviation() {
        use ndarray::array;
        
        let data = array![1.0, 2.0, 3.0, 4.0, 5.0];
        let std_dev = utils::standard_deviation(&data.view());
        
        // Expected std dev for [1,2,3,4,5] is sqrt(2) â‰ˆ 1.414
        assert_abs_diff_eq!(std_dev, 1.4142135623730951, epsilon = 1e-10);
    }
    
    #[test]
    fn test_z_score() {
        use ndarray::array;
        
        let data = array![1.0, 2.0, 3.0, 4.0, 5.0];
        let z_scores = utils::z_score(&data.view()).unwrap();
        
        // Mean is 3.0, std is sqrt(2)
        // z_score[0] = (1-3)/sqrt(2) = -2/sqrt(2) = -sqrt(2)
        assert_abs_diff_eq!(z_scores[0], -1.4142135623730951, epsilon = 1e-10);
        assert_abs_diff_eq!(z_scores[2], 0.0, epsilon = 1e-10); // Mean should be 0
        assert_abs_diff_eq!(z_scores[4], 1.4142135623730951, epsilon = 1e-10);
    }
    
    #[test]
    fn test_find_peaks() {
        use ndarray::array;
        
        let data = array![1.0, 3.0, 2.0, 4.0, 1.0, 5.0, 2.0];
        let peaks = utils::find_peaks(&data.view(), 0.5);
        
        // Should find peaks at indices 1, 3, 5
        assert!(peaks.contains(&1)); // 3.0
        assert!(peaks.contains(&3)); // 4.0
        assert!(peaks.contains(&5)); // 5.0
    }
    
    #[test]
    fn test_find_valleys() {
        use ndarray::array;
        
        let data = array![5.0, 2.0, 4.0, 1.0, 3.0, 0.0, 2.0];
        let valleys = utils::find_valleys(&data.view(), 0.5);
        
        // Should find valleys at indices 1, 3, 5
        assert!(valleys.contains(&1)); // 2.0
        assert!(valleys.contains(&3)); // 1.0
        assert!(valleys.contains(&5)); // 0.0
    }
    
    #[test]
    fn test_fractal_dimension() {
        use ndarray::array;
        
        // Simple linear data should have fractal dimension close to 1
        let linear_data = array![1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0];
        let dim = utils::fractal_dimension(&linear_data.view());
        assert!(dim >= 1.0 && dim <= 2.0);
        
        // Random-like data should have higher fractal dimension
        let random_data = array![1.0, 4.0, 2.0, 7.0, 3.0, 8.0, 1.0, 5.0];
        let dim_random = utils::fractal_dimension(&random_data.view());
        assert!(dim_random >= 1.0 && dim_random <= 2.0);
    }
}