# OpenTelemetry Collector Configuration for Bayesian VaR Production Monitoring
# Constitutional Prime Directive Compliant Observability Stack

apiVersion: v1
kind: ConfigMap
metadata:
  name: opentelemetry-collector-config
  namespace: production
  labels:
    app: bayesian-var
    component: observability
data:
  otel-collector-config.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
            
      prometheus:
        config:
          scrape_configs:
          - job_name: 'bayesian-var-production'
            scrape_interval: 15s
            static_configs:
            - targets: ['bayesian-var-service:8090']
            relabel_configs:
            - source_labels: [__address__]
              target_label: __param_target
            - source_labels: [__param_target]
              target_label: instance
            - target_label: __address__
              replacement: bayesian-var-service:8090
              
          - job_name: 'kubernetes-pods'
            kubernetes_sd_configs:
            - role: pod
              namespaces:
                names:
                - production
            relabel_configs:
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
              action: keep
              regex: true
            - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
              action: replace
              target_label: __metrics_path__
              regex: (.+)
            - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
              action: replace
              regex: ([^:]+)(?::\d+)?;(\d+)
              replacement: $1:$2
              target_label: __address__
            - action: labelmap
              regex: __meta_kubernetes_pod_label_(.+)
            - source_labels: [__meta_kubernetes_namespace]
              action: replace
              target_label: kubernetes_namespace
            - source_labels: [__meta_kubernetes_pod_name]
              action: replace
              target_label: kubernetes_pod_name
              
    processors:
      batch:
        timeout: 1s
        send_batch_size: 1024
        send_batch_max_size: 2048
        
      resource:
        attributes:
        - key: service.name
          value: bayesian-var-production
          action: upsert
        - key: service.version
          value: v2.0.0
          action: upsert
        - key: deployment.environment
          value: production
          action: upsert
        - key: constitutional.prime.directive
          value: enabled
          action: upsert
          
      memory_limiter:
        limit_mib: 512
        spike_limit_mib: 128
        check_interval: 5s
        
      # Constitutional Prime Directive processor for compliance tracking
      attributes:
        actions:
        - key: constitutional_compliance
          value: required
          action: upsert
        - key: financial_system
          value: true
          action: upsert
        - key: zero_downtime_required
          value: true
          action: upsert
          
      # Filter sensitive data
      filter:
        traces:
          span:
          - 'attributes["user.id"] == nil'
          - 'attributes["sensitive.data"] == nil'
        metrics:
          metric:
          - 'name == "sensitive_metric"'
          
    exporters:
      # Prometheus metrics export
      prometheus:
        endpoint: "0.0.0.0:8889"
        namespace: "bayesian_var"
        const_labels:
          environment: production
          system: bayesian-var
          constitutional_compliance: required
          
      # OTLP export to external systems
      otlp/jaeger:
        endpoint: http://jaeger-collector:14250
        tls:
          insecure: true
          
      otlp/tempo:
        endpoint: http://tempo:3200
        tls:
          insecure: true
          
      # Logging export
      logging:
        loglevel: info
        sampling_initial: 5
        sampling_thereafter: 200
        
      # File export for audit trails
      file:
        path: /var/log/otel/constitutional-compliance.jsonl
        
      # Kafka export for real-time monitoring
      kafka:
        brokers: [kafka:9092]
        topic: bayesian-var-telemetry
        metadata:
          full: true
        timeout: 5s
        
    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter, resource, attributes, batch]
          exporters: [otlp/jaeger, otlp/tempo, logging]
          
        metrics:
          receivers: [otlp, prometheus]
          processors: [memory_limiter, resource, attributes, batch]
          exporters: [prometheus, logging, file]
          
        logs:
          receivers: [otlp]
          processors: [memory_limiter, resource, attributes, batch]
          exporters: [logging, file, kafka]
          
      extensions: [health_check, pprof, zpages]
      telemetry:
        logs:
          level: "info"
        metrics:
          address: 0.0.0.0:8888
          
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-collector
  namespace: production
  labels:
    app: opentelemetry-collector
    component: observability
spec:
  replicas: 2  # High availability
  selector:
    matchLabels:
      app: opentelemetry-collector
  template:
    metadata:
      labels:
        app: opentelemetry-collector
        component: observability
    spec:
      containers:
      - name: opentelemetry-collector
        image: otel/opentelemetry-collector-contrib:0.95.0
        args:
        - --config=/conf/otel-collector-config.yaml
        ports:
        - containerPort: 4317
          name: otlp-grpc
          protocol: TCP
        - containerPort: 4318
          name: otlp-http
          protocol: TCP
        - containerPort: 8889
          name: prometheus
          protocol: TCP
        - containerPort: 8888
          name: metrics
          protocol: TCP
        resources:
          requests:
            memory: 256Mi
            cpu: 100m
          limits:
            memory: 512Mi
            cpu: 500m
        volumeMounts:
        - name: config-volume
          mountPath: /conf
        - name: log-volume
          mountPath: /var/log/otel
        livenessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /
            port: 13133
          initialDelaySeconds: 5
          periodSeconds: 10
        env:
        - name: GOGC
          value: "80"
        - name: GOMEMLIMIT
          value: "400MiB"
      volumes:
      - name: config-volume
        configMap:
          name: opentelemetry-collector-config
      - name: log-volume
        emptyDir:
          sizeLimit: 1Gi
      serviceAccountName: opentelemetry-collector
      
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: opentelemetry-collector
  namespace: production

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: opentelemetry-collector
rules:
- apiGroups: [""]
  resources: ["pods", "nodes", "services", "endpoints", "namespaces"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["apps"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["extensions"]
  resources: ["deployments", "replicasets"]
  verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: opentelemetry-collector
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: opentelemetry-collector
subjects:
- kind: ServiceAccount
  name: opentelemetry-collector
  namespace: production

---
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-collector
  namespace: production
  labels:
    app: opentelemetry-collector
    component: observability
spec:
  type: ClusterIP
  ports:
  - port: 4317
    targetPort: 4317
    protocol: TCP
    name: otlp-grpc
  - port: 4318
    targetPort: 4318
    protocol: TCP
    name: otlp-http
  - port: 8889
    targetPort: 8889
    protocol: TCP
    name: prometheus
  - port: 8888
    targetPort: 8888
    protocol: TCP
    name: metrics
  selector:
    app: opentelemetry-collector

---
# ServiceMonitor for OpenTelemetry Collector
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: opentelemetry-collector-monitor
  namespace: production
  labels:
    app: opentelemetry-collector
spec:
  selector:
    matchLabels:
      app: opentelemetry-collector
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
  - port: prometheus
    interval: 15s
    path: /metrics
    
---
# Jaeger deployment for distributed tracing
apiVersion: apps/v1
kind: Deployment
metadata:
  name: jaeger
  namespace: production
  labels:
    app: jaeger
    component: tracing
spec:
  replicas: 1
  selector:
    matchLabels:
      app: jaeger
  template:
    metadata:
      labels:
        app: jaeger
        component: tracing
    spec:
      containers:
      - name: jaeger
        image: jaegertracing/all-in-one:1.52
        ports:
        - containerPort: 16686
          name: ui
        - containerPort: 14250
          name: grpc
        - containerPort: 14268
          name: http
        env:
        - name: COLLECTOR_OTLP_ENABLED
          value: "true"
        - name: SPAN_STORAGE_TYPE
          value: memory
        resources:
          requests:
            memory: 256Mi
            cpu: 100m
          limits:
            memory: 512Mi
            cpu: 500m

---
apiVersion: v1
kind: Service
metadata:
  name: jaeger-collector
  namespace: production
  labels:
    app: jaeger
spec:
  type: ClusterIP
  ports:
  - port: 14250
    targetPort: 14250
    name: grpc
  - port: 14268
    targetPort: 14268
    name: http
  - port: 16686
    targetPort: 16686
    name: ui
  selector:
    app: jaeger

---
# Tempo deployment for traces
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tempo
  namespace: production
  labels:
    app: tempo
    component: tracing
spec:
  replicas: 1
  selector:
    matchLabels:
      app: tempo
  template:
    metadata:
      labels:
        app: tempo
        component: tracing
    spec:
      containers:
      - name: tempo
        image: grafana/tempo:2.3.1
        ports:
        - containerPort: 3200
          name: http
        - containerPort: 9095
          name: grpc
        volumeMounts:
        - name: tempo-config
          mountPath: /etc/tempo
        - name: tempo-data
          mountPath: /var/tempo
        resources:
          requests:
            memory: 256Mi
            cpu: 100m
          limits:
            memory: 512Mi
            cpu: 500m
      volumes:
      - name: tempo-config
        configMap:
          name: tempo-config
      - name: tempo-data
        emptyDir:
          sizeLimit: 2Gi

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: tempo-config
  namespace: production
data:
  tempo.yaml: |
    server:
      http_listen_port: 3200
      grpc_listen_port: 9095

    distributor:
      receivers:
        otlp:
          protocols:
            grpc:
              endpoint: 0.0.0.0:4317
            http:
              endpoint: 0.0.0.0:4318

    ingester:
      trace_idle_period: 10s
      max_block_bytes: 1_000_000
      max_block_duration: 5m

    compactor:
      compaction:
        compaction_window: 1h
        max_compaction_objects: 1000000
        block_retention: 1h
        compacted_block_retention: 10m

    storage:
      trace:
        backend: local
        local:
          path: /var/tempo/traces
        wal:
          path: /var/tempo/wal
        pool:
          max_workers: 100
          queue_depth: 10000

---
apiVersion: v1
kind: Service
metadata:
  name: tempo
  namespace: production
  labels:
    app: tempo
spec:
  type: ClusterIP
  ports:
  - port: 3200
    targetPort: 3200
    name: http
  - port: 9095
    targetPort: 9095
    name: grpc
  - port: 4317
    targetPort: 4317
    name: otlp-grpc
  - port: 4318
    targetPort: 4318
    name: otlp-http
  selector:
    app: tempo