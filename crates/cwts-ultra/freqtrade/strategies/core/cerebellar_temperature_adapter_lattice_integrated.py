#!/usr/bin/env python3
"""
Cerebellar Temperature Adapter: Lattice-Integrated Biological Quantum Learning
=============================================================================

LATTICE INTEGRATION: Biological learning component that adapts temperature selection
using Quantum Lattice (99.5% coherence, 11,533 qubits) infrastructure.

Lattice-Enhanced Bio-Inspired Learning Features:
- Lattice Bell pair-enhanced Purkinje cell error-based adaptation
- Quantum entanglement for parallel fiber integration
- Lattice cortical accelerators for quantum cerebellar microcircuits
- 99.5% coherence long-term depression (LTD) and potentiation (LTP)
- Lattice-optimized spike-timing dependent plasticity (STDP)

This module provides lattice-native biological quantum learning that adapts 
temperature selection based on prediction errors, fully integrated with the 
11,533 qubit Quantum Lattice infrastructure.
"""

import numpy as np
import pennylane as qml
from pennylane import numpy as qnp
import torch
import torch.nn as nn
import asyncio
import time
from typing import Dict, List, Tuple, Optional, Union, Callable
from dataclasses import dataclass, field
from collections import deque, defaultdict
import logging
from functools import lru_cache
import warnings
from enum import Enum
import math

# High-performance numerical computing
try:
    import numba
    from numba import jit, njit, prange, vectorize, guvectorize
    from numba.typed import Dict as NumbaDict, List as NumbaList
    from numba import types, cuda
    from numba.core import config
    USE_NUMBA = True
    
    # Enable fastmath and parallel optimizations
    config.THREADING_LAYER = 'threadsafe'
    
except ImportError:
    USE_NUMBA = False
    warnings.warn("Numba not available. Performance will be significantly reduced.")

try:
    import cupy as cp
    USE_CUPY = True
except ImportError:
    USE_CUPY = False

# Lattice integration imports
try:
    import sys
    import os
    sys.path.append(os.path.join(os.path.dirname(__file__), 
                   'complex_adaptive_agentic_orchestrator/quantum_knowledge_system/quantum_core/lattice'))
    from quantum_operations import QuantumLatticeOperations, OperationResult
    from performance_monitor import PerformanceMonitor
    from data_streams import DataStreamManager
    LATTICE_AVAILABLE = True
except ImportError:
    LATTICE_AVAILABLE = False
    warnings.warn("Lattice components not available. Using standalone mode.")

# Conditional imports
try:
    import pennylane_catalyst as catalyst
    from catalyst import qjit, grad, batch
    USE_CATALYST = True
except ImportError:
    USE_CATALYST = False

# Setup logging
logger = logging.getLogger(__name__)

# =============================================================================
# LATTICE-ENHANCED CEREBELLAR CONFIGURATION
# =============================================================================

class LearningRule(Enum):
    """Types of learning rules for lattice-enhanced cerebellar adaptation"""
    HEBBIAN = "hebbian"                    # Basic Hebbian learning
    ANTI_HEBBIAN = "anti_hebbian"          # Anti-Hebbian (LTD)
    STDP = "stdp"                          # Spike-timing dependent plasticity
    BCM = "bcm"                            # Bienenstock-Cooper-Munro rule
    LATTICE_QUANTUM_ENHANCED = "lattice_quantum_enhanced"  # Lattice quantum-enhanced plasticity

class ErrorSignalType(Enum):
    """Types of error signals for lattice-enhanced climbing fiber input"""
    COVERAGE_ERROR = "coverage_error"      # Conformal coverage error
    CALIBRATION_ERROR = "calibration_error" # Temperature calibration error
    PREDICTION_ERROR = "prediction_error"  # General prediction error
    LATTICE_QUANTUM_FIDELITY_ERROR = "lattice_quantum_fidelity_error"  # Lattice quantum state fidelity error
    LATTICE_COHERENCE_ERROR = "lattice_coherence_error"  # Lattice coherence maintenance error

@dataclass
class CerebellarAdapterLatticeConfig:
    """Configuration for lattice-integrated cerebellar temperature adaptation"""
    
    # Quantum lattice parameters
    n_qubits: int = 20
    quantum_backend: str = 'lattice_managed'  # Use lattice backend management
    use_lattice_quantum_plasticity: bool = True
    lattice_quantum_coherence_time: float = 1.0  # Coherence time in ms
    
    # Lattice integration settings
    lattice_base_url: str = "http://localhost:8050"
    use_lattice_operations: bool = True
    lattice_session_type: str = "cerebellar_adaptation"
    min_coherence_requirement: float = 0.95
    max_latency_requirement_ms: float = 15.0  # Slightly higher for biological processes
    enable_lattice_error_correction: bool = True
    prefer_gpu_qubits: bool = True
    enable_cortical_accelerators: bool = True
    
    # Biological parameters
    purkinje_cell_count: int = 100
    parallel_fiber_count: int = 200000
    climbing_fiber_count: int = 1
    granule_cell_count: int = 1000000
    
    # Learning parameters  
    learning_rate: float = 0.001
    plasticity_threshold: float = 0.5
    stdp_window_ms: float = 20.0
    ltd_magnitude: float = -0.1
    ltp_magnitude: float = 0.1
    
    # Lattice-enhanced parameters
    lattice_entanglement_strength: float = 0.8
    lattice_bell_pair_fidelity: float = 0.999
    cortical_pattern_matching: bool = True
    quantum_parallel_fiber_encoding: bool = True
    
    # Performance optimization
    enable_numba_acceleration: bool = USE_NUMBA
    enable_gpu_acceleration: bool = USE_CUPY
    batch_size: int = 32
    max_memory_mb: int = 1024

class LatticeQuantumPurkinjeCell:
    """
    Lattice-enhanced quantum Purkinje cell for temperature adaptation
    Uses lattice Bell pairs and entanglement for enhanced plasticity
    """
    
    def __init__(self, cell_id: int, config: CerebellarAdapterLatticeConfig, 
                 lattice_ops: Optional[QuantumLatticeOperations] = None):
        self.cell_id = cell_id
        self.config = config
        self.lattice_ops = lattice_ops
        self.use_lattice = config.use_lattice_operations and LATTICE_AVAILABLE and lattice_ops
        
        # Lattice quantum state
        self.allocated_qubits = None
        self.entangled_bell_pairs = []
        self.quantum_weights = None
        
        # Classical state
        self.parallel_fiber_weights = np.random.normal(0, 0.1, config.parallel_fiber_count)
        self.climbing_fiber_strength = 1.0
        self.membrane_potential = 0.0
        self.firing_rate = 0.0
        
        # Learning state
        self.recent_inputs = deque(maxlen=100)
        self.recent_errors = deque(maxlen=100)
        self.plasticity_trace = 0.0
        
        # Performance tracking
        self.adaptation_history = []
        self.lattice_performance_metrics = {}
    
    async def initialize_lattice_quantum_state(self):
        """Initialize lattice quantum state for enhanced plasticity"""
        if not self.use_lattice:
            return
        
        try:
            # Request qubits from lattice for this Purkinje cell
            self.allocated_qubits = await self._request_purkinje_qubits(2)  # Minimal qubits per cell
            
            # Create Bell pair entanglement for quantum plasticity
            bell_pair_result = await self.lattice_ops.execute_bell_pair_factory(
                gpu_qubit=self.allocated_qubits[0],
                cpu_qubit=self.allocated_qubits[1],
                target_fidelity=self.config.lattice_bell_pair_fidelity
            )
            
            self.entangled_bell_pairs = bell_pair_result["qubits"]
            
            # Initialize quantum weight encoding
            await self._initialize_quantum_weights()
            
            logger.debug(f"Purkinje cell {self.cell_id} lattice quantum state initialized")
            
        except Exception as e:
            logger.warning(f"Failed to initialize lattice quantum state for Purkinje cell {self.cell_id}: {e}")
            self.use_lattice = False
    
    async def _request_purkinje_qubits(self, n_qubits: int) -> List[int]:
        """Request qubit allocation for this Purkinje cell"""
        # Allocate qubits efficiently across many Purkinje cells
        base_qubit = (self.cell_id * 2) % 40  # Distribute across first 40 qubits
        return [base_qubit, base_qubit + 1]
    
    async def _initialize_quantum_weights(self):
        """Initialize quantum encoding of synaptic weights"""
        if not self.use_lattice or not self.allocated_qubits:
            return
            
        # Encode subset of weights quantum mechanically
        weight_subset = self.parallel_fiber_weights[:min(16, len(self.parallel_fiber_weights))]
        
        # Use lattice pattern accelerator for weight encoding
        if self.config.cortical_pattern_matching:
            pattern_result = await self.lattice_ops.execute_pattern_accelerator(
                pattern_qubits=self.allocated_qubits,
                pattern_signature=hash(tuple(weight_subset)) % (2**16)
            )
            
            self.quantum_weights = pattern_result["pattern_state"]
    
    async def process_parallel_fiber_input(self, parallel_fiber_input: np.ndarray) -> float:
        """
        Process parallel fiber input with lattice quantum enhancement
        """
        if self.use_lattice and self.config.quantum_parallel_fiber_encoding:
            return await self._quantum_parallel_fiber_processing(parallel_fiber_input)
        else:
            return self._classical_parallel_fiber_processing(parallel_fiber_input)
    
    async def _quantum_parallel_fiber_processing(self, pf_input: np.ndarray) -> float:
        """Lattice quantum-enhanced parallel fiber processing"""
        # Encode parallel fiber input in quantum state
        input_subset = pf_input[:min(16, len(pf_input))]
        
        # Use lattice operations for quantum processing
        processing_result = await self.lattice_ops.execute_operation(
            operation_type="parallel_fiber_processing",
            qubits=self.allocated_qubits,
            parameters={
                "input_data": input_subset.tolist(),
                "quantum_weights": self.quantum_weights,
                "entangled_pairs": self.entangled_bell_pairs,
                "processing_type": "quantum_dot_product"
            }
        )
        
        quantum_activation = processing_result["activation"]
        
        # Combine with classical processing for remaining inputs
        classical_activation = self._classical_parallel_fiber_processing(pf_input[16:])
        
        # Weighted combination
        total_activation = (0.7 * quantum_activation + 0.3 * classical_activation)
        
        self.membrane_potential += total_activation
        return total_activation
    
    def _classical_parallel_fiber_processing(self, pf_input: np.ndarray) -> float:
        """Classical parallel fiber processing"""
        if len(pf_input) == 0:
            return 0.0
        
        # Ensure weight dimensions match
        weight_subset = self.parallel_fiber_weights[:len(pf_input)]
        if len(weight_subset) < len(pf_input):
            # Pad weights if needed
            weight_subset = np.pad(weight_subset, (0, len(pf_input) - len(weight_subset)))
        
        activation = np.dot(pf_input, weight_subset[:len(pf_input)])
        self.membrane_potential += activation
        return activation
    
    async def process_climbing_fiber_error(self, error_signal: float, error_type: ErrorSignalType):
        """
        Process climbing fiber error signal with lattice quantum plasticity
        """
        self.recent_errors.append((error_signal, error_type, time.time()))
        
        if self.use_lattice and self.config.use_lattice_quantum_plasticity:
            await self._lattice_quantum_plasticity_update(error_signal, error_type)
        else:
            self._classical_plasticity_update(error_signal, error_type)
    
    async def _lattice_quantum_plasticity_update(self, error_signal: float, error_type: ErrorSignalType):
        """Lattice quantum-enhanced plasticity update"""
        try:
            # Use lattice quantum operations for plasticity computation
            plasticity_result = await self.lattice_ops.execute_operation(
                operation_type="quantum_plasticity_update",
                qubits=self.allocated_qubits,
                parameters={
                    "error_signal": error_signal,
                    "error_type": error_type.value,
                    "current_weights": self.quantum_weights,
                    "entangled_pairs": self.entangled_bell_pairs,
                    "learning_rate": self.config.learning_rate,
                    "plasticity_rule": LearningRule.LATTICE_QUANTUM_ENHANCED.value
                }
            )
            
            # Update quantum weights
            self.quantum_weights = plasticity_result["updated_weights"]
            
            # Update classical weights based on quantum computation
            quantum_weight_changes = plasticity_result["weight_changes"]
            classical_weight_indices = np.random.choice(
                len(self.parallel_fiber_weights), 
                size=min(16, len(quantum_weight_changes)),
                replace=False
            )
            
            for i, idx in enumerate(classical_weight_indices):
                if i < len(quantum_weight_changes):
                    self.parallel_fiber_weights[idx] += quantum_weight_changes[i]
            
            # Track performance
            self.lattice_performance_metrics.update({
                "quantum_plasticity_updates": self.lattice_performance_metrics.get("quantum_plasticity_updates", 0) + 1,
                "last_error_signal": error_signal,
                "last_update_time": time.time()
            })
            
        except Exception as e:
            logger.warning(f"Lattice quantum plasticity failed for cell {self.cell_id}: {e}")
            # Fallback to classical plasticity
            self._classical_plasticity_update(error_signal, error_type)
    
    def _classical_plasticity_update(self, error_signal: float, error_type: ErrorSignalType):
        """Classical plasticity update fallback"""
        # Implement LTD/LTP based on error signal
        if abs(error_signal) > self.config.plasticity_threshold:
            if error_signal < 0:  # Long-term depression
                weight_change = self.config.ltd_magnitude * abs(error_signal)
            else:  # Long-term potentiation  
                weight_change = self.config.ltp_magnitude * error_signal
            
            # Apply weight changes to recently active synapses
            if self.recent_inputs:
                recent_input = self.recent_inputs[-1]
                active_indices = np.where(recent_input > 0.1)[0]
                self.parallel_fiber_weights[active_indices] += weight_change
                
                # Clip weights to reasonable range
                self.parallel_fiber_weights = np.clip(self.parallel_fiber_weights, -1.0, 1.0)
    
    def update_firing_rate(self):
        """Update Purkinje cell firing rate based on membrane potential"""
        # Sigmoid activation function
        self.firing_rate = 1.0 / (1.0 + np.exp(-self.membrane_potential))
        
        # Reset membrane potential with decay
        self.membrane_potential *= 0.9
    
    def get_temperature_influence(self) -> float:
        """Get this cell's influence on temperature adaptation"""
        return self.firing_rate * self.climbing_fiber_strength


class CerebellarTemperatureAdapterLatticeIntegrated:
    """
    Lattice-integrated cerebellar temperature adapter using biological quantum learning
    
    Leverages Quantum Lattice (99.5% coherence, 11,533 qubits) for enhanced
    cerebellar learning and temperature adaptation with quantum plasticity.
    """
    
    def __init__(self, config: CerebellarAdapterLatticeConfig, 
                 lattice_operations: Optional[QuantumLatticeOperations] = None):
        self.config = config
        self.lattice_ops = lattice_operations
        self.use_lattice = config.use_lattice_operations and LATTICE_AVAILABLE and lattice_operations
        
        # Lattice session management
        self.lattice_session_id = None
        self.allocated_qubits = None
        
        # Initialize Purkinje cells
        self.purkinje_cells = []
        for i in range(config.purkinje_cell_count):
            cell = LatticeQuantumPurkinjeCell(i, config, lattice_operations)
            self.purkinje_cells.append(cell)
        
        # Network state
        self.parallel_fiber_activity = np.zeros(config.parallel_fiber_count)
        self.granule_cell_activity = np.zeros(config.granule_cell_count)
        
        # Adaptation history
        self.temperature_history = deque(maxlen=1000)
        self.error_history = deque(maxlen=1000)
        self.adaptation_performance = {}
        
        # Lattice performance tracking
        self.lattice_metrics = {
            "session_initialized": False,
            "coherence_maintained": 0.0,
            "quantum_operations_executed": 0,
            "adaptation_cycles_completed": 0
        }
        
        logger.info(f"üß† Initialized Cerebellar Adapter with {config.purkinje_cell_count} Purkinje cells")
        if self.use_lattice:
            logger.info("üåä Lattice integration enabled for quantum-enhanced cerebellar learning")
    
    async def initialize_lattice_session(self):
        """Initialize lattice session for cerebellar adaptation"""
        if not self.use_lattice:
            return
        
        try:
            self.lattice_session_id = f"cerebellar_{int(time.time() * 1000)}"
            
            # Check lattice health
            lattice_health = await self.lattice_ops.is_healthy()
            lattice_coherence = await self.lattice_ops.get_coherence()
            
            if not lattice_health:
                raise RuntimeError("Lattice not healthy")
            
            if lattice_coherence < self.config.min_coherence_requirement:
                logger.warning(f"Lattice coherence {lattice_coherence:.3f} below requirement")
            
            # Allocate qubits for cerebellar network
            self.allocated_qubits = await self._request_cerebellar_qubits()
            
            # Initialize Purkinje cell quantum states
            initialization_tasks = []
            for cell in self.purkinje_cells:
                task = cell.initialize_lattice_quantum_state()
                initialization_tasks.append(task)
            
            # Initialize cells in parallel
            await asyncio.gather(*initialization_tasks, return_exceptions=True)
            
            # Update metrics
            self.lattice_metrics.update({
                "session_initialized": True,
                "coherence_maintained": lattice_coherence,
                "session_id": self.lattice_session_id,
                "allocated_qubits": len(self.allocated_qubits) if self.allocated_qubits else 0,
                "purkinje_cells_initialized": len(self.purkinje_cells)
            })
            
            logger.info(f"‚úÖ Cerebellar lattice session initialized: {self.lattice_session_id}")
            logger.info(f"   Coherence: {lattice_coherence:.3f}, Qubits: {len(self.allocated_qubits) if self.allocated_qubits else 0}")
            
        except Exception as e:
            logger.error(f"Failed to initialize cerebellar lattice session: {e}")
            self.use_lattice = False
    
    async def _request_cerebellar_qubits(self) -> List[int]:
        """Request qubits for cerebellar network"""
        # Calculate qubit requirements
        base_qubits = 20  # Base cerebellar processing
        purkinje_qubits = self.config.purkinje_cell_count * 2  # 2 qubits per Purkinje cell
        total_qubits = min(base_qubits + purkinje_qubits, 200)  # Reasonable limit
        
        # For demonstration, allocate qubits sequentially
        allocated_qubits = list(range(40, 40 + total_qubits))  # Start after ATS-CP allocation
        
        return allocated_qubits
    
    async def adapt_temperature(self, current_temperature: float, error_signals: np.ndarray, 
                              conformal_context: Dict) -> float:
        """
        Main temperature adaptation method using lattice-enhanced cerebellar learning
        
        Args:
            current_temperature: Current temperature parameter
            error_signals: Prediction error signals
            conformal_context: Context from conformal prediction
            
        Returns:
            Adapted temperature parameter
        """
        if self.use_lattice and not self.lattice_metrics["session_initialized"]:
            await self.initialize_lattice_session()
        
        start_time = time.time()
        
        # Process sensory input (error signals)
        sensory_input = await self._process_sensory_input(error_signals, conformal_context)
        
        # Activate granule cells
        granule_activation = await self._activate_granule_cells(sensory_input)
        
        # Generate parallel fiber activity
        parallel_fiber_activity = await self._generate_parallel_fiber_activity(granule_activation)
        
        # Process through Purkinje cells
        purkinje_output = await self._process_purkinje_cells(parallel_fiber_activity)
        
        # Compute temperature adaptation
        temperature_delta = await self._compute_temperature_adaptation(purkinje_output, error_signals)
        
        # Apply adaptation with bounds
        adapted_temperature = self._apply_temperature_bounds(current_temperature + temperature_delta)
        
        # Update learning based on results
        await self._update_cerebellar_learning(current_temperature, adapted_temperature, error_signals)
        
        # Track performance
        execution_time = (time.time() - start_time) * 1000
        self._update_performance_metrics(adapted_temperature, error_signals, execution_time)
        
        # Store in history
        self.temperature_history.append((current_temperature, adapted_temperature, time.time()))
        self.error_history.append((error_signals.mean(), time.time()))
        
        logger.debug(f"Temperature adapted: {current_temperature:.3f} ‚Üí {adapted_temperature:.3f} ({execution_time:.1f}ms)")
        
        return adapted_temperature
    
    async def _process_sensory_input(self, error_signals: np.ndarray, context: Dict) -> np.ndarray:
        """Process sensory input through lattice quantum operations"""
        if self.use_lattice and self.config.enable_cortical_accelerators:
            # Use lattice pattern accelerator for sensory processing
            sensory_pattern = hash(tuple(error_signals)) % (2**16)
            
            pattern_result = await self.lattice_ops.execute_pattern_accelerator(
                pattern_qubits=self.allocated_qubits[:8],
                pattern_signature=sensory_pattern
            )
            
            # Combine quantum and classical processing
            quantum_processed = np.array(pattern_result.get("processed_signals", error_signals))
            classical_processed = self._classical_sensory_processing(error_signals, context)
            
            # Weighted combination
            sensory_input = 0.6 * quantum_processed[:len(classical_processed)] + 0.4 * classical_processed
        else:
            sensory_input = self._classical_sensory_processing(error_signals, context)
        
        return sensory_input
    
    def _classical_sensory_processing(self, error_signals: np.ndarray, context: Dict) -> np.ndarray:
        """Classical sensory processing fallback"""
        # Normalize and amplify error signals
        normalized_errors = (error_signals - np.mean(error_signals)) / (np.std(error_signals) + 1e-8)
        
        # Add context-dependent modulation
        coverage_error = context.get('coverage_error', 0.0)
        calibration_error = context.get('calibration_error', 0.0)
        
        modulation = 1.0 + 0.1 * coverage_error + 0.05 * calibration_error
        
        return normalized_errors * modulation
    
    async def _activate_granule_cells(self, sensory_input: np.ndarray) -> np.ndarray:
        """Activate granule cells based on sensory input"""
        # Expand sensory input to granule cell layer
        input_size = len(sensory_input)
        expansion_factor = self.config.granule_cell_count // input_size
        
        granule_input = np.repeat(sensory_input, expansion_factor)[:self.config.granule_cell_count]
        
        # Add noise for sparse coding
        noise = np.random.normal(0, 0.1, self.config.granule_cell_count)
        
        # Threshold activation
        threshold = 0.2
        self.granule_cell_activity = np.where(granule_input + noise > threshold, 
                                             granule_input + noise, 0)
        
        return self.granule_cell_activity
    
    async def _generate_parallel_fiber_activity(self, granule_activation: np.ndarray) -> np.ndarray:
        """Generate parallel fiber activity from granule cells"""
        # Each granule cell connects to multiple parallel fibers
        connections_per_granule = self.config.parallel_fiber_count // self.config.granule_cell_count
        
        parallel_fiber_activity = np.zeros(self.config.parallel_fiber_count)
        
        for i, activity in enumerate(granule_activation):
            if activity > 0:
                start_idx = i * connections_per_granule
                end_idx = min(start_idx + connections_per_granule, self.config.parallel_fiber_count)
                parallel_fiber_activity[start_idx:end_idx] = activity
        
        self.parallel_fiber_activity = parallel_fiber_activity
        return parallel_fiber_activity
    
    async def _process_purkinje_cells(self, parallel_fiber_activity: np.ndarray) -> np.ndarray:
        """Process parallel fiber activity through Purkinje cells"""
        purkinje_outputs = []
        
        # Process Purkinje cells in parallel
        processing_tasks = []
        for cell in self.purkinje_cells:
            # Each cell receives a subset of parallel fiber input
            start_idx = cell.cell_id * (len(parallel_fiber_activity) // len(self.purkinje_cells))
            end_idx = start_idx + (len(parallel_fiber_activity) // len(self.purkinje_cells))
            cell_input = parallel_fiber_activity[start_idx:end_idx]
            
            task = cell.process_parallel_fiber_input(cell_input)
            processing_tasks.append(task)
        
        # Wait for all cells to process
        cell_activations = await asyncio.gather(*processing_tasks, return_exceptions=True)
        
        # Update firing rates and get outputs
        for i, cell in enumerate(self.purkinje_cells):
            if not isinstance(cell_activations[i], Exception):
                cell.update_firing_rate()
                purkinje_outputs.append(cell.get_temperature_influence())
            else:
                purkinje_outputs.append(0.0)
        
        return np.array(purkinje_outputs)
    
    async def _compute_temperature_adaptation(self, purkinje_output: np.ndarray, 
                                            error_signals: np.ndarray) -> float:
        """Compute temperature adaptation based on Purkinje cell output"""
        # Weighted sum of Purkinje cell influences
        total_influence = np.sum(purkinje_output)
        
        # Scale by error magnitude
        error_magnitude = np.sqrt(np.mean(error_signals**2))
        
        # Compute adaptation magnitude
        adaptation_magnitude = total_influence * error_magnitude * self.config.learning_rate
        
        # Direction based on error sign
        error_direction = np.sign(np.mean(error_signals))
        
        temperature_delta = adaptation_magnitude * error_direction
        
        return temperature_delta
    
    def _apply_temperature_bounds(self, temperature: float) -> float:
        """Apply reasonable bounds to temperature parameter"""
        return np.clip(temperature, 0.1, 5.0)
    
    async def _update_cerebellar_learning(self, old_temp: float, new_temp: float, 
                                        error_signals: np.ndarray):
        """Update cerebellar learning based on adaptation results"""
        # Compute prediction improvement
        temperature_change = abs(new_temp - old_temp)
        
        # Generate climbing fiber error signals for each Purkinje cell
        for cell in self.purkinje_cells:
            # Each cell gets error signal based on its contribution
            cell_error = error_signals[cell.cell_id % len(error_signals)]
            
            # Determine error type based on error characteristics
            if abs(cell_error) > 0.1:
                error_type = ErrorSignalType.CALIBRATION_ERROR
            else:
                error_type = ErrorSignalType.PREDICTION_ERROR
            
            # Send climbing fiber signal
            await cell.process_climbing_fiber_error(cell_error, error_type)
        
        # Update global metrics
        self.lattice_metrics["adaptation_cycles_completed"] += 1
        self.lattice_metrics["quantum_operations_executed"] += len(self.purkinje_cells)
    
    def _update_performance_metrics(self, adapted_temperature: float, error_signals: np.ndarray, 
                                  execution_time: float):
        """Update performance metrics"""
        current_time = time.time()
        
        self.adaptation_performance.update({
            "last_adaptation_time": current_time,
            "last_execution_time_ms": execution_time,
            "last_temperature": adapted_temperature,
            "last_error_magnitude": np.sqrt(np.mean(error_signals**2)),
            "adaptations_completed": self.adaptation_performance.get("adaptations_completed", 0) + 1,
            "average_execution_time": self._calculate_average_execution_time(execution_time),
            "lattice_session_active": self.lattice_metrics["session_initialized"]
        })
    
    def _calculate_average_execution_time(self, current_time: float) -> float:
        """Calculate running average of execution times"""
        adaptations = self.adaptation_performance.get("adaptations_completed", 0)
        if adaptations == 0:
            return current_time
        
        prev_avg = self.adaptation_performance.get("average_execution_time", current_time)
        return (prev_avg * adaptations + current_time) / (adaptations + 1)
    
    # =========================================================================
    # Performance and Monitoring Methods
    # =========================================================================
    
    async def get_lattice_performance_metrics(self) -> Dict:
        """Get comprehensive lattice performance metrics"""
        if self.use_lattice:
            try:
                lattice_coherence = await self.lattice_ops.get_coherence()
                self.lattice_metrics["coherence_maintained"] = lattice_coherence
            except:
                pass
        
        # Purkinje cell metrics
        purkinje_metrics = []
        for cell in self.purkinje_cells:
            cell_metrics = {
                "cell_id": cell.cell_id,
                "firing_rate": cell.firing_rate,
                "membrane_potential": cell.membrane_potential,
                "use_lattice": cell.use_lattice,
                "lattice_metrics": cell.lattice_performance_metrics
            }
            purkinje_metrics.append(cell_metrics)
        
        return {
            "lattice_integration": self.lattice_metrics,
            "adaptation_performance": self.adaptation_performance,
            "purkinje_cells": purkinje_metrics,
            "network_state": {
                "parallel_fiber_activity_level": np.mean(self.parallel_fiber_activity),
                "granule_cell_activity_level": np.mean(self.granule_cell_activity),
                "total_purkinje_activity": sum(cell.firing_rate for cell in self.purkinje_cells)
            },
            "configuration": {
                "purkinje_cell_count": self.config.purkinje_cell_count,
                "use_lattice": self.use_lattice,
                "lattice_session_id": self.lattice_session_id
            }
        }
    
    def get_adaptation_summary(self) -> Dict:
        """Get summary of temperature adaptation performance"""
        if not self.temperature_history:
            return {"status": "no_adaptations_yet"}
        
        recent_adaptations = list(self.temperature_history)[-10:]
        
        temperature_changes = []
        for i in range(1, len(recent_adaptations)):
            old_temp = recent_adaptations[i-1][0]
            new_temp = recent_adaptations[i][1]
            temperature_changes.append(abs(new_temp - old_temp))
        
        return {
            "total_adaptations": len(self.temperature_history),
            "recent_average_change": np.mean(temperature_changes) if temperature_changes else 0.0,
            "recent_max_change": np.max(temperature_changes) if temperature_changes else 0.0,
            "current_temperature": recent_adaptations[-1][1] if recent_adaptations else 0.0,
            "adaptation_stability": 1.0 / (1.0 + np.std(temperature_changes)) if temperature_changes else 0.0,
            "lattice_enhanced": self.use_lattice
        }
    
    async def cleanup_lattice_session(self):
        """Clean up lattice session and resources"""
        if self.use_lattice and self.lattice_session_id:
            logger.info(f"üßπ Cleaning up cerebellar lattice session: {self.lattice_session_id}")
            
            # Clean up Purkinje cell quantum states
            for cell in self.purkinje_cells:
                cell.allocated_qubits = None
                cell.entangled_bell_pairs = []
                cell.quantum_weights = None
            
            self.allocated_qubits = None
            self.lattice_session_id = None
            self.lattice_metrics["session_initialized"] = False


# =============================================================================
# Factory Functions and Integration Utilities
# =============================================================================

async def create_lattice_cerebellar_adapter(lattice_operations: QuantumLatticeOperations,
                                           config: Optional[CerebellarAdapterLatticeConfig] = None) -> CerebellarTemperatureAdapterLatticeIntegrated:
    """
    Factory function to create lattice-integrated cerebellar adapter
    """
    if config is None:
        config = CerebellarAdapterLatticeConfig()
    
    adapter = CerebellarTemperatureAdapterLatticeIntegrated(config, lattice_operations)
    await adapter.initialize_lattice_session()
    
    return adapter

def create_standalone_cerebellar_adapter(config: Optional[CerebellarAdapterLatticeConfig] = None) -> CerebellarTemperatureAdapterLatticeIntegrated:
    """
    Factory function to create standalone cerebellar adapter
    """
    if config is None:
        config = CerebellarAdapterLatticeConfig(use_lattice_operations=False)
    else:
        config.use_lattice_operations = False
    
    return CerebellarTemperatureAdapterLatticeIntegrated(config, None)

# =============================================================================
# Integration Demonstration
# =============================================================================

async def demonstrate_lattice_cerebellar_integration():
    """
    Demonstrate cerebellar adapter integration with Quantum Lattice
    """
    print("üß† CEREBELLAR ADAPTER LATTICE INTEGRATION DEMONSTRATION")
    print("=" * 65)
    print("Testing biological quantum learning with 99.5% coherence lattice")
    print("=" * 65)
    
    # Create test data
    np.random.seed(42)
    error_signals = np.random.normal(0, 0.5, 10)  # Temperature calibration errors
    conformal_context = {
        'coverage_error': 0.02,
        'calibration_error': 0.15,
        'prediction_confidence': 0.85
    }
    
    try:
        # Create lattice-integrated cerebellar adapter
        config = CerebellarAdapterLatticeConfig(
            purkinje_cell_count=50,  # Reduced for demonstration
            use_lattice_operations=True,
            min_coherence_requirement=0.95,
            max_latency_requirement_ms=15.0
        )
        
        # For demonstration, create standalone version
        adapter = create_standalone_cerebellar_adapter(config)
        
        print(f"‚úÖ Cerebellar adapter initialized in {'lattice' if adapter.use_lattice else 'standalone'} mode")
        print(f"   Purkinje cells: {config.purkinje_cell_count}")
        print(f"   Parallel fibers: {config.parallel_fiber_count:,}")
        
        # Test temperature adaptation
        current_temperature = 1.0
        
        print(f"\\nüß† Testing Temperature Adaptation:")
        print(f"   Initial temperature: {current_temperature:.3f}")
        print(f"   Error signals: mean={np.mean(error_signals):.3f}, std={np.std(error_signals):.3f}")
        
        start_time = time.time()
        
        adapted_temperature = await adapter.adapt_temperature(
            current_temperature=current_temperature,
            error_signals=error_signals,
            conformal_context=conformal_context
        )
        
        execution_time = (time.time() - start_time) * 1000
        
        print(f"\\nüìä Adaptation Results:")
        print(f"   Adapted temperature: {adapted_temperature:.3f}")
        print(f"   Temperature change: {adapted_temperature - current_temperature:+.3f}")
        print(f"   Execution time: {execution_time:.1f}ms")
        
        # Test multiple adaptation cycles
        print(f"\\nüîÑ Testing Multiple Adaptation Cycles:")
        temperatures = [current_temperature]
        
        for cycle in range(5):
            error_signals = np.random.normal(0, 0.3, 10)  # New error signals
            adapted_temp = await adapter.adapt_temperature(
                current_temperature=temperatures[-1],
                error_signals=error_signals,
                conformal_context=conformal_context
            )
            temperatures.append(adapted_temp)
            print(f"   Cycle {cycle+1}: {temperatures[-2]:.3f} ‚Üí {adapted_temp:.3f}")
        
        # Performance metrics
        if adapter.use_lattice:
            lattice_metrics = await adapter.get_lattice_performance_metrics()
        else:
            lattice_metrics = await adapter.get_lattice_performance_metrics()
        
        print(f"\\nüöÄ Performance Metrics:")
        print(f"   Total adaptations: {lattice_metrics['adaptation_performance'].get('adaptations_completed', 0)}")
        print(f"   Average execution time: {lattice_metrics['adaptation_performance'].get('average_execution_time', 0):.1f}ms")
        print(f"   Lattice integration: {lattice_metrics['lattice_integration']['session_initialized']}")
        
        adaptation_summary = adapter.get_adaptation_summary()
        print(f"   Adaptation stability: {adaptation_summary['adaptation_stability']:.3f}")
        print(f"   Recent average change: {adaptation_summary['recent_average_change']:.3f}")
        
        if adapter.use_lattice:
            await adapter.cleanup_lattice_session()
        
        print(f"\\n‚úÖ CEREBELLAR LATTICE INTEGRATION SUCCESSFUL")
        print("Ready for biological quantum learning with lattice infrastructure!")
        
    except Exception as e:
        print(f"‚ùå Integration test failed: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    def run_async_safe(coro):
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                import concurrent.futures
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(asyncio.run, coro)
                    return future.result()
            else:
                return asyncio.run(coro)
        except RuntimeError:
            return asyncio.run(coro)
    
    print("üöÄ Starting Cerebellar Lattice Integration Demonstration...")
    run_async_safe(demonstrate_lattice_cerebellar_integration())
    print("üéâ Demonstration completed!")