# ML Training Infrastructure

A production-ready machine learning training infrastructure for the Neuro Trader system, providing unified interfaces for deep learning and gradient boosting models with comprehensive experiment tracking and deployment capabilities.

## Features

### ðŸš€ Model Support
- **Deep Learning**: Transformer, LSTM with GPU acceleration
- **Gradient Boosting**: XGBoost, LightGBM with GPU support
- **Classical ML**: Neural networks, ensemble methods
- **Unified Interface**: Common API for all model types

### ðŸ“Š Training Pipeline
- **Batch & Real-time**: Support for both training modes
- **Checkpointing**: Automatic model checkpointing during training
- **Early Stopping**: Configurable early stopping strategies
- **Mixed Precision**: FP16 training for faster computation

### ðŸ§ª Experiment Tracking
- **MLflow-like Interface**: Track experiments, runs, and artifacts
- **Metrics Logging**: Comprehensive metric tracking
- **Parameter Tracking**: Automatic hyperparameter logging
- **Model Versioning**: Semantic versioning for models

### ðŸ“ˆ Cross-Validation
- **Time Series Split**: Proper time series cross-validation
- **Purged K-Fold**: Avoid data leakage in financial data
- **Walk-Forward Analysis**: Rolling window validation
- **Combinatorial Purged**: Advanced CV for finance

### ðŸŽ¯ Hyperparameter Optimization
- **Bayesian Optimization**: Efficient parameter search
- **Grid & Random Search**: Traditional search methods
- **Optuna Integration**: State-of-the-art HPO
- **Pruning**: Early stopping for bad trials

### ðŸ­ Production Features
- **Model Registry**: Centralized model storage
- **Deployment Ready**: Export to ONNX, TensorRT
- **Monitoring**: Prometheus metrics integration
- **GPU Management**: Efficient GPU memory handling

## Quick Start

```rust
use ml_training_infrastructure::{
    initialize, MLInfrastructure, TrainingConfig, ModelType,
};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize infrastructure
    initialize().await?;
    
    // Create configuration
    let config = TrainingConfig::default();
    
    // Create infrastructure
    let infra = MLInfrastructure::new(config).await?;
    
    // Load data
    let data = load_training_data().await?;
    
    // Train model
    let model_id = infra.train_model(
        ModelType::XGBoost,
        data,
        "my_experiment"
    ).await?;
    
    // Deploy model
    let model = infra.deploy_model(&model_id).await?;
    
    Ok(())
}
```

## Configuration

```toml
[data]
source_path = "data/market_data.parquet"
batch_size = 64
sequence_length = 100
horizon = 10
features = ["open", "high", "low", "close", "volume"]
normalization = "standard"

[models.xgboost]
n_estimators = 100
max_depth = 6
learning_rate = 0.1
tree_method = "gpu_hist"  # GPU acceleration

[models.transformer]
num_layers = 6
d_model = 512
num_heads = 8
dropout = 0.1

[validation]
cv_strategy = "time_series_split"
n_folds = 5
gap = 10  # Purge gap for financial data

[optimization]
method = "bayesian"
n_trials = 50
timeout = 3600
```

## Model Types

### Transformer
- Multi-head attention for sequence modeling
- Positional encoding for time series
- GPU-accelerated training with Candle

### LSTM
- Bidirectional LSTM support
- Attention mechanism integration
- Optimized for time series forecasting

### XGBoost
- GPU-accelerated training (gpu_hist)
- Early stopping support
- Feature importance extraction

### LightGBM
- Fast training with histogram-based algorithms
- GPU support for large datasets
- Categorical feature handling

## Cross-Validation Strategies

### Time Series Split
```rust
let config = ValidationConfig {
    cv_strategy: CVStrategy::TimeSeriesSplit,
    n_folds: 5,
    gap: 10,  // Avoid lookahead bias
};
```

### Purged K-Fold
```rust
let config = ValidationConfig {
    cv_strategy: CVStrategy::PurgedKFold,
    n_folds: 5,
    purged: true,  // Remove overlapping samples
};
```

### Walk-Forward Analysis
```rust
let config = ValidationConfig {
    cv_strategy: CVStrategy::WalkForward,
    walk_forward: true,
    n_folds: 10,  // Number of windows
};
```

## Experiment Tracking

```rust
// Start experiment
let experiment_id = tracker.start_experiment("xgboost_tuning", ModelType::XGBoost).await?;

// Log parameters
tracker.log_config(&experiment_id, config).await?;

// Log metrics during training
tracker.log_metrics(&experiment_id, &metrics).await?;

// Log artifacts
tracker.log_artifact(&experiment_id, ArtifactType::Model, &model_path).await?;

// Compare experiments
let comparison = tracker.compare_experiments(vec![exp1, exp2, exp3]).await?;
```

## Performance Metrics

### Financial Metrics
- **Sharpe Ratio**: Risk-adjusted returns
- **Maximum Drawdown**: Worst peak-to-trough decline
- **Hit Rate**: Directional accuracy
- **Profit Factor**: Gross profit / gross loss

### ML Metrics
- MSE, MAE, RMSE, MAPE
- R-squared
- Custom metrics support

## Benchmarks

Run benchmarks:
```bash
cargo bench --features gpu
```

Performance on NVIDIA A100:
- XGBoost training: ~1000 samples/sec
- Transformer inference: ~10ms/batch
- Data loading: ~50GB/sec with parallel loading

## Integration with Neuro Trader

The infrastructure integrates seamlessly with other Neuro Trader components:

```rust
// Use with neural-forecast models
let forecast_model = neural_forecast::NHITSModel::new(config)?;
let trained_model = infra.train_model(forecast_model, data).await?;

// Use with CDFA features
let cdfa_features = cdfa_core::extract_features(&market_data)?;
let enhanced_data = data.with_features(cdfa_features);
```

## Production Deployment

### Model Registry
```rust
// Save model
let model_id = registry.save_model(&model, &experiment_id).await?;

// Load model
let model = registry.load_model(&model_id).await?;

// List models
let models = registry.list_models(ModelType::XGBoost).await?;
```

### Export Formats
- **ONNX**: Cross-platform inference
- **TensorRT**: NVIDIA GPU optimization
- **Custom Binary**: Fast loading

### Monitoring
```rust
// Prometheus metrics
let metrics = METRICS_REGISTRY.gather();

// Custom monitoring
monitor.track_inference_time(&model_id, duration);
monitor.track_prediction_accuracy(&model_id, accuracy);
```

## Contributing

See [CONTRIBUTING.md](../../CONTRIBUTING.md) for development guidelines.

## License

This project is licensed under the MIT OR Apache-2.0 license.